{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CpLYkhvwqiWU"
   },
   "source": [
    "# Home 4: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Xing Fang\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSjwn_ZyqiWY"
   },
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbHH0uUEqiWa"
   },
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5dpUgZGlqiWd"
   },
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "_Q-FXyc-qiWg",
    "outputId": "3dcef9f7-fef2-4d8d-9760-61c8cb0ba94c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 6s 0us/step\n",
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lcFme21AqiWq"
   },
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "hVkAYnWxqiWt",
    "outputId": "14f61400-86c7-4e19-be38-c48bce5f90ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def to_one_hot(y, num_class=10):\n",
    "    results = np.zeros([(len(y)), num_class])\n",
    "    for i, label in enumerate(y):\n",
    "        results[i, label] = 1\n",
    "    return results\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ImANKJ4qiW8"
   },
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaunHMUKqiXB"
   },
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "D8BfvIwFqiXE",
    "outputId": "f3379e09-397e-490a-cd79-513688644cde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "se1byVdAqiXM"
   },
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I3u_WFijqiXO"
   },
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OlqeudRXfPzg"
   },
   "source": [
    "### Baseline model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7OYdPv7hqiXQ",
    "outputId": "4ac8ca4d-1681-4b90-88a7-2ecaf5d5c49e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 461,514\n",
      "Trainable params: 460,554\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "ZFds7ct6YQBJ",
    "outputId": "518e67dc-1b0c-4c95-951a-cf1435b2b826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-5 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "92DiBqRvYK6e",
    "outputId": "fcafa846-c2d8-45d9-979f-b4e837f896f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "40000/40000 [==============================] - 31s 773us/step - loss: 2.1598 - acc: 0.2171 - val_loss: 1.7682 - val_acc: 0.3875\n",
      "Epoch 2/60\n",
      "40000/40000 [==============================] - 24s 601us/step - loss: 1.8700 - acc: 0.3166 - val_loss: 1.6091 - val_acc: 0.4365\n",
      "Epoch 3/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 1.7257 - acc: 0.3640 - val_loss: 1.5039 - val_acc: 0.4657\n",
      "Epoch 4/60\n",
      "40000/40000 [==============================] - 24s 606us/step - loss: 1.6373 - acc: 0.3999 - val_loss: 1.4294 - val_acc: 0.4960\n",
      "Epoch 5/60\n",
      "40000/40000 [==============================] - 24s 604us/step - loss: 1.5682 - acc: 0.4241 - val_loss: 1.3787 - val_acc: 0.5113\n",
      "Epoch 6/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 1.5111 - acc: 0.4471 - val_loss: 1.3377 - val_acc: 0.5218\n",
      "Epoch 7/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.4661 - acc: 0.4637 - val_loss: 1.3016 - val_acc: 0.5333\n",
      "Epoch 8/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.4249 - acc: 0.4832 - val_loss: 1.2717 - val_acc: 0.5424\n",
      "Epoch 9/60\n",
      "40000/40000 [==============================] - 24s 601us/step - loss: 1.3867 - acc: 0.4947 - val_loss: 1.2360 - val_acc: 0.5560\n",
      "Epoch 10/60\n",
      "40000/40000 [==============================] - 24s 604us/step - loss: 1.3552 - acc: 0.5072 - val_loss: 1.2134 - val_acc: 0.5666\n",
      "Epoch 11/60\n",
      "40000/40000 [==============================] - 24s 600us/step - loss: 1.3257 - acc: 0.5197 - val_loss: 1.1956 - val_acc: 0.5729\n",
      "Epoch 12/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.2965 - acc: 0.5323 - val_loss: 1.1725 - val_acc: 0.5802\n",
      "Epoch 13/60\n",
      "40000/40000 [==============================] - 24s 601us/step - loss: 1.2731 - acc: 0.5415 - val_loss: 1.1534 - val_acc: 0.5880\n",
      "Epoch 14/60\n",
      "40000/40000 [==============================] - 24s 601us/step - loss: 1.2542 - acc: 0.5483 - val_loss: 1.1328 - val_acc: 0.5966\n",
      "Epoch 15/60\n",
      "40000/40000 [==============================] - 24s 605us/step - loss: 1.2252 - acc: 0.5619 - val_loss: 1.1189 - val_acc: 0.6028\n",
      "Epoch 16/60\n",
      "40000/40000 [==============================] - 24s 611us/step - loss: 1.1992 - acc: 0.5677 - val_loss: 1.1042 - val_acc: 0.6073\n",
      "Epoch 17/60\n",
      "40000/40000 [==============================] - 24s 608us/step - loss: 1.1824 - acc: 0.5767 - val_loss: 1.0893 - val_acc: 0.6144\n",
      "Epoch 18/60\n",
      "40000/40000 [==============================] - 24s 607us/step - loss: 1.1628 - acc: 0.5841 - val_loss: 1.0750 - val_acc: 0.6175\n",
      "Epoch 19/60\n",
      "40000/40000 [==============================] - 24s 605us/step - loss: 1.1440 - acc: 0.5901 - val_loss: 1.0651 - val_acc: 0.6215\n",
      "Epoch 20/60\n",
      "40000/40000 [==============================] - 24s 604us/step - loss: 1.1286 - acc: 0.5951 - val_loss: 1.0528 - val_acc: 0.6274\n",
      "Epoch 21/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.1093 - acc: 0.6043 - val_loss: 1.0428 - val_acc: 0.6321\n",
      "Epoch 22/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.0936 - acc: 0.6087 - val_loss: 1.0372 - val_acc: 0.6329\n",
      "Epoch 23/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 1.0787 - acc: 0.6145 - val_loss: 1.0238 - val_acc: 0.6387\n",
      "Epoch 24/60\n",
      "40000/40000 [==============================] - 24s 604us/step - loss: 1.0628 - acc: 0.6201 - val_loss: 1.0248 - val_acc: 0.6353\n",
      "Epoch 25/60\n",
      "40000/40000 [==============================] - 24s 604us/step - loss: 1.0461 - acc: 0.6246 - val_loss: 1.0092 - val_acc: 0.6400\n",
      "Epoch 26/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.0258 - acc: 0.6351 - val_loss: 1.0037 - val_acc: 0.6434\n",
      "Epoch 27/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.0137 - acc: 0.6370 - val_loss: 0.9956 - val_acc: 0.6488\n",
      "Epoch 28/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 0.9980 - acc: 0.6454 - val_loss: 0.9887 - val_acc: 0.6507\n",
      "Epoch 29/60\n",
      "40000/40000 [==============================] - 24s 605us/step - loss: 0.9878 - acc: 0.6473 - val_loss: 0.9879 - val_acc: 0.6514\n",
      "Epoch 30/60\n",
      "40000/40000 [==============================] - 24s 599us/step - loss: 0.9745 - acc: 0.6504 - val_loss: 0.9866 - val_acc: 0.6514\n",
      "Epoch 31/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 0.9681 - acc: 0.6555 - val_loss: 0.9719 - val_acc: 0.6586\n",
      "Epoch 32/60\n",
      "40000/40000 [==============================] - 24s 598us/step - loss: 0.9508 - acc: 0.6628 - val_loss: 0.9698 - val_acc: 0.6590\n",
      "Epoch 33/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 0.9338 - acc: 0.6686 - val_loss: 0.9609 - val_acc: 0.6629\n",
      "Epoch 34/60\n",
      "40000/40000 [==============================] - 24s 600us/step - loss: 0.9264 - acc: 0.6688 - val_loss: 0.9599 - val_acc: 0.6623\n",
      "Epoch 35/60\n",
      "40000/40000 [==============================] - 24s 598us/step - loss: 0.9144 - acc: 0.6735 - val_loss: 0.9566 - val_acc: 0.6654\n",
      "Epoch 36/60\n",
      "40000/40000 [==============================] - 24s 598us/step - loss: 0.9011 - acc: 0.6803 - val_loss: 0.9551 - val_acc: 0.6672\n",
      "Epoch 37/60\n",
      "40000/40000 [==============================] - 24s 596us/step - loss: 0.8938 - acc: 0.6819 - val_loss: 0.9496 - val_acc: 0.6688\n",
      "Epoch 38/60\n",
      "40000/40000 [==============================] - 24s 597us/step - loss: 0.8795 - acc: 0.6898 - val_loss: 0.9434 - val_acc: 0.6699\n",
      "Epoch 39/60\n",
      "40000/40000 [==============================] - 24s 594us/step - loss: 0.8757 - acc: 0.6887 - val_loss: 0.9381 - val_acc: 0.6729\n",
      "Epoch 40/60\n",
      "40000/40000 [==============================] - 24s 596us/step - loss: 0.8592 - acc: 0.6949 - val_loss: 0.9435 - val_acc: 0.6712\n",
      "Epoch 41/60\n",
      "40000/40000 [==============================] - 24s 597us/step - loss: 0.8531 - acc: 0.6971 - val_loss: 0.9446 - val_acc: 0.6708\n",
      "Epoch 42/60\n",
      "40000/40000 [==============================] - 24s 600us/step - loss: 0.8427 - acc: 0.7020 - val_loss: 0.9319 - val_acc: 0.6777\n",
      "Epoch 43/60\n",
      "40000/40000 [==============================] - 24s 598us/step - loss: 0.8377 - acc: 0.7023 - val_loss: 0.9241 - val_acc: 0.6813\n",
      "Epoch 44/60\n",
      "40000/40000 [==============================] - 24s 596us/step - loss: 0.8247 - acc: 0.7062 - val_loss: 0.9273 - val_acc: 0.6783\n",
      "Epoch 45/60\n",
      "40000/40000 [==============================] - 24s 596us/step - loss: 0.8162 - acc: 0.7098 - val_loss: 0.9293 - val_acc: 0.6778\n",
      "Epoch 46/60\n",
      "40000/40000 [==============================] - 24s 595us/step - loss: 0.8004 - acc: 0.7176 - val_loss: 0.9291 - val_acc: 0.6802\n",
      "Epoch 47/60\n",
      "40000/40000 [==============================] - 24s 595us/step - loss: 0.7940 - acc: 0.7187 - val_loss: 0.9280 - val_acc: 0.6812\n",
      "Epoch 48/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 0.7864 - acc: 0.7212 - val_loss: 0.9333 - val_acc: 0.6757\n",
      "Epoch 49/60\n",
      "40000/40000 [==============================] - 24s 605us/step - loss: 0.7809 - acc: 0.7242 - val_loss: 0.9142 - val_acc: 0.6863\n",
      "Epoch 50/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 0.7659 - acc: 0.7273 - val_loss: 0.9341 - val_acc: 0.6805\n",
      "Epoch 51/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 0.7595 - acc: 0.7320 - val_loss: 0.9162 - val_acc: 0.6879\n",
      "Epoch 52/60\n",
      "40000/40000 [==============================] - 24s 606us/step - loss: 0.7548 - acc: 0.7325 - val_loss: 0.9238 - val_acc: 0.6849\n",
      "Epoch 53/60\n",
      "40000/40000 [==============================] - 24s 605us/step - loss: 0.7427 - acc: 0.7362 - val_loss: 0.9224 - val_acc: 0.6865\n",
      "Epoch 54/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 0.7320 - acc: 0.7416 - val_loss: 0.9139 - val_acc: 0.6907\n",
      "Epoch 55/60\n",
      "40000/40000 [==============================] - 24s 610us/step - loss: 0.7276 - acc: 0.7405 - val_loss: 0.9120 - val_acc: 0.6903\n",
      "Epoch 56/60\n",
      "40000/40000 [==============================] - 24s 606us/step - loss: 0.7216 - acc: 0.7441 - val_loss: 0.9185 - val_acc: 0.6881\n",
      "Epoch 57/60\n",
      "40000/40000 [==============================] - 24s 604us/step - loss: 0.7146 - acc: 0.7458 - val_loss: 0.9216 - val_acc: 0.6903\n",
      "Epoch 58/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 0.6991 - acc: 0.7531 - val_loss: 0.9191 - val_acc: 0.6916\n",
      "Epoch 59/60\n",
      "40000/40000 [==============================] - 24s 605us/step - loss: 0.6874 - acc: 0.7567 - val_loss: 0.9119 - val_acc: 0.6956\n",
      "Epoch 60/60\n",
      "40000/40000 [==============================] - 24s 601us/step - loss: 0.6861 - acc: 0.7563 - val_loss: 0.9221 - val_acc: 0.6895\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_tr, y_tr,  \n",
    "           epochs=60, \n",
    "           verbose = 1,\n",
    "           validation_data = (x_val, y_val)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ZiQwOcXYfmu"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_train_val_acc(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "luPsGGYJYouF",
    "outputId": "db9fe012-c9bc-42b4-ac6f-873423be7aef"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd5iU1dnH8e8NrCxLb4qKsFiCFGmu\noIICagxijEHRiKtYQzRFjSkS+2tCXjXGXqJvokZFjBF7NMQAETsCoYioWECRjtIRWLjfP86zMCwz\nu7O7Mzs7O7/Pdc018zxz5sx5tsw9p5u7IyIiuatepgsgIiKZpUAgIpLjFAhERHKcAoGISI5TIBAR\nyXEKBCIiOU6BQFLKzOqb2Xoz65DKtJlkZgeaWcrHWZvZcWa2IOb4QzM7Kpm0VXivP5vZlVV9fTn5\n/s7MHk51vlKzGmS6AJJZZrY+5rAA2Axsi45/5O5jK5Ofu28DmqQ6bS5w986pyMfMLgTOcvdBMXlf\nmIq8pW5SIMhx7r7jgzj6xnmhu/87UXoza+DuJTVRNhGpGWoaknJFVf+/mdk4M1sHnGVmR5jZ22a2\n2syWmNmdZpYXpW9gZm5mhdHxY9HzL5vZOjN7y8w6VTZt9PwJZvaRma0xs7vM7A0zOzdBuZMp44/M\n7GMz+9rM7ox5bX0zu83MVpnZp8CQcn4+V5nZE2XO3WNmt0aPLzSzedH1fBJ9W0+U1yIzGxQ9LjCz\nR6OyzQUOLZP2ajP7NMp3rpl9Lzp/CHA3cFTU7LYy5md7fczrL4qufZWZPWtmeyfzs6mImQ2LyrPa\nzCaZWeeY5640s8VmttbMPoi51sPNbEZ0fpmZ/SHZ95MUcXfddMPdARYAx5U59ztgC3AS4YtDI+Aw\noB+hRrk/8BHw0yh9A8CBwuj4MWAlUATkAX8DHqtC2j2BdcDJ0XOXA1uBcxNcSzJlfA5oDhQCX5Ve\nO/BTYC7QHmgNTAn/KnHfZ39gPdA4Ju/lQFF0fFKUxoBjgE1Aj+i544AFMXktAgZFj28B/gO0BDoC\n75dJezqwd/Q7OTMqw17RcxcC/ylTzseA66PHx0dl7AXkA/cCk5L52cS5/t8BD0ePu0TlOCb6HV0J\nfBg97gYsBNpFaTsB+0eP3wVGRI+bAv0y/b+QazfVCCQZr7v7C+6+3d03ufu77v6Ou5e4+6fAA8DA\ncl7/lLtPc/etwFjCB1Bl034XmOnuz0XP3UYIGnElWcb/dfc17r6A8KFb+l6nA7e5+yJ3XwXcWM77\nfAq8RwhQAN8Gvnb3adHzL7j7px5MAiYCcTuEyzgd+J27f+3uCwnf8mPf90l3XxL9Th4nBPGiJPIF\nKAb+7O4z3f0bYDQw0Mzax6RJ9LMpzxnA8+4+Kfod3UgIJv2AEkLQ6RY1L34W/ewgBPSDzKy1u69z\n93eSvA5JEQUCScYXsQdmdrCZ/cPMlprZWuAGoE05r18a83gj5XcQJ0q7T2w53N0J36DjSrKMSb0X\n4ZtseR4HRkSPz4yOS8vxXTN7x8y+MrPVhG/j5f2sSu1dXhnM7FwzmxU1wawGDk4yXwjXtyM/d18L\nfA3sG5OmMr+zRPluJ/yO9nX3D4FfEH4Py6OmxnZR0vOArsCHZjbVzIYmeR2SIgoEkoyyQyfvJ3wL\nPtDdmwHXEpo+0mkJoakGADMzdv3gKqs6ZVwC7BdzXNHw1ieB48xsX0LN4PGojI2Ap4D/JTTbtAD+\nlWQ5liYqg5ntD9wHXAy0jvL9ICbfioa6LiY0N5Xm15TQBPVlEuWqTL71CL+zLwHc/TF3709oFqpP\n+Lng7h+6+xmE5r8/AuPNLL+aZZFKUCCQqmgKrAE2mFkX4Ec18J4vAn3M7CQzawBcCrRNUxmfBC4z\ns33NrDVwRXmJ3X0p8DrwMPChu8+PnmoI7AGsALaZ2XeBYytRhivNrIWFeRY/jXmuCeHDfgUhJv6Q\nUCMotQxoX9o5Hsc44AIz62FmDQkfyK+5e8IaViXK/D0zGxS9968I/TrvmFkXMxscvd+m6LadcAFn\nm1mbqAaxJrq27dUsi1SCAoFUxS+Acwj/5PcTOnXTyt2XAT8AbgVWAQcA/yXMe0h1Ge8jtOXPIXRk\nPpXEax4ndP7uaBZy99XAz4FnCB2uwwkBLRnXEWomC4CXgUdi8p0N3AVMjdJ0BmLb1V8B5gPLzCy2\niaf09f8kNNE8E72+A6HfoFrcfS7hZ34fIUgNAb4X9Rc0BG4m9OssJdRAropeOhSYZ2FU2i3AD9x9\nS3XLI8mz0NQqkl3MrD6hKWK4u7+W6fKIZDPVCCRrmNmQqKmkIXANYbTJ1AwXSyTrKRBINhkAfEpo\ndvgOMMzdEzUNiUiS1DQkIpLjVCMQEclxWbfoXJs2bbywsDDTxRARySrTp09f6e5xh1xnXSAoLCxk\n2rRpmS6GiEhWMbOEM+TT1jRkZvuZ2WQzez9ajfDSOGmKzWy2mc0xszfNrGe6yiMiIvGls0ZQAvzC\n3WdEU9inm9kr7v5+TJrPgIHu/rWZnUBYGKxfGsskIiJlpC0QuPsSwqxF3H2dmc0jrA3zfkyaN2Ne\n8jYxa8mIiEjNqJE+Agsbj/Rm12nwZV1AmEof7/WjgFEAHTrU6u1tReqcrVu3smjRIr755ptMF0WS\nkJ+fT/v27cnLS7TU1O7SHgjMrAkwHrgsWu42XprBhEAwIN7z7v4AodmIoqIiTXwQqUGLFi2iadOm\nFBYWEhZ9ldrK3Vm1ahWLFi2iU6dOFb8gktZ5BNEKhOOBse7+dII0PYA/AydHm4Ck3NixUFgI9eqF\n+7GV2o5dJLd98803tG7dWkEgC5gZrVu3rnTtLW01gmi9+L8A89z91gRpOgBPA2e7+0fpKMfYsTBq\nFGzcGI4XLgzHAMXVXm9RJDcoCGSPqvyu0lkj6A+cDRxjZjOj29Bo0+yLojTXEvaEvTd6PuUTBK66\namcQKLVxYzgvIiLpHTX0OhXsxOTuFxI22k6bzz+v3HkRqV1WrVrFsceG/XyWLl1K/fr1ads2TJCd\nOnUqe+yxR4V5nHfeeYwePZrOnTsnTHPPPffQokULilPQVDBgwADuvvtuevVKZqvnzMu6mcWV1aFD\naA6Kd15EUm/s2FDj/vzz8H82Zkz1mmFbt27NzJkzAbj++utp0qQJv/zlL3dJ4+64O/XqxW/keOih\nhyp8n5/85CdVL2SWq/OLzo0ZAwUFu54rKAjnRSS1SvvkFi4E9519cukYoPHxxx/TtWtXiouL6dat\nG0uWLGHUqFEUFRXRrVs3brjhhh1pBwwYwMyZMykpKaFFixaMHj2anj17csQRR7B8+XIArr76am6/\n/fYd6UePHk3fvn3p3Lkzb74Zpjxt2LCBU089la5duzJ8+HCKiop2BKlEHnvsMQ455BC6d+/OlVde\nCUBJSQlnn332jvN33nknALfddhtdu3alR48enHXWWSn/mSVS52sEpd9EUvkNRUTiK69PLh3/cx98\n8AGPPPIIRUVFANx44420atWKkpISBg8ezPDhw+natesur1mzZg0DBw7kxhtv5PLLL+fBBx9k9OjR\nu+Xt7kydOpXnn3+eG264gX/+85/cddddtGvXjvHjxzNr1iz69OlTbvkWLVrE1VdfzbRp02jevDnH\nHXccL774Im3btmXlypXMmTMHgNWrVwNw8803s3DhQvbYY48d52pCna8RQPgDXLAAtm8P9woCIulR\n031yBxxwwI4gADBu3Dj69OlDnz59mDdvHu+///5ur2nUqBEnnHACAIceeigLFiyIm/cpp5yyW5rX\nX3+dM844A4CePXvSrVu3csv3zjvvcMwxx9CmTRvy8vI488wzmTJlCgceeCAffvghl1xyCRMmTKB5\n8+YAdOvWjbPOOouxY8dWakJYdeVEIBCRmpGo7y1dfXKNGzfe8Xj+/PnccccdTJo0idmzZzNkyJC4\n4+ljO5fr169PSUlJ3LwbNmxYYZqqat26NbNnz+aoo47innvu4Uc/+hEAEyZM4KKLLuLdd9+lb9++\nbNu2LaXvm4gCgYikTCb75NauXUvTpk1p1qwZS5YsYcKECSl/j/79+/Pkk08CMGfOnLg1jlj9+vVj\n8uTJrFq1ipKSEp544gkGDhzIihUrcHdOO+00brjhBmbMmMG2bdtYtGgRxxxzDDfffDMrV65kY9l2\ntjSp830EIlJzMtkn16dPH7p27crBBx9Mx44d6d+/f8rf42c/+xkjR46ka9euO26lzTrxtG/fnt/+\n9rcMGjQId+ekk07ixBNPZMaMGVxwwQW4O2bGTTfdRElJCWeeeSbr1q1j+/bt/PKXv6Rp06Ypv4Z4\nsm7P4qKiItfGNCI1Z968eXTp0iXTxagVSkpKKCkpIT8/n/nz53P88cczf/58GjSoXd+p4/3OzGy6\nuxfFS1+7Si8iUoutX7+eY489lpKSEtyd+++/v9YFgarI/isQEakhLVq0YPr06ZkuRsqps1hEJMcp\nEIiI5DgFAhGRHKdAICKS4xQIRKRWGzx48G6Tw26//XYuvvjicl/XpEkTABYvXszw4cPjphk0aBAV\nDUe//fbbd5nYNXTo0JSsA3T99ddzyy23VDufVFAgEJFabcSIETzxxBO7nHviiScYMWJEUq/fZ599\neOqpp6r8/mUDwUsvvUSLFi2qnF9tpEAgIrXa8OHD+cc//sGWLVsAWLBgAYsXL+aoo47aMa6/T58+\nHHLIITz33HO7vX7BggV0794dgE2bNnHGGWfQpUsXhg0bxqZNm3aku/jii3csYX3dddcBcOedd7J4\n8WIGDx7M4MGDASgsLGTlypUA3HrrrXTv3p3u3bvvWMJ6wYIFdOnShR/+8Id069aN448/fpf3iWfm\nzJkcfvjh9OjRg2HDhvH111/veP/SZalLF7t79dVX6dWrF7169aJ3796sW7euyj/bUppHICLJu+wy\nqGD9/Urr1QuiD9F4WrVqRd++fXn55Zc5+eSTeeKJJzj99NMxM/Lz83nmmWdo1qwZK1eu5PDDD+d7\n3/tewn1777vvPgoKCpg3bx6zZ8/eZRnpMWPG0KpVK7Zt28axxx7L7NmzueSSS7j11luZPHkybdq0\n2SWv6dOn89BDD/HOO+/g7vTr14+BAwfSsmVL5s+fz7hx4/i///s/Tj/9dMaPH1/u/gIjR47krrvu\nYuDAgVx77bX8z//8D7fffjs33ngjn332GQ0bNtzRHHXLLbdwzz330L9/f9avX09+fn5lftpxpa1G\nYGb7mdlkM3vfzOaa2aVx0piZ3WlmH5vZbDMrf3FvEclJsc1Dsc1C7s6VV15Jjx49OO644/jyyy9Z\ntmxZwnymTJmy4wO5R48e9OjRY8dzTz75JH369KF3797MnTu3wgXlXn/9dYYNG0bjxo1p0qQJp5xy\nCq+99hoAnTp12rFNZXlLXUPYH2H16tUMHDgQgHPOOYcpU6bsKGNxcTGPPfbYjhnM/fv35/LLL+fO\nO+9k9erVKZnZnM4aQQnwC3efYWZNgelm9oq7x/50TwAOim79gPuiexGpjcr55p5OJ598Mj//+c+Z\nMWMGGzdu5NBDDwVg7NixrFixgunTp5OXl0dhYWHcpacr8tlnn3HLLbfw7rvv0rJlS84999wq5VOq\ndAlrCMtYV9Q0lMg//vEPpkyZwgsvvMCYMWOYM2cOo0eP5sQTT+Sll16if//+TJgwgYMPPrjKZYU0\n1gjcfYm7z4gerwPmAfuWSXYy8IgHbwMtzGzvdJVJRLJTkyZNGDx4MOeff/4uncRr1qxhzz33JC8v\nj8mTJ7Mw3gblMY4++mgef/xxAN577z1mz54NhCWsGzduTPPmzVm2bBkvv/zyjtc0bdo0bjv8UUcd\nxbPPPsvGjRvZsGEDzzzzDEcddVSlr6158+a0bNlyR23i0UcfZeDAgWzfvp0vvviCwYMHc9NNN7Fm\nzRrWr1/PJ598wiGHHMIVV1zBYYcdxgcffFDp9yyrRvoIzKwQ6A28U+apfYEvYo4XReeWlHn9KGAU\nQAftOi+Sk0aMGMGwYcN2GUFUXFzMSSedxCGHHEJRUVGF34wvvvhizjvvPLp06UKXLl121Cx69uxJ\n7969Ofjgg9lvv/12WcJ61KhRDBkyhH322YfJkyfvON+nTx/OPfdc+vbtC8CFF15I7969y20GSuSv\nf/0rF110ERs3bmT//ffnoYceYtu2bZx11lmsWbMGd+eSSy6hRYsWXHPNNUyePJl69erRrVu3Hbut\nVUfal6E2sybAq8AYd3+6zHMvAje6++vR8UTgCndPOLBXy1CL1CwtQ519KrsMdVqHj5pZHjAeGFs2\nCES+BPaLOW4fnRMRkRqSzlFDBvwFmOfutyZI9jwwMho9dDiwxt2XJEgrIiJpkM4+gv7A2cAcMysd\neHwl0AHA3f8EvAQMBT4GNgLnpbE8IlJFpVsqSu1Xleb+tAWCqN2/3L8cDyX+SbrKICLVl5+fz6pV\nq2jdurWCQS3n7qxatarSk8w0s1hEytW+fXsWLVrEihUrMl0USUJ+fj7t27ev1GsUCESkXHl5eXTq\n1CnTxZA00qJzIiI5ToFARCTHKRCIiOQ4BQIRkRynQCAikuMUCEREclxOB4KxY6GwEOrVC/djx2a6\nRCIiNS9n5xGMHQujRkHpntQLF4ZjgOLizJVLRKSm5WyN4KqrdgaBUhs3hvMiIrkkZwPB559X7ryI\nSF2Vs4Eg0UZn2gBNRHJNzgaCMWOgoGDXcwUF4byISC7J2UBQXAwPPAAdO4JZuH/gAXUUi0juydlR\nQxA+9PXBLyK5LmdrBCIiEqRzz+IHzWy5mb2X4PnmZvaCmc0ys7lmpm0qRUQyIJ01goeBIeU8/xPg\nfXfvCQwC/mhme6SxPCIiEkfaAoG7TwG+Ki8J0NTCJqhNorQl6SqPiIjEl8nO4ruB54HFQFPgB+6+\nPYPlERHJSZnsLP4OMBPYB+gF3G1mzeIlNLNRZjbNzKZpA20RkdTKZCA4D3jag4+Bz4CD4yV09wfc\nvcjdi9q2bVujhRQRqesyGQg+B44FMLO9gM7Ap2l9x40bwT2tbyEikm3SOXx0HPAW0NnMFpnZBWZ2\nkZldFCX5LXCkmc0BJgJXuPvKdJWHv/0NmjcP602LiMgOaessdvcRFTy/GDg+Xe+/my5doKQEpkwJ\nu9CIiAiQSzOLu3eHFi3gtdcyXRIRkVoldwJBvXpw1FGhRlAObV8pIrkmdwIBhEDw0UewdGncp0u3\nr1y4MPQpl25fqWAgInVZbgWCo48O9wmah7R9pYjkotwKBH36hN1nEjQPaftKEclFuRUI8vLgyCMT\nBgJtXykiuSi3AgGE5qE5c+Cr3dfD0/aVIpKLcjMQuMMbb+z2lLavFJFclHuBoG9f2GOPhB3GxcWw\nYAFs3x7uFQREpK7LvUDQqFEIBhXMJxARyRW5FwggNA9Nnw7r12e6JCIiGZe7gaCkBN5+O9MlERHJ\nuNwMBEceGdaQUPOQiEiOBoKmTaF376QDgdYfEpG6LDcDAYTmobffhs2by02m9YdEpK7L7UCweTO8\n+265ybT+kIjUdbkbCAYMCPcVNA9p/SERqetyNxC0aQPdulW4UY3WHxKRui6dexY/aGbLzey9ctIM\nMrOZZjbXzF5NV1kSOvrosNRESUnCJFp/SETqunTWCB4GhiR60sxaAPcC33P3bsBpaSxLfEcfDevW\nwcyZCZNo/SERqevSuXn9FDMrLCfJmcDT7v55lH55usqS0ODBYUzos89CUVHCZMXF+uAXkbork30E\n3wJamtl/zGy6mY1MlNDMRpnZNDObtmLFitSVYK+94NvfhkcfDavMiYjkoEwGggbAocCJwHeAa8zs\nW/ESuvsD7l7k7kVt27ZNbSlGjgxDgCroNBYRqasyGQgWARPcfYO7rwSmAD1rvBTf/z40aQKPPFKp\nl2m2sYjUFZkMBM8BA8ysgZkVAP2AeTVeioICGD4c/v532LQpqZdotrGI1CXpHD46DngL6Gxmi8zs\nAjO7yMwuAnD3ecA/gdnAVODP7p5wqGlajRwZRg8991xSyTXbWETqEnP3TJehUoqKinzatGmpzXT7\n9tC+0707vPRShcnr1Qs1gbLM1OcsIrWTmU1397jDI3N3ZnGsevXgrLPgX/+CpUsrTK7ZxiJSlygQ\nlDr7bNi2DcaNqzCpZhuLSF2iQFCqS5cwqezRRytMqtnGIlKXKBDEGjkS/vtfeK/iPuviYliwIPQJ\nLFgQjjWkVESykQJBrDPOgAYNkqoVlKUhpSKSrRQIYrVtCyecAI89FvoLKkFDSkUkWykQlDVyJCxe\nDJMmVepl2sBGRLKVAkFZ3/1u2LTmj3+s1Ms0pFREspUCQVn5+TB6NEyYUKmF6DSkVESylQJBPBdf\nDHvvDVdfHX8KcRyJhpSCRhKJSO2mQBBPQUHo5Z0yBSZOTPplZYeUgkYSiUjtp7WGEtm8Gb71LWjX\nDt5+O3zNr6TCwvDhX1bHjjsDhYhITaj2WkNmdqmZNbPgL2Y2w8yOT20xa5mGDeHaa2HqVHjxxSpl\noZFEIpINkm0aOt/d1wLHAy2Bs4Eb01aq2mLkSDjwQLjmmiotK6qRRCKSDZINBKXtIkOBR919bsy5\nuisvD66/HmbNgvHjK/1yjSQSkWyQbCCYbmb/IgSCCWbWFMiNlffPOAO6dg3NRJWcbVze4nRal0hE\naoukOovNrB7QC/jU3VebWSugvbvPTncBy6qxzuJY48eH7SwffhjOOafa2ZWuSxS7JEVBgVYwFZH0\nScXGNEcAH0ZB4CzgamBNqgpY6w0bBocdBj//efxhQJWkdYlEpDZJNhDcB2w0s57AL4BPgEfKe4GZ\nPWhmy82s3DWdzewwMysxs+FJlqXm1asHjz8emoZOPx22bKlWdhpNJCK1SbKBoMRDG9LJwN3ufg/Q\ntILXPAwMKS+BmdUHbgL+lWQ5MufAA+Ghh8Jw0l/9qlpZaTSRiNQmyQaCdWb2G8Kw0X9EfQZ55b3A\n3acAX1WQ78+A8cDyJMuRWaecApddBnfeCU89VeVsEo0mGjpUHcgiUvOSDQQ/ADYT5hMsBdoDf6jO\nG5vZvsAwQrNTRWlHmdk0M5u2YsWK6rxt9d10Exx+OJx/PsyfX6Us4o0mOucc+OtftRyFiNS8pJeY\nMLO9gMOiw6nuXuG3eDMrBF509+5xnvs78Ed3f9vMHo7SVfg1OyOjhsr6/HPo3Rv22w/eegsaNap2\nllqOQkTSKRVLTJwOTAVOA04H3klB524R8ISZLQCGA/ea2fermWfN6NAh7GI2a1ZYqTQF6zWpA1lE\nMiXZpqGrgMPc/Rx3Hwn0Ba6pzhu7eyd3L3T3QuAp4Mfu/mx18qxRJ5wA110X2nOuuKLawSBRR3Gr\nVuo3EJH0apBkunplmoJWUUEQMbNxwCCgjZktAq4j6mB29z9Vvqi10HXXwfLl8Ic/QMuW8JvfVDmr\nMWN2n2SWlwfr1sGqVeG4tN8ANPFMRFIn2UDwTzObAIyLjn8AvFTeC9x9RLKFcPdzk01bq5jB3XfD\nmjVw5ZXQvDn8+MdVyqr0g/2qq0JzUIcOsH79ziBQqnTimQKBiKRKZTqLTwX6R4evufszaStVOWpF\nZ3FZW7fCqafCCy+EvoMUfUrXqxe/xcmsSouhikgOS8USE7j7eHe/PLplJAjUWnl58OSTMGhQGAf6\n/PMpyVb9BiJSEypq519nZmvj3NaZ2dqaKmRWyM8PAaBPHzjtNHim+rEy3sSz0n4DzTcQkVQpNxC4\ne1N3bxbn1tTdm9VUIbNG06YwYUIIBsOHhxFF1RBv4lmzZrsvdaQF60SkOrR5faq1bAmvvALHHAPn\nnhuWo6iG4uIwoWz79nD/VYJFOzTfQESqSoEgHZo0CfscDxsGl14KN9yQkklnoH4DEUk9BYJ0adgw\ndCCfc06Yb3D55SkZ6qN+AxFJNQWCdGrQAB58MNQKbr8dTjwxcdtOktRvICKppkCQbvXqwW23wX33\nwcSJcOihMGNGtbJMtt9g4UI1F4lIxRQIaoIZXHQRvPYalJTAkUeGmkKKJOo3MFNzkYhUTIGgJvXr\nF2oDAwbABRfAD38ImzdXO9t4/QZmu/dPq7lIROJRIKhpbduGuQa/+Q38+c9w0klhUaFqiNdvkGiQ\nkpqLRKQsBYJMqF8ffv/7sAfyxInw7W+npBM5tt+gY8f46dRcJCJlKRBk0rnnwvjxoblo4EBYvDhl\nWau5SESSpUCQad//Prz8cvgaP2AAfPJJSrKtTHORZiWL5DYFgtrgmGNg0iRYuxb694cpU1KSbbLN\nRR06hOYh9R2I5CYFgtrisMPC8NJGjUIz0ZlnwqJFKX2LeM1FBQUwdGjoK1DfgUhuUiCoTbp0gblz\nw5IUzzwDnTuHTuVvvklJ9vGaix54AF56adctMkF9ByK5JG2BwMweNLPlZvZegueLzWy2mc0xszfN\nrGe6ypJVCgrg+uth3jw44YTwadytGzzxRJiMVk1lm4uKixP3EWioqUhuSGeN4GFgSDnPfwYMdPdD\ngN8CD6SxLNmnsBCeegr+/e/QXDRiRKgh3HsvbNqU0rfSzGSR3Ja2QODuU4CEg+Pd/U13/zo6fBto\nn66yZLVjj4XZs0NT0Z57wk9+Etp0fve7as89KFWZoaaXXqpagkhdU1v6CC4AXk70pJmNMrNpZjZt\nxYoVNVisWqJevTDM9M034dVXQ8fyNdfAQQfB/ffDtm3Vyr4yQ01XrVItQaSuMU/RhilxMzcrBF50\n9+7lpBkM3AsMcPdVFeVZVFTk06ZNS1kZs9asWeHr+auvQlFRaDI67LCUZV9YGD7ok9GxY+hvEJHa\ny8ymu3tRvOcyWiMwsx7An4GTkwkCEqNnT5g8OXwd//LLsKDdqFGwcmVKso/XXJSIOpVFslvGAoGZ\ndQCeBs52948yVY6sZhbmG3zwAfz852Fp6wMPDMNPv/664teXI15zUevWiYuh5iKR7JW2piEzGwcM\nAtoAy4DrgDwAd/+Tmf0ZOBUobYAoSVRtiaWmoXLMnQvXXgtPPw1Nm8Ill4QAkegTvJLGjg0f8rFz\nDuJ1KoOai0Rqm/KahtLaR5AOCgRJmD0bfvvbMPy0SZMQEH75S2jZstpZjx0bpjZ8/nkYdlpeP0LH\njjvTjRkTahkikhm1to9A0raH0c8AABLXSURBVKRHD/j732HOnLB+xP/+LxxwAPzhD9Weg6DlrkXq\nHgWCuqx7d/jb38Iy1/36wa9/Dd/6VuhLSMEsZdAcBJG6QIEgF/TqFZa6njQJ9tknbJPZowfccQcs\nW1atrDUHQST7KRDkksGD4e23Q99Bfj5cdhnsu29oPnr8cdiwoUrZJttcVFbpwnZaAlsksxQIco0Z\nnHpqaC56773QXDR3bvg0b9cOzj8f3ngj8df6JFR2DoKWwBbJLAWCXNatW1jm+rPP4D//gdNPD53M\nAwbAwQfDTTfBkiWVzrYycxDq14+/BLb6E0RqjoaPyq7Wrw9NR3/5C7z+evikHjo09CsMHQp5eVXK\nNt4chIKC3YNAIgUFIbhoCKpI1Wj4qCSvSRM499ywW9qHH4b5B+++Gxa922+/0JT0wQeVzjbRpjiV\n6U9QLUEkPVQjkIqVlIRRR3/5C7z4Yljt9MgjQ8A4/XRo3rzKWcerKSRLtQSR5KlGINXToAGcdBI8\n+2zYR/nmm2H16vAJ3q5dWO/oX/+q0nLYlelPKEu1BJHUUI1AqsYdpk2Dv/41DD39+mto2xYGDQrD\nVI85JkxeM6t01qoliKSe1hqS9Nq8GV54IdwmTQq1BoC994bjjgv9C9/5DjRunHSWZdc0Wr8+TEhL\nhha8E9mdAoHUHHf45JOwV8KkSfDKK+ETvFEjGDIETjkFvvtdaNGiUtlWtpagBe9EdqVAIJlTUhJG\nID39dLgtXhyGpPbtG/ZjPvZYOOIIaNiwwqySrSWUXetIzUUiCgRSW2zfHoaiPv88TJwYHm/fHmoL\n/fvDIYeEfZgPOij0L7RvH3qBE6jM/gitW4eRsaolSK5SIJDaac2asOfyxIkwZUqYtxC7THZ+fuh8\nPvPM0M/QtOluWVRmf4RYqiVIrlEgkOywfXtoOpo/P9zefz8MWV24MASFk04KQaF799BB/c034X7z\n5jDZ7cADKSxMPhh07BhqBrGBRDUFqasUCCR7bd8eVkx9/HF48klYsSJx2kGDeL3bjzjpwWGs3lRx\nnwPsvsyFagpSV2UkEJjZg8B3geXu3j3O8wbcAQwFNgLnuvuMivJVIMhhJSVhNNKyZaFzOfb2zjtw\n//3w2Wd806wtD3Me96w9m00dOrN6Q17cTuX69ePPgVN/gtRFmQoERwPrgUcSBIKhwM8IgaAfcIe7\n96soXwUCSWj79jBc9U9/CnMatm2D+vVZ26YTb604iA+2H8SHdGYaRcxv1LNStYZzzoGXXlJwkOyV\nsaYhMysEXkwQCO4H/uPu46LjD4FB7l7uuscKBJKUL7+Ef/879DV89BFfTZ1Pw8/n09jD5jvb6ufx\nXv2evLHlMN7lMGbSi3l0YTP5cbPTkFTJdrU1ELwI3Ojur0fHE4Er3H23T3kzGwWMAujQocOhC5Pt\nDRSJ5Q5ffBGWxpg6laUvvEvB++/SjHUAlFCfDziY2fRgDofwFa3YSt4ut800ZBON2EQj8pvnY40b\nMXXxfrTu2ES1BKnVygsEDWq6MFXh7g8AD0CoEWS4OJKtzEK7TocOcMoptLsRxj66nb+Mnk/bxbMY\n0Gw239o0i/5b3+BMxlWc35pw20gjnlo4nEcuuIA3Xj+al142NSFJVslkIPgS2C/muH10TqTGFJ9d\nj+KzOwOdgdMZOxa6joL6G9fShPXksZU92EqDqE7QkM00YhP5fEMjNlHARgbyKiMYx8jNj/Lxnw6g\nJefxHCezamFrLvthM/ACis+q/OJ7IjUlk01DJwI/ZWdn8Z3u3reiPNVHIOlWdpLa0KFhkdXy1jlq\nxEZO4WnO50GOYfIuz22jHuvrNWPZ9rbMbdyXfU/rT9+f9w9bhdavn+arEQkyNWpoHDAIaAMsA64D\n8gDc/U/R8NG7gSGE4aPnxesfKEuBQDKhMquhduJTDudtmrF2l1t7FnEkb9KOZSFhs2Zw2GFhY5+G\nDcOkudL7Vq3Cst577hlubduGdAUF4dYgK1p1pRbRhDKRFKvMOke7cjrxGSe3foPbTnsTZsyADRt2\nnSm9aVOINOXJywsBYa+94MADw+2gg8L9t761c7cekYgCgUgaVKUJKVa5S2Vv2RJmUa9YAcuXh9u6\ndSHz0tuGDbBkCXz8cRgmu2HDztfn50PnztC1K3TpAgcfHILEAQeEmkhZX30V8vnssxCEyi7h0atX\nWEY8P/7wWqn9FAhEakh1l8qGKq595B5mXM+fHxbvmzdv563sLj1t2oSg0K5d2ETo44/D1qMVadIk\nrPd02mkhKDRqlETBMsg9TDJUPwygQCCSMZVdKnvTpt3XPqr2rOaNG+Gjj8KGQaW3jz8OtYlosT4O\nOCDcd+q0a59Ffn4o8OTJ8NRT8MwzIbI1aQIDB0JR0c5bu3a7vu+GDbByZUi/dm2o0axdG24bNoR8\nS2/16oXbHnvs7Ctp2DAcL14cylta7k8/DUuWX3stHH/87tuhusNzz8E114S0F14Il18eqmA5TIFA\nJIOqulR2qVo1q3nrVvjPf0JQeP31UOMoLdy++4ZgUNqkFbukeHXl5cH++4dg1aEDvPhimBzYrx9c\nf33YChVgwoQQAKZNC30lhx4Kf/97KOOIEfDrX4cg4h6CxIwZMH16uI769UMtJz8/3DduHEZ2HXFE\neN/K7r+9aVMIhCtWhPuVK0MVsXlzaNky7NLXsmX4BtCqVeJ83GHu3DBTvlevsDR7FSgQiNQilVkq\nO5FaszDe+vUwc2b44J02LXz7b9t211vr1uHDr2nT0D/RrFmIZqURbvv2nfdbtoS+idj+iXbtwiZF\nsU08mzfDww/D738ffgh9+4Zg8cYb4Qd83XVw1llhdNXnn8Ptt4fouWED9O4d+kJKm8Py8kJ/ilmo\nPW3atLPDfuvWkKZ1azj88HArLAzXEnv76qvwYf3eezvvly1L/ue4997Qs2f4oO/VKwSxWbPCh/+/\n/70zr1/9Cm6+uUq/KgUCkVokXnNRQUH4EppoSGpFcnZhvC1bQg/9738fPrSvvhrOPz80KZX11Vdw\n771hYcIuXaBPn1Bj6N49/lap27aFmsLbb8Nbb4X7998vvzyltYhu3UItYs89Q59M27bhvnHj0DT2\n9dchEK1eDUuXwpw5IaC+//7O4APh9ccdt3Nb12o0bykQiNQyZZuLxowJ56s2JDV+Wi2MlwZr1+4c\nwVXa77FuXagVdO8efpnVGba7ZUsIPh98EEZ8de9e+SapBBQIRLJEdYeklhWvCQm0K1suUiAQyWKV\nmdVckby88AVzy5ad51RzyA3lBQJNPRSp5YqLw1SA7dvD/R13hA/vWMm2HmzdumsQgFDbuOqqVJRU\nspUCgUiWKS4O3+A7dgwBoGNHuOii3YNDZXz+eah5lK5MUVgYjiU3KBCIZKGytYR77909OLRunXx+\nrVqFjuqFC0OH88KF4fjHP1ZwyAUKBCJ1RDJNSHl5u4+sLE1TtkN648aw/bOCQ92nQCBSR8VrQnro\nIXjwwV3PPfBAGGIfT9mxJAoOdZNGDYlItWc7x5vDkJMT3GoxjRoSkXKNGVP1kUigmkO2UyAQkaRH\nIqUjOCgYZF5aA4GZDTGzD83sYzMbHef5DmY22cz+a2azzWxoOssjIoklMxIpHcFBcxgyL22BwMzq\nA/cAJwBdgRFm1rVMsquBJ929N3AGcG+6yiMilVcTwSHRHAbNa6g56awR9AU+dvdP3X0L8ARwcpk0\nDpTum9ccWJzG8ohICqQ6OMSbw3DeeWERUfUx1Ix0BoJ9gS9ijhdF52JdD5xlZouAl4CfpbE8IpIm\nVQ0OieYwJFoKQx3Q6ZHpzuIRwMPu3h4YCjxqZruVycxGmdk0M5u2YsWKGi+kiFReMsGhvDkM8agD\nOj3SGQi+BPaLOW4fnYt1AfAkgLu/BeQDbcpm5O4PuHuRuxe1bds2TcUVkXQrGxyKi8Mcg+qIFxwu\nvVS1hMpIZyB4FzjIzDqZ2R6EzuDny6T5HDgWwMy6EAKBvvKL5JB4cxjiLYVRmQ7oVavUhFQZaQsE\n7l4C/BSYAMwjjA6aa2Y3mNn3omS/AH5oZrOAccC5nm1TnUWkWpJdCqM6o5PKa0LS6CQtMSEiWSQd\nO7ht2rT7/tF1cXkM7VAmInVWKndwK1UX93/WWkMiUmelcge3Usl2QNeVZiUFAhGpU5JdN6mgoHKb\n95TtgK5Lk97UNCQiOaFsE9KYMeH8qFG79hGUbRaqrNq6JLf6CEREEkh1B3Q8taHPQX0EIiIJpHr/\n53hq+6Q3BQIRkTKquv9zdSe9ZSoYKBCIiFSgpia9XXVVZpbkVh+BiEgKVbfPoaBg17R5eSGYxK7G\nWpU+BnUWi4hkULKT3urXh23bksuzY8fQbJUsdRaLiGRQMn0OBQXJBwEIQSVVFAhERGpYvD6H0uNk\nVXf57lgNUpeViIgkq7g4fht/2QluifoISifEpYJqBCIitUSyo5NSPRlNncUiIjlAncUiIpKQAoGI\nSI5TIBARyXEKBCIiOU6BQEQkx2XdqCEzWwEsrOLL2wArU1icTNP11F516Vqgbl1PXboWSP56Orp7\n23hPZF0gqA4zm5Zo+FQ20vXUXnXpWqBuXU9duhZIzfWoaUhEJMcpEIiI5LhcCwQPZLoAKabrqb3q\n0rVA3bqeunQtkILryak+AhER2V2u1QhERKQMBQIRkRyXM4HAzIaY2Ydm9rGZjc50eSrLzB40s+Vm\n9l7MuVZm9oqZzY/uW2ayjMkys/3MbLKZvW9mc83s0uh8tl5PvplNNbNZ0fX8T3S+k5m9E/3N/c3M\n9sh0WZNlZvXN7L9m9mJ0nM3XssDM5pjZTDObFp3L1r+1Fmb2lJl9YGbzzOyIVFxLTgQCM6sP3AOc\nAHQFRphZ18yWqtIeBoaUOTcamOjuBwETo+NsUAL8wt27AocDP4l+H9l6PZuBY9y9J9ALGGJmhwM3\nAbe5+4HA18AFGSxjZV0KzIs5zuZrARjs7r1ixttn69/aHcA/3f1goCfhd1T9a3H3On8DjgAmxBz/\nBvhNpstVhesoBN6LOf4Q2Dt6vDfwYabLWMXreg74dl24HqAAmAH0I8z2bBCd3+VvsDbfgPbRB8ox\nwIuAZeu1ROVdALQpcy7r/taA5sBnRIN8UnktOVEjAPYFvog5XhSdy3Z7ufuS6PFSYK9MFqYqzKwQ\n6A28QxZfT9SUMhNYDrwCfAKsdveSKEk2/c3dDvwa2B4dtyZ7rwXAgX+Z2XQzGxWdy8a/tU7ACuCh\nqNnuz2bWmBRcS64EgjrPw9eBrBoLbGZNgPHAZe6+Nva5bLsed9/m7r0I36b7AgdnuEhVYmbfBZa7\n+/RMlyWFBrh7H0LT8E/M7OjYJ7Pob60B0Ae4z917Axso0wxU1WvJlUDwJbBfzHH76Fy2W2ZmewNE\n98szXJ6kmVkeIQiMdfeno9NZez2l3H01MJnQfNLCzBpET2XL31x/4HtmtgB4gtA8dAfZeS0AuPuX\n0f1y4BlCoM7Gv7VFwCJ3fyc6fooQGKp9LbkSCN4FDopGPuwBnAE8n+EypcLzwDnR43MIbe21npkZ\n8BdgnrvfGvNUtl5PWzNrET1uROjvmEcICMOjZFlxPe7+G3dv7+6FhP+TSe5eTBZeC4CZNTazpqWP\ngeOB98jCvzV3Xwp8YWado1PHAu+TimvJdAdIDXa0DAU+IrTdXpXp8lSh/OOAJcBWwjeDCwhttxOB\n+cC/gVaZLmeS1zKAUH2dDcyMbkOz+Hp6AP+Nruc94Nro/P7AVOBj4O9Aw0yXtZLXNQh4MZuvJSr3\nrOg2t/R/P4v/1noB06K/tWeBlqm4Fi0xISKS43KlaUhERBJQIBARyXEKBCIiOU6BQEQkxykQiIjk\nOAUCkYiZbYtWqCy9pWwhMjMrjF05VqQ2aVBxEpGcscnDMhEiOUU1ApEKROvZ3xytaT/VzA6Mzhea\n2SQzm21mE82sQ3R+LzN7JtqfYJaZHRllVd/M/i/as+Bf0SxkzOySaG+G2Wb2RIYuU3KYAoHITo3K\nNA39IOa5Ne5+CHA3YXVOgLuAv7p7D2AscGd0/k7gVQ/7E/QhzGgFOAi4x927AauBU6Pzo4HeUT4X\npeviRBLRzGKRiJmtd/cmcc4vIGw882m0WN5Sd29tZisJ68Bvjc4vcfc2ZrYCaO/um2PyKARe8bB5\nCGZ2BZDn7r8zs38C6wlLBjzr7uvTfKkiu1CNQCQ5nuBxZWyOebyNnX10JxJ20OsDvBuzyqdIjVAg\nEEnOD2Lu34oev0lYoROgGHgtejwRuBh2bFjTPFGmZlYP2M/dJwNXEHah2q1WIpJO+uYhslOjaJex\nUv9099IhpC3NbDbhW/2I6NzPCLtF/Yqwc9R50flLgQfM7ALCN/+LCSvHxlMfeCwKFgbc6WFPA5Ea\noz4CkQpEfQRF7r4y02URSQc1DYmI5DjVCEREcpxqBCIiOU6BQEQkxykQiIjkOAUCEZEcp0AgIpLj\n/h+nBLlcCkpaxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_val_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahljEKwtfGW1"
   },
   "source": [
    "### 1.Tune structure of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kEC1wyqvHxMe"
   },
   "outputs": [],
   "source": [
    "def create_model(dropout_rate = 0.5,lr = 1e-2 ):\n",
    "    \n",
    "    #build model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optimizers.RMSprop(lr = lr),\n",
    "                metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0a8-JMIeJ3Tk"
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "model = KerasClassifier(build_fn = create_model, batch_size = 1000, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9FNP4AdKV8-"
   },
   "outputs": [],
   "source": [
    "lr = [1e-2, 1e-3, 1e-4]\n",
    "dropout_rate = [0.3, 0.5, 0.7]\n",
    "param_grid = dict(lr = lr, dropout_rate = dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WQYHh1eCUHj"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "grid = RandomizedSearchCV(estimator = model, cv = KFold(5), \n",
    "              param_distributions = param_grid,\n",
    "              verbose = 20, \n",
    "              n_iter = 10, n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YNZc942RCX3e",
    "outputId": "a170b374-efb1-48c5-d3be-1f30df34b93c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] lr=0.01, dropout_rate=0.3 .......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 7s 172us/step - loss: 3.7218 - acc: 0.1365\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.9680 - acc: 0.2621\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.7191 - acc: 0.3516\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.5314 - acc: 0.4310\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3763 - acc: 0.4901\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2357 - acc: 0.5499\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.1306 - acc: 0.5874\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0282 - acc: 0.6301\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9386 - acc: 0.6652\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8577 - acc: 0.6938\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7823 - acc: 0.7220\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7194 - acc: 0.7449\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6489 - acc: 0.7711\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6064 - acc: 0.7854\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5372 - acc: 0.8107\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4970 - acc: 0.8248\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4460 - acc: 0.8441\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4067 - acc: 0.8587\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3701 - acc: 0.8702\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3267 - acc: 0.8860\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2953 - acc: 0.8961\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2729 - acc: 0.9051\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2456 - acc: 0.9147\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2203 - acc: 0.9233\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2060 - acc: 0.9284\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1966 - acc: 0.9329\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1756 - acc: 0.9398\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1647 - acc: 0.9449\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1560 - acc: 0.9465\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1418 - acc: 0.9523\n",
      "10000/10000 [==============================] - 1s 66us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.3, score=0.717, total= 2.5min\n",
      "[CV] lr=0.01, dropout_rate=0.3 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 3.9443 - acc: 0.1132\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 2.0649 - acc: 0.2288\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.7534 - acc: 0.3351\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.5478 - acc: 0.4187\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.3766 - acc: 0.4897\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.2451 - acc: 0.5418\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.1397 - acc: 0.5880\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0400 - acc: 0.6236\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9427 - acc: 0.6612\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8605 - acc: 0.6952\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7815 - acc: 0.7242\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7110 - acc: 0.7496\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6548 - acc: 0.7688\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5890 - acc: 0.7923\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5423 - acc: 0.8082\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4779 - acc: 0.8322\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4377 - acc: 0.8472\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4025 - acc: 0.8597\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3582 - acc: 0.8752\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3296 - acc: 0.8841\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2904 - acc: 0.9002\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2677 - acc: 0.9069\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2390 - acc: 0.9174\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2234 - acc: 0.9236\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2038 - acc: 0.9323\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1894 - acc: 0.9351\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1757 - acc: 0.9395\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1587 - acc: 0.9471\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1563 - acc: 0.9467\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1375 - acc: 0.9535\n",
      "10000/10000 [==============================] - 1s 73us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.3, score=0.674, total= 2.5min\n",
      "[CV] lr=0.01, dropout_rate=0.3 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 3.4553 - acc: 0.1232\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 2.0526 - acc: 0.2014\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.8214 - acc: 0.3031\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.6079 - acc: 0.3902\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.4438 - acc: 0.4636\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2950 - acc: 0.5240\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1650 - acc: 0.5759\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0588 - acc: 0.6190\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9609 - acc: 0.6562\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8777 - acc: 0.6885\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8060 - acc: 0.7167\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7386 - acc: 0.7393\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6699 - acc: 0.7666\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6140 - acc: 0.7861\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5618 - acc: 0.8048\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5135 - acc: 0.8216\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4657 - acc: 0.8355\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4167 - acc: 0.8541\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3711 - acc: 0.8696\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3428 - acc: 0.8795\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3104 - acc: 0.8914\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2837 - acc: 0.9000\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2537 - acc: 0.9121\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2233 - acc: 0.9222\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2169 - acc: 0.9260\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1976 - acc: 0.9316\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1708 - acc: 0.9417\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1723 - acc: 0.9405\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1614 - acc: 0.9462\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1378 - acc: 0.9540\n",
      "10000/10000 [==============================] - 1s 80us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.3, score=0.587, total= 2.5min\n",
      "[CV] lr=0.01, dropout_rate=0.3 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 3.8744 - acc: 0.1217\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 2.0676 - acc: 0.2274\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.7553 - acc: 0.3373\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.5420 - acc: 0.4272\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3728 - acc: 0.4937\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.2364 - acc: 0.5464\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.1182 - acc: 0.5974\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0120 - acc: 0.6369\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9194 - acc: 0.6726\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8378 - acc: 0.7031\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7610 - acc: 0.7327\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6933 - acc: 0.7566\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6309 - acc: 0.7797\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5707 - acc: 0.7983\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5162 - acc: 0.8182\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4613 - acc: 0.8400\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4165 - acc: 0.8528\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3800 - acc: 0.8660\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3282 - acc: 0.8833\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3052 - acc: 0.8943\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2677 - acc: 0.9065\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2470 - acc: 0.9137\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2283 - acc: 0.9215\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2110 - acc: 0.9280\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1933 - acc: 0.9322\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1764 - acc: 0.9405\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1596 - acc: 0.9459\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1537 - acc: 0.9481\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1450 - acc: 0.9510\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1382 - acc: 0.9537\n",
      "10000/10000 [==============================] - 1s 89us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.3, score=0.651, total= 2.5min\n",
      "[CV] lr=0.01, dropout_rate=0.3 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 10.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 7s 168us/step - loss: 3.4886 - acc: 0.1313\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 2.0062 - acc: 0.2288\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.7778 - acc: 0.3262\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.5477 - acc: 0.4200\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3902 - acc: 0.4852\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2614 - acc: 0.5388\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1428 - acc: 0.5823\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0414 - acc: 0.6221\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9457 - acc: 0.6627\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8648 - acc: 0.6905\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7827 - acc: 0.7237\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7189 - acc: 0.7449\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6439 - acc: 0.7743\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5928 - acc: 0.7909\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5377 - acc: 0.8109\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4949 - acc: 0.8262\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4410 - acc: 0.8446\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3970 - acc: 0.8601\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3624 - acc: 0.8743\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3290 - acc: 0.8852\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2887 - acc: 0.8976\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2653 - acc: 0.9078\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2372 - acc: 0.9173\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2230 - acc: 0.9227\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1949 - acc: 0.9326\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1828 - acc: 0.9370\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1753 - acc: 0.9395\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1595 - acc: 0.9453\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1537 - acc: 0.9478\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1419 - acc: 0.9521\n",
      "10000/10000 [==============================] - 1s 95us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.3, score=0.722, total= 2.5min\n",
      "[CV] lr=0.001, dropout_rate=0.3 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 7s 170us/step - loss: 1.7617 - acc: 0.3667\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3208 - acc: 0.5113\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1434 - acc: 0.5839\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0047 - acc: 0.6383\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8993 - acc: 0.6797\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8159 - acc: 0.7096\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7538 - acc: 0.7297\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6799 - acc: 0.7586\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6154 - acc: 0.7843\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5692 - acc: 0.7992\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5111 - acc: 0.8196\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4703 - acc: 0.8352\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4337 - acc: 0.8453\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3936 - acc: 0.8601\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3583 - acc: 0.8734\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3242 - acc: 0.8846\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2917 - acc: 0.8966\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2665 - acc: 0.9056\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2512 - acc: 0.9101\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2212 - acc: 0.9211\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2105 - acc: 0.9274\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1964 - acc: 0.9310\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1730 - acc: 0.9399\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1641 - acc: 0.9430\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1515 - acc: 0.9479\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1400 - acc: 0.9513\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1294 - acc: 0.9542\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1400 - acc: 0.9522\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1105 - acc: 0.9616\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1138 - acc: 0.9619\n",
      "10000/10000 [==============================] - 1s 102us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.3, score=0.730, total= 2.5min\n",
      "[CV] lr=0.001, dropout_rate=0.3 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 15.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 7s 175us/step - loss: 1.7776 - acc: 0.3620\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3387 - acc: 0.5083\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1658 - acc: 0.5749\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0347 - acc: 0.6260\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9343 - acc: 0.6655\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8383 - acc: 0.7011\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7660 - acc: 0.7284\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6966 - acc: 0.7524\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6434 - acc: 0.7743\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5844 - acc: 0.7943\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5400 - acc: 0.8098\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4882 - acc: 0.8260\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4562 - acc: 0.8370\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4078 - acc: 0.8544\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3728 - acc: 0.8696\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3449 - acc: 0.8787\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3101 - acc: 0.8903\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2923 - acc: 0.8934\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2618 - acc: 0.9062\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2365 - acc: 0.9160\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2147 - acc: 0.9243\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1951 - acc: 0.9318\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1926 - acc: 0.9345\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1675 - acc: 0.9420\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1698 - acc: 0.9407\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1513 - acc: 0.9481\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1399 - acc: 0.9516\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1311 - acc: 0.9548\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1252 - acc: 0.9562\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1254 - acc: 0.9567\n",
      "10000/10000 [==============================] - 1s 112us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.3, score=0.742, total= 2.5min\n",
      "[CV] lr=0.001, dropout_rate=0.3 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 17.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 1.7747 - acc: 0.3655\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3295 - acc: 0.5087\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1461 - acc: 0.5835\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0218 - acc: 0.6319\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9187 - acc: 0.6707\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8336 - acc: 0.7041\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7651 - acc: 0.7280\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6879 - acc: 0.7553\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6356 - acc: 0.7730\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5871 - acc: 0.7913\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5249 - acc: 0.8137\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5007 - acc: 0.8232\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4464 - acc: 0.8405\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4023 - acc: 0.8547\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3642 - acc: 0.8699\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3435 - acc: 0.8774\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3139 - acc: 0.8887\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2756 - acc: 0.9007\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2555 - acc: 0.9090\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2349 - acc: 0.9162\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2145 - acc: 0.9241\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1950 - acc: 0.9303\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1838 - acc: 0.9335\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1704 - acc: 0.9406\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1604 - acc: 0.9439\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1466 - acc: 0.9504\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1382 - acc: 0.9518\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1393 - acc: 0.9529\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1130 - acc: 0.9624\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1188 - acc: 0.9595\n",
      "10000/10000 [==============================] - 1s 130us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.3, score=0.675, total= 2.6min\n",
      "[CV] lr=0.001, dropout_rate=0.3 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 20.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 1.7716 - acc: 0.3596\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3365 - acc: 0.5076\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1488 - acc: 0.5830\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0286 - acc: 0.6276\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9252 - acc: 0.6685\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8329 - acc: 0.7040\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7625 - acc: 0.7276\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7002 - acc: 0.7482\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6393 - acc: 0.7721\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5948 - acc: 0.7885\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5341 - acc: 0.8095\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4977 - acc: 0.8236\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4515 - acc: 0.8381\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4128 - acc: 0.8525\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3752 - acc: 0.8660\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3355 - acc: 0.8787\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3107 - acc: 0.8890\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2751 - acc: 0.9020\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2621 - acc: 0.9073\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2258 - acc: 0.9213\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2305 - acc: 0.9181\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1974 - acc: 0.9314\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1794 - acc: 0.9363\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1793 - acc: 0.9375\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1619 - acc: 0.9435\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1419 - acc: 0.9510\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1445 - acc: 0.9511\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1295 - acc: 0.9547\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1271 - acc: 0.9580\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1183 - acc: 0.9604\n",
      "10000/10000 [==============================] - 1s 133us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.3, score=0.651, total= 2.5min\n",
      "[CV] lr=0.001, dropout_rate=0.3 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 22.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.7495 - acc: 0.3740\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3097 - acc: 0.5202\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1284 - acc: 0.5919\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0001 - acc: 0.6375\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8896 - acc: 0.6836\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8161 - acc: 0.7091\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7439 - acc: 0.7333\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6772 - acc: 0.7579\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6254 - acc: 0.7776\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5710 - acc: 0.7985\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5134 - acc: 0.8172\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4779 - acc: 0.8293\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4229 - acc: 0.8497\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3936 - acc: 0.8584\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3614 - acc: 0.8731\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3283 - acc: 0.8822\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2906 - acc: 0.8978\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2655 - acc: 0.9066\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2532 - acc: 0.9109\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2233 - acc: 0.9213\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2090 - acc: 0.9260\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1935 - acc: 0.9331\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1755 - acc: 0.9398\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1747 - acc: 0.9405\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1609 - acc: 0.9437\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1399 - acc: 0.9503\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1318 - acc: 0.9539\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1255 - acc: 0.9568\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1245 - acc: 0.9589\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1187 - acc: 0.9598\n",
      "10000/10000 [==============================] - 1s 135us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.3, score=0.704, total= 2.6min\n",
      "[CV] lr=0.0001, dropout_rate=0.3 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 25.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.9265 - acc: 0.3120\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5916 - acc: 0.4207\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.4338 - acc: 0.4764\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3342 - acc: 0.5133\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2666 - acc: 0.5413\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2051 - acc: 0.5643\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1544 - acc: 0.5846\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1084 - acc: 0.6020\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0682 - acc: 0.6184\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0302 - acc: 0.6324\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9965 - acc: 0.6451\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9660 - acc: 0.6564\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9331 - acc: 0.6697\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9052 - acc: 0.6787\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8758 - acc: 0.6875\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8477 - acc: 0.6998\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8262 - acc: 0.7069\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8019 - acc: 0.7177\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7748 - acc: 0.7276\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7529 - acc: 0.7345\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7271 - acc: 0.7417\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7123 - acc: 0.7474\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6881 - acc: 0.7576\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6666 - acc: 0.7651\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6499 - acc: 0.7705\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6280 - acc: 0.7790\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6072 - acc: 0.7864\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5928 - acc: 0.7895\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5731 - acc: 0.7987\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5574 - acc: 0.8027\n",
      "10000/10000 [==============================] - 1s 145us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.3, score=0.664, total= 2.6min\n",
      "[CV] lr=0.0001, dropout_rate=0.3 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed: 27.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 1.8947 - acc: 0.3117\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5688 - acc: 0.4282\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.4233 - acc: 0.4829\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3270 - acc: 0.5207\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2549 - acc: 0.5442\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1956 - acc: 0.5708\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1428 - acc: 0.5897\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0975 - acc: 0.6059\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0556 - acc: 0.6205\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0219 - acc: 0.6325\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9849 - acc: 0.6493\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9568 - acc: 0.6599\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9229 - acc: 0.6702\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8965 - acc: 0.6795\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8659 - acc: 0.6928\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8407 - acc: 0.7031\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8169 - acc: 0.7119\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7922 - acc: 0.7165\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7721 - acc: 0.7256\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7525 - acc: 0.7333\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7255 - acc: 0.7408\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7059 - acc: 0.7498\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6829 - acc: 0.7562\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6695 - acc: 0.7605\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6457 - acc: 0.7724\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6310 - acc: 0.7760\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6118 - acc: 0.7833\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5952 - acc: 0.7884\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5705 - acc: 0.7965\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5620 - acc: 0.8003\n",
      "10000/10000 [==============================] - 2s 157us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.3, score=0.658, total= 2.6min\n",
      "[CV] lr=0.0001, dropout_rate=0.3 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 30.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 1.9208 - acc: 0.3064\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.5603 - acc: 0.4353\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.4048 - acc: 0.4903\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.2984 - acc: 0.5314\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.2136 - acc: 0.5646\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1558 - acc: 0.5847\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0972 - acc: 0.6068\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0519 - acc: 0.6218\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0122 - acc: 0.6393\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9677 - acc: 0.6548\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9326 - acc: 0.6688\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8997 - acc: 0.6825\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8683 - acc: 0.6918\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8358 - acc: 0.7064\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8139 - acc: 0.7123\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7869 - acc: 0.7204\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7600 - acc: 0.7321\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7363 - acc: 0.7394\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7158 - acc: 0.7469\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6897 - acc: 0.7579\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6680 - acc: 0.7635\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6458 - acc: 0.7740\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6240 - acc: 0.7802\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6047 - acc: 0.7872\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5874 - acc: 0.7945\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5668 - acc: 0.8008\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5468 - acc: 0.8076\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5265 - acc: 0.8152\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5051 - acc: 0.8224\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4926 - acc: 0.8258\n",
      "10000/10000 [==============================] - 2s 168us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.3, score=0.690, total= 2.6min\n",
      "[CV] lr=0.0001, dropout_rate=0.3 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed: 33.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 9s 214us/step - loss: 1.9349 - acc: 0.2958\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5599 - acc: 0.4264\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.4125 - acc: 0.4859\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3073 - acc: 0.5263\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2381 - acc: 0.5514\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1775 - acc: 0.5770\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1210 - acc: 0.5969\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0750 - acc: 0.6139\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0366 - acc: 0.6286\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9922 - acc: 0.6499\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9592 - acc: 0.6570\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9204 - acc: 0.6719\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8910 - acc: 0.6817\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8609 - acc: 0.6956\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8372 - acc: 0.7014\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8114 - acc: 0.7118\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7812 - acc: 0.7241\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7570 - acc: 0.7322\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7346 - acc: 0.7409\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7111 - acc: 0.7494\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6916 - acc: 0.7544\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6659 - acc: 0.7650\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6457 - acc: 0.7712\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6239 - acc: 0.7777\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6035 - acc: 0.7872\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5867 - acc: 0.7909\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5693 - acc: 0.7993\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5513 - acc: 0.8057\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5324 - acc: 0.8149\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5157 - acc: 0.8180\n",
      "10000/10000 [==============================] - 2s 176us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.3, score=0.662, total= 2.6min\n",
      "[CV] lr=0.0001, dropout_rate=0.3 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 35.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.8908 - acc: 0.3174\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.5592 - acc: 0.4358\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.4059 - acc: 0.4905\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3067 - acc: 0.5284\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2274 - acc: 0.5600\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.1659 - acc: 0.5802\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.1169 - acc: 0.6005\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0689 - acc: 0.6173\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0329 - acc: 0.6323\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9938 - acc: 0.6453\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9547 - acc: 0.6612\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9278 - acc: 0.6710\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8981 - acc: 0.6826\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8691 - acc: 0.6923\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8390 - acc: 0.7023\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8133 - acc: 0.7093\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7882 - acc: 0.7213\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7660 - acc: 0.7308\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7417 - acc: 0.7354\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7169 - acc: 0.7469\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7005 - acc: 0.7535\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6744 - acc: 0.7607\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6597 - acc: 0.7672\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6408 - acc: 0.7729\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6205 - acc: 0.7821\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5958 - acc: 0.7891\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5791 - acc: 0.7957\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5631 - acc: 0.8033\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5490 - acc: 0.8052\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5266 - acc: 0.8143\n",
      "10000/10000 [==============================] - 2s 188us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.3, score=0.678, total= 2.6min\n",
      "[CV] lr=0.01, dropout_rate=0.5 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 38.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 3.8905 - acc: 0.1102\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 2.1150 - acc: 0.1993\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.8111 - acc: 0.3097\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.6289 - acc: 0.3880\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.4664 - acc: 0.4573\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3406 - acc: 0.5054\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.2455 - acc: 0.5415\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.1440 - acc: 0.5847\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0528 - acc: 0.6182\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9678 - acc: 0.6512\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9018 - acc: 0.6755\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8370 - acc: 0.7040\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7723 - acc: 0.7269\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7206 - acc: 0.7493\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6610 - acc: 0.7688\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6026 - acc: 0.7906\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5619 - acc: 0.8017\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5177 - acc: 0.8211\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4760 - acc: 0.8346\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4426 - acc: 0.8461\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3956 - acc: 0.8613\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3647 - acc: 0.8743\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3388 - acc: 0.8794\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3086 - acc: 0.8928\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2874 - acc: 0.9016\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2672 - acc: 0.9094\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2548 - acc: 0.9114\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2172 - acc: 0.9229\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2185 - acc: 0.9260\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1953 - acc: 0.9347\n",
      "10000/10000 [==============================] - 2s 190us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.5, score=0.676, total= 2.6min\n",
      "[CV] lr=0.01, dropout_rate=0.5 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 40.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 3.7977 - acc: 0.1143\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 2.0919 - acc: 0.2079\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.7938 - acc: 0.3208\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5855 - acc: 0.4021\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.4305 - acc: 0.4626\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3086 - acc: 0.5203\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2075 - acc: 0.5567\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0927 - acc: 0.6030\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0029 - acc: 0.6440\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9286 - acc: 0.6677\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8487 - acc: 0.7017\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7828 - acc: 0.7249\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7223 - acc: 0.7455\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6611 - acc: 0.7672\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6154 - acc: 0.7841\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5616 - acc: 0.8025\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5138 - acc: 0.8213\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4764 - acc: 0.8330\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4306 - acc: 0.8497\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3991 - acc: 0.8615\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3627 - acc: 0.8739\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3410 - acc: 0.8802\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3072 - acc: 0.8926\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2878 - acc: 0.9012\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2663 - acc: 0.9075\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2482 - acc: 0.9147\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2215 - acc: 0.9234\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2060 - acc: 0.9296\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2040 - acc: 0.9300\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1856 - acc: 0.9364\n",
      "10000/10000 [==============================] - 2s 203us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.5, score=0.704, total= 2.6min\n",
      "[CV] lr=0.01, dropout_rate=0.5 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed: 43.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 3.9346 - acc: 0.1242\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 2.0642 - acc: 0.2033\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.8353 - acc: 0.2908\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.6306 - acc: 0.3723\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.4690 - acc: 0.4505\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3212 - acc: 0.5102\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2030 - acc: 0.5663\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0888 - acc: 0.6081\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0077 - acc: 0.6393\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9231 - acc: 0.6747\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8491 - acc: 0.7010\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7839 - acc: 0.7263\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7283 - acc: 0.7455\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6580 - acc: 0.7710\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6143 - acc: 0.7858\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5663 - acc: 0.8020\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5151 - acc: 0.8199\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4760 - acc: 0.8347\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4293 - acc: 0.8525\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3892 - acc: 0.8646\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3641 - acc: 0.8735\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3295 - acc: 0.8860\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3046 - acc: 0.8938\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2753 - acc: 0.9048\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2605 - acc: 0.9123\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2319 - acc: 0.9192\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2253 - acc: 0.9245\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2093 - acc: 0.9298\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1897 - acc: 0.9351\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1915 - acc: 0.9367\n",
      "10000/10000 [==============================] - 2s 210us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.5, score=0.694, total= 2.6min\n",
      "[CV] lr=0.01, dropout_rate=0.5 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 45.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 4.1138 - acc: 0.1106\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 2.1995 - acc: 0.1627\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.8898 - acc: 0.2704\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.6599 - acc: 0.3632\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.4697 - acc: 0.4409\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3363 - acc: 0.5034\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2082 - acc: 0.5546\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0965 - acc: 0.6023\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0181 - acc: 0.6352\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9156 - acc: 0.6770\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8407 - acc: 0.7018\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7694 - acc: 0.7318\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7004 - acc: 0.7539\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6490 - acc: 0.7742\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5974 - acc: 0.7923\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5363 - acc: 0.8123\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4919 - acc: 0.8283\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4474 - acc: 0.8445\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4073 - acc: 0.8576\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3712 - acc: 0.8705\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3434 - acc: 0.8813\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3087 - acc: 0.8936\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2809 - acc: 0.9003\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2557 - acc: 0.9138\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2411 - acc: 0.9197\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2157 - acc: 0.9256\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2085 - acc: 0.9301\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1969 - acc: 0.9329\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1772 - acc: 0.9396\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1690 - acc: 0.9442\n",
      "10000/10000 [==============================] - 2s 223us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.5, score=0.629, total= 2.6min\n",
      "[CV] lr=0.01, dropout_rate=0.5 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed: 48.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 10s 250us/step - loss: 3.3105 - acc: 0.1338\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 2.0213 - acc: 0.2255\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.7727 - acc: 0.3200\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5827 - acc: 0.4002\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.4304 - acc: 0.4676\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3045 - acc: 0.5236\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1933 - acc: 0.5664\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0941 - acc: 0.6047\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0162 - acc: 0.6335\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9423 - acc: 0.6656\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8705 - acc: 0.6916\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8058 - acc: 0.7153\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7412 - acc: 0.7395\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6819 - acc: 0.7622\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6318 - acc: 0.7788\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5888 - acc: 0.7964\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5348 - acc: 0.8129\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4896 - acc: 0.8302\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4577 - acc: 0.8398\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4137 - acc: 0.8556\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3820 - acc: 0.8667\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3443 - acc: 0.8820\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3245 - acc: 0.8885\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2899 - acc: 0.8986\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2752 - acc: 0.9059\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2536 - acc: 0.9121\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2350 - acc: 0.9193\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2219 - acc: 0.9256\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2015 - acc: 0.9309\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1836 - acc: 0.9379\n",
      "10000/10000 [==============================] - 2s 236us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.5, score=0.646, total= 2.6min\n",
      "[CV] lr=0.001, dropout_rate=0.5 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 10s 257us/step - loss: 1.8415 - acc: 0.3351\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.3931 - acc: 0.4868\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2038 - acc: 0.5590\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0845 - acc: 0.6086\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9858 - acc: 0.6480\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8980 - acc: 0.6788\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8298 - acc: 0.7059\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7729 - acc: 0.7250\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7137 - acc: 0.7460\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6563 - acc: 0.7701\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6228 - acc: 0.7809\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5674 - acc: 0.7985\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5299 - acc: 0.8120\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4943 - acc: 0.8259\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4676 - acc: 0.8355\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4249 - acc: 0.8486\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4008 - acc: 0.8589\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3658 - acc: 0.8696\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3457 - acc: 0.8782\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3080 - acc: 0.8919\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2960 - acc: 0.8953\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2742 - acc: 0.9009\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2523 - acc: 0.9106\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2350 - acc: 0.9167\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2230 - acc: 0.9189\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2012 - acc: 0.9298\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.1920 - acc: 0.9347\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.1826 - acc: 0.9366\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1668 - acc: 0.9417\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1649 - acc: 0.9439\n",
      "10000/10000 [==============================] - 2s 248us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.5, score=0.723, total= 2.6min\n",
      "[CV] lr=0.001, dropout_rate=0.5 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 10s 262us/step - loss: 1.8530 - acc: 0.3343\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.4374 - acc: 0.4698\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2563 - acc: 0.5387\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1172 - acc: 0.5950\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0274 - acc: 0.6319\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9296 - acc: 0.6678\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8622 - acc: 0.6926\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7885 - acc: 0.7199\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7275 - acc: 0.7414\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6740 - acc: 0.7613\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6326 - acc: 0.7753\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5897 - acc: 0.7923\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5450 - acc: 0.8078\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5022 - acc: 0.8231\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4635 - acc: 0.8355\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4352 - acc: 0.8482\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4004 - acc: 0.8589\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3707 - acc: 0.8707\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3402 - acc: 0.8804\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3271 - acc: 0.8865\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3009 - acc: 0.8941\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2693 - acc: 0.9039\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2617 - acc: 0.9080\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2356 - acc: 0.9179\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2152 - acc: 0.9236\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2072 - acc: 0.9258\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1983 - acc: 0.9311\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1819 - acc: 0.9359\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1772 - acc: 0.9379\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1555 - acc: 0.9451\n",
      "10000/10000 [==============================] - 3s 253us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.5, score=0.708, total= 2.7min\n",
      "[CV] lr=0.001, dropout_rate=0.5 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 11s 268us/step - loss: 1.8353 - acc: 0.3420\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3804 - acc: 0.4925\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1977 - acc: 0.5653\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0796 - acc: 0.6122\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9854 - acc: 0.6469\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8959 - acc: 0.6802\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8336 - acc: 0.7029\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7646 - acc: 0.7322\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7124 - acc: 0.7484\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6660 - acc: 0.7641\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6167 - acc: 0.7830\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5662 - acc: 0.8009\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5306 - acc: 0.8123\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4879 - acc: 0.8270\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4548 - acc: 0.8382\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4177 - acc: 0.8540\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3888 - acc: 0.8611\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3678 - acc: 0.8690\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3282 - acc: 0.8840\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3090 - acc: 0.8898\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2793 - acc: 0.9007\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2627 - acc: 0.9070\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2469 - acc: 0.9135\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2258 - acc: 0.9194\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2109 - acc: 0.9238\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2014 - acc: 0.9298\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1967 - acc: 0.9322\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1690 - acc: 0.9401\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1659 - acc: 0.9422\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1606 - acc: 0.9448\n",
      "10000/10000 [==============================] - 3s 253us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.5, score=0.673, total= 2.6min\n",
      "[CV] lr=0.001, dropout_rate=0.5 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 11s 267us/step - loss: 1.8179 - acc: 0.3469\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3934 - acc: 0.4854\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2159 - acc: 0.5585\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0841 - acc: 0.6052\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9848 - acc: 0.6460\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9073 - acc: 0.6748\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8330 - acc: 0.7030\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7706 - acc: 0.7284\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7163 - acc: 0.7463\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6699 - acc: 0.7619\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6100 - acc: 0.7827\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5723 - acc: 0.7979\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5289 - acc: 0.8124\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4936 - acc: 0.8247\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4573 - acc: 0.8386\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4252 - acc: 0.8520\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3867 - acc: 0.8626\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3724 - acc: 0.8670\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3353 - acc: 0.8811\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3190 - acc: 0.8878\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2848 - acc: 0.9010\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2764 - acc: 0.9035\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2471 - acc: 0.9151\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2299 - acc: 0.9191\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2205 - acc: 0.9213\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2017 - acc: 0.9291\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1974 - acc: 0.9319\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1755 - acc: 0.9395\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1681 - acc: 0.9423\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1576 - acc: 0.9439\n",
      "10000/10000 [==============================] - 3s 265us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.5, score=0.704, total= 2.6min\n",
      "[CV] lr=0.001, dropout_rate=0.5 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 11s 276us/step - loss: 1.8217 - acc: 0.3428\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3795 - acc: 0.4892\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2043 - acc: 0.5589\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0714 - acc: 0.6129\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9723 - acc: 0.6510\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8857 - acc: 0.6844\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8160 - acc: 0.7137\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7571 - acc: 0.7310\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6996 - acc: 0.7514\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6472 - acc: 0.7687\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6005 - acc: 0.7895\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5642 - acc: 0.8017\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5192 - acc: 0.8182\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4846 - acc: 0.8276\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4500 - acc: 0.8423\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4108 - acc: 0.8517\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3886 - acc: 0.8639\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3571 - acc: 0.8740\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3351 - acc: 0.8811\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3032 - acc: 0.8936\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2884 - acc: 0.8984\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2621 - acc: 0.9059\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2473 - acc: 0.9121\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2305 - acc: 0.9193\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2236 - acc: 0.9214\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1926 - acc: 0.9317\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1853 - acc: 0.9346\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1791 - acc: 0.9379\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1697 - acc: 0.9406\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1517 - acc: 0.9464\n",
      "10000/10000 [==============================] - 3s 270us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.5, score=0.650, total= 2.7min\n",
      "[CV] lr=0.0001, dropout_rate=0.5 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 11s 283us/step - loss: 2.0723 - acc: 0.2519\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.7031 - acc: 0.3747\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5383 - acc: 0.4340\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.4336 - acc: 0.4724\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3489 - acc: 0.5062\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2898 - acc: 0.5299\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2406 - acc: 0.5504\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1989 - acc: 0.5658\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1544 - acc: 0.5830\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1163 - acc: 0.5998\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0865 - acc: 0.6113\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0552 - acc: 0.6229\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0250 - acc: 0.6332\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0031 - acc: 0.6387\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9740 - acc: 0.6484\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9519 - acc: 0.6601\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9259 - acc: 0.6705\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9054 - acc: 0.6764\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8813 - acc: 0.6870\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8673 - acc: 0.6891\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8461 - acc: 0.7015\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8254 - acc: 0.7064\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8044 - acc: 0.7160\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7860 - acc: 0.7199\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7698 - acc: 0.7258\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7509 - acc: 0.7326\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7362 - acc: 0.7376\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7241 - acc: 0.7443\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7021 - acc: 0.7512\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6930 - acc: 0.7553\n",
      "10000/10000 [==============================] - 3s 289us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.5, score=0.665, total= 2.7min\n",
      "[CV] lr=0.0001, dropout_rate=0.5 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 11s 286us/step - loss: 2.0269 - acc: 0.2670\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.7310 - acc: 0.3665\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5810 - acc: 0.4167\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.4747 - acc: 0.4593\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.4019 - acc: 0.4857\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.3351 - acc: 0.5112\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2855 - acc: 0.5344\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2388 - acc: 0.5501\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1970 - acc: 0.5661\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1617 - acc: 0.5793\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1283 - acc: 0.5936\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0971 - acc: 0.6036\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0667 - acc: 0.6154\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0428 - acc: 0.6240\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0087 - acc: 0.6372\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9919 - acc: 0.6445\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9576 - acc: 0.6572\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9405 - acc: 0.6602\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9213 - acc: 0.6704\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8987 - acc: 0.6767\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8753 - acc: 0.6853\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8596 - acc: 0.6929\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8409 - acc: 0.6977\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8243 - acc: 0.7046\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8032 - acc: 0.7101\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7837 - acc: 0.7190\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7733 - acc: 0.7224\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7516 - acc: 0.7302\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7384 - acc: 0.7355\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7190 - acc: 0.7457\n",
      "10000/10000 [==============================] - 3s 299us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.5, score=0.671, total= 2.7min\n",
      "[CV] lr=0.0001, dropout_rate=0.5 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 12s 291us/step - loss: 2.0401 - acc: 0.2597\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.7149 - acc: 0.3678\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.5610 - acc: 0.4255\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.4710 - acc: 0.4598\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.4022 - acc: 0.4870\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.3449 - acc: 0.5076\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2930 - acc: 0.5323\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2510 - acc: 0.5463\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2032 - acc: 0.5642\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1727 - acc: 0.5744\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1381 - acc: 0.5883\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1033 - acc: 0.6012\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0823 - acc: 0.6120\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0522 - acc: 0.6229\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0300 - acc: 0.6293\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0057 - acc: 0.6418\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9817 - acc: 0.6480\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9562 - acc: 0.6574\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9366 - acc: 0.6645\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9183 - acc: 0.6711\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8934 - acc: 0.6793\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8791 - acc: 0.6851\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8576 - acc: 0.6958\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8409 - acc: 0.6993\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8221 - acc: 0.7082\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8036 - acc: 0.7148\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7903 - acc: 0.7169\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7736 - acc: 0.7233\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7560 - acc: 0.7323\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7401 - acc: 0.7372\n",
      "10000/10000 [==============================] - 3s 315us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.5, score=0.667, total= 2.7min\n",
      "[CV] lr=0.0001, dropout_rate=0.5 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 12s 300us/step - loss: 2.0377 - acc: 0.2601\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.7204 - acc: 0.3618\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.5623 - acc: 0.4201\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4747 - acc: 0.4561\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3949 - acc: 0.4864\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3302 - acc: 0.5137\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2810 - acc: 0.5344\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2350 - acc: 0.5520\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1966 - acc: 0.5667\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1576 - acc: 0.5830\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1207 - acc: 0.5933\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0883 - acc: 0.6080\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0557 - acc: 0.6176\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0258 - acc: 0.6310\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0025 - acc: 0.6391\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9747 - acc: 0.6489\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9519 - acc: 0.6591\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9305 - acc: 0.6684\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9022 - acc: 0.6755\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8804 - acc: 0.6848\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8636 - acc: 0.6901\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8411 - acc: 0.7010\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8233 - acc: 0.7048\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7994 - acc: 0.7121\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7816 - acc: 0.7207\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7689 - acc: 0.7279\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7522 - acc: 0.7310\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7299 - acc: 0.7406\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7169 - acc: 0.7433\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6964 - acc: 0.7519\n",
      "10000/10000 [==============================] - 3s 327us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.5, score=0.652, total= 2.7min\n",
      "[CV] lr=0.0001, dropout_rate=0.5 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 12s 303us/step - loss: 2.1023 - acc: 0.2480\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.7201 - acc: 0.3680\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5530 - acc: 0.4282\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4470 - acc: 0.4693\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3645 - acc: 0.5010\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3037 - acc: 0.5252\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2527 - acc: 0.5472\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2073 - acc: 0.5677\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1682 - acc: 0.5799\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1357 - acc: 0.5911\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1031 - acc: 0.6033\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0742 - acc: 0.6139\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0423 - acc: 0.6249\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0194 - acc: 0.6348\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9952 - acc: 0.6440\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9649 - acc: 0.6560\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9459 - acc: 0.6612\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9249 - acc: 0.6728\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9041 - acc: 0.6760\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8842 - acc: 0.6863\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8665 - acc: 0.6915\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8445 - acc: 0.7008\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8286 - acc: 0.7053\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8059 - acc: 0.7141\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7916 - acc: 0.7188\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7781 - acc: 0.7226\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7558 - acc: 0.7318\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7404 - acc: 0.7393\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7259 - acc: 0.7444\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7074 - acc: 0.7496\n",
      "10000/10000 [==============================] - 3s 342us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.5, score=0.681, total= 2.7min\n",
      "[CV] lr=0.01, dropout_rate=0.7 .......................................\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 12s 310us/step - loss: 3.7977 - acc: 0.1098\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 2.1920 - acc: 0.1718\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.8756 - acc: 0.2691\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6592 - acc: 0.3650\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5132 - acc: 0.4311\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3798 - acc: 0.4923\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2799 - acc: 0.5312\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1789 - acc: 0.5722\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0862 - acc: 0.6119\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0192 - acc: 0.6361\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9464 - acc: 0.6657\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8879 - acc: 0.6881\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8249 - acc: 0.7100\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7708 - acc: 0.7312\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7126 - acc: 0.7534\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6762 - acc: 0.7652\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6151 - acc: 0.7869\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5729 - acc: 0.8043\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5441 - acc: 0.8128\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4956 - acc: 0.8292\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4655 - acc: 0.8409\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4307 - acc: 0.8521\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3981 - acc: 0.8660\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3737 - acc: 0.8744\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3489 - acc: 0.8806\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3229 - acc: 0.8897\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3088 - acc: 0.8988\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2935 - acc: 0.9023\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2646 - acc: 0.9105\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2550 - acc: 0.9144\n",
      "10000/10000 [==============================] - 3s 348us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.7, score=0.560, total= 2.7min\n",
      "[CV] lr=0.01, dropout_rate=0.7 .......................................\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 13s 319us/step - loss: 3.3480 - acc: 0.1421\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.9972 - acc: 0.2164\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.8079 - acc: 0.3030\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6238 - acc: 0.3766\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4656 - acc: 0.4497\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.3570 - acc: 0.4988\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2530 - acc: 0.5402\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1727 - acc: 0.5770\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0836 - acc: 0.6123\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0064 - acc: 0.6418\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9419 - acc: 0.6631\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8856 - acc: 0.6875\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8150 - acc: 0.7170\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7683 - acc: 0.7288\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7055 - acc: 0.7560\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6606 - acc: 0.7714\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6232 - acc: 0.7848\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5812 - acc: 0.8025\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5370 - acc: 0.8178\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4953 - acc: 0.8299\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4592 - acc: 0.8421\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4201 - acc: 0.8575\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3972 - acc: 0.8658\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.3624 - acc: 0.8770\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3439 - acc: 0.8821\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3193 - acc: 0.8902\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3093 - acc: 0.8958\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2763 - acc: 0.9068\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2577 - acc: 0.9127\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2502 - acc: 0.9155\n",
      "10000/10000 [==============================] - 4s 364us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.7, score=0.629, total= 2.7min\n",
      "[CV] lr=0.01, dropout_rate=0.7 .......................................\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 13s 327us/step - loss: 3.5317 - acc: 0.1199\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 2.0606 - acc: 0.2127\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.8431 - acc: 0.2914\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6621 - acc: 0.3620\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5072 - acc: 0.4283\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3945 - acc: 0.4797\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2849 - acc: 0.5281\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1960 - acc: 0.5667\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1029 - acc: 0.6055\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0351 - acc: 0.6278\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9625 - acc: 0.6584\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.8966 - acc: 0.6861\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.8483 - acc: 0.7011\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7948 - acc: 0.7215\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7387 - acc: 0.7424\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6890 - acc: 0.7609\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6576 - acc: 0.7733\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6039 - acc: 0.7906\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5641 - acc: 0.8057\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5305 - acc: 0.8203\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4921 - acc: 0.8315\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4549 - acc: 0.8447\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4158 - acc: 0.8586\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3933 - acc: 0.8673\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3705 - acc: 0.8751\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3348 - acc: 0.8869\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3255 - acc: 0.8919\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2987 - acc: 0.9015\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2798 - acc: 0.9073\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.2690 - acc: 0.9100\n",
      "10000/10000 [==============================] - 4s 372us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.7, score=0.621, total= 2.7min\n",
      "[CV] lr=0.01, dropout_rate=0.7 .......................................\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 13s 329us/step - loss: 3.3795 - acc: 0.1518\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 2.0202 - acc: 0.2339\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.7877 - acc: 0.3139\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.6248 - acc: 0.3821\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4891 - acc: 0.4409\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3697 - acc: 0.4932\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2739 - acc: 0.5335\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1730 - acc: 0.5746\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0889 - acc: 0.6089\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0074 - acc: 0.6403\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9473 - acc: 0.6647\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8787 - acc: 0.6895\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8225 - acc: 0.7128\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7787 - acc: 0.7288\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7275 - acc: 0.7454\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6778 - acc: 0.7627\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6339 - acc: 0.7764\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5886 - acc: 0.7955\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5610 - acc: 0.8045\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5183 - acc: 0.8203\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4845 - acc: 0.8325\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4548 - acc: 0.8448\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4191 - acc: 0.8552\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4003 - acc: 0.8632\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3657 - acc: 0.8733\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3530 - acc: 0.8791\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3253 - acc: 0.8874\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3071 - acc: 0.8952\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2870 - acc: 0.9009\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.2766 - acc: 0.9061\n",
      "10000/10000 [==============================] - 4s 386us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.7, score=0.524, total= 2.7min\n",
      "[CV] lr=0.01, dropout_rate=0.7 .......................................\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 13s 337us/step - loss: 3.4229 - acc: 0.1152\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 2.1104 - acc: 0.1992\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.8660 - acc: 0.2842\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6838 - acc: 0.3612\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.5259 - acc: 0.4282\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4118 - acc: 0.4758\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2989 - acc: 0.5230\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2125 - acc: 0.5626\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1269 - acc: 0.5934\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0475 - acc: 0.6253\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9800 - acc: 0.6527\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9158 - acc: 0.6775\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8592 - acc: 0.6981\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8057 - acc: 0.7186\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7592 - acc: 0.7372\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7000 - acc: 0.7556\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6657 - acc: 0.7696\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6217 - acc: 0.7850\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5716 - acc: 0.8034\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5328 - acc: 0.8154\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.5027 - acc: 0.8257\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4616 - acc: 0.8423\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4405 - acc: 0.8494\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4013 - acc: 0.8628\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3833 - acc: 0.8702\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3590 - acc: 0.8770\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3342 - acc: 0.8851\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3141 - acc: 0.8930\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3122 - acc: 0.8940\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2721 - acc: 0.9074\n",
      "10000/10000 [==============================] - 4s 382us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.7, score=0.673, total= 2.7min\n",
      "[CV] lr=0.001, dropout_rate=0.7 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 14s 338us/step - loss: 1.9566 - acc: 0.3002\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5149 - acc: 0.4329\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3313 - acc: 0.5119\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2067 - acc: 0.5625\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1008 - acc: 0.6045\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0271 - acc: 0.6346\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9592 - acc: 0.6591\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8998 - acc: 0.6820\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8358 - acc: 0.7035\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8032 - acc: 0.7170\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7498 - acc: 0.7365\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7192 - acc: 0.7479\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6779 - acc: 0.7603\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6385 - acc: 0.7788\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6013 - acc: 0.7891\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5632 - acc: 0.8012\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5425 - acc: 0.8102\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5061 - acc: 0.8220\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4785 - acc: 0.8302\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4538 - acc: 0.8396\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4374 - acc: 0.8469\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4032 - acc: 0.8588\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3883 - acc: 0.8662\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.3625 - acc: 0.8715\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.3386 - acc: 0.8804\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3275 - acc: 0.8830\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3084 - acc: 0.8924\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2917 - acc: 0.8973\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2785 - acc: 0.9013\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2544 - acc: 0.9098\n",
      "10000/10000 [==============================] - 4s 394us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.7, score=0.652, total= 2.8min\n",
      "[CV] lr=0.001, dropout_rate=0.7 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 14s 342us/step - loss: 2.0005 - acc: 0.2914\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.5683 - acc: 0.4145\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3870 - acc: 0.4901\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2565 - acc: 0.5427\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1509 - acc: 0.5814\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0719 - acc: 0.6107\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9904 - acc: 0.6470\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9243 - acc: 0.6733\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8776 - acc: 0.6881\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8233 - acc: 0.7109\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7732 - acc: 0.7287\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7348 - acc: 0.7417\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6878 - acc: 0.7585\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6504 - acc: 0.7708\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6193 - acc: 0.7836\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5874 - acc: 0.7935\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5599 - acc: 0.8027\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5305 - acc: 0.8120\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4957 - acc: 0.8253\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4739 - acc: 0.8318\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4552 - acc: 0.8411\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4197 - acc: 0.8532\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4018 - acc: 0.8588\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3795 - acc: 0.8676\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3589 - acc: 0.8741\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3472 - acc: 0.8779\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.3144 - acc: 0.8899\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3094 - acc: 0.8909\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2865 - acc: 0.9010\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2822 - acc: 0.9026\n",
      "10000/10000 [==============================] - 4s 399us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.7, score=0.683, total= 2.8min\n",
      "[CV] lr=0.001, dropout_rate=0.7 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 14s 350us/step - loss: 1.9937 - acc: 0.2910\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.5656 - acc: 0.4152\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3731 - acc: 0.4901\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2386 - acc: 0.5478\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1375 - acc: 0.5869\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0416 - acc: 0.6272\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9756 - acc: 0.6536\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9129 - acc: 0.6775\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8653 - acc: 0.6948\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8104 - acc: 0.7138\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7619 - acc: 0.7354\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7201 - acc: 0.7504\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6849 - acc: 0.7598\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6404 - acc: 0.7765\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6062 - acc: 0.7881\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.5755 - acc: 0.7988\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5456 - acc: 0.8086\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5148 - acc: 0.8185\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4897 - acc: 0.8274\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.4566 - acc: 0.8393\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.4356 - acc: 0.8486\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4141 - acc: 0.8541\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3831 - acc: 0.8665\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3594 - acc: 0.8748\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3467 - acc: 0.8786\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.3250 - acc: 0.8862\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3250 - acc: 0.8859\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2935 - acc: 0.8978\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2773 - acc: 0.9029\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2744 - acc: 0.9042\n",
      "10000/10000 [==============================] - 4s 411us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.7, score=0.651, total= 2.8min\n",
      "[CV] lr=0.001, dropout_rate=0.7 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 14s 354us/step - loss: 1.9431 - acc: 0.2926\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5432 - acc: 0.4212\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3459 - acc: 0.5040\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2150 - acc: 0.5568\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1192 - acc: 0.5939\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0328 - acc: 0.6294\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9621 - acc: 0.6547\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8954 - acc: 0.6846\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.8378 - acc: 0.7002\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7827 - acc: 0.7229\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7445 - acc: 0.7381\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6969 - acc: 0.7571\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6573 - acc: 0.7698\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6289 - acc: 0.7791\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5921 - acc: 0.7902\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5525 - acc: 0.8059\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5262 - acc: 0.8162\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4945 - acc: 0.8284\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4664 - acc: 0.8346\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4450 - acc: 0.8458\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4191 - acc: 0.8527\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3918 - acc: 0.8606\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3796 - acc: 0.8648\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3459 - acc: 0.8769\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3341 - acc: 0.8824\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3160 - acc: 0.8865\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3021 - acc: 0.8938\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2754 - acc: 0.9045\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2658 - acc: 0.9073\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2546 - acc: 0.9098\n",
      "10000/10000 [==============================] - 4s 423us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.7, score=0.621, total= 2.8min\n",
      "[CV] lr=0.001, dropout_rate=0.7 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 14s 362us/step - loss: 1.9672 - acc: 0.2963\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5363 - acc: 0.4269\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3433 - acc: 0.5091\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2116 - acc: 0.5583\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0991 - acc: 0.6045\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0270 - acc: 0.6322\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9594 - acc: 0.6598\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8903 - acc: 0.6860\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8341 - acc: 0.7060\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7918 - acc: 0.7195\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7397 - acc: 0.7414\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7043 - acc: 0.7531\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6517 - acc: 0.7718\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6290 - acc: 0.7815\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5868 - acc: 0.7936\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.5590 - acc: 0.8036\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5230 - acc: 0.8160\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4963 - acc: 0.8267\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4659 - acc: 0.8382\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4383 - acc: 0.8475\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4220 - acc: 0.8518\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3965 - acc: 0.8621\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3804 - acc: 0.8670\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.3516 - acc: 0.8755\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3324 - acc: 0.8831\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3145 - acc: 0.8904\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3038 - acc: 0.8945\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2803 - acc: 0.9006\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2702 - acc: 0.9048\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2490 - acc: 0.9130\n",
      "10000/10000 [==============================] - 4s 428us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.7, score=0.568, total= 2.8min\n",
      "[CV] lr=0.0001, dropout_rate=0.7 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 15s 363us/step - loss: 2.3600 - acc: 0.1985\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.9714 - acc: 0.2806\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.8086 - acc: 0.3260\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.7011 - acc: 0.3592\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6267 - acc: 0.3894\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5651 - acc: 0.4120\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5124 - acc: 0.4359\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4761 - acc: 0.4478\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.4316 - acc: 0.4686\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3928 - acc: 0.4811\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3567 - acc: 0.4971\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3290 - acc: 0.5079\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3017 - acc: 0.5176\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2733 - acc: 0.5318\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2477 - acc: 0.5404\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2239 - acc: 0.5486\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2048 - acc: 0.5605\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1837 - acc: 0.5669\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1532 - acc: 0.5756\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1340 - acc: 0.5869\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1198 - acc: 0.5908\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1011 - acc: 0.5991\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0843 - acc: 0.6053\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0665 - acc: 0.6125\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0522 - acc: 0.6204\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0350 - acc: 0.6259\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0222 - acc: 0.6311\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0015 - acc: 0.6378\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9866 - acc: 0.6422\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9715 - acc: 0.6466\n",
      "10000/10000 [==============================] - 4s 437us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.7, score=0.633, total= 2.8min\n",
      "[CV] lr=0.0001, dropout_rate=0.7 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 15s 371us/step - loss: 2.2726 - acc: 0.2036\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.9333 - acc: 0.2935\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.7725 - acc: 0.3437\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6666 - acc: 0.3776\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5904 - acc: 0.4112\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.5236 - acc: 0.4319\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4694 - acc: 0.4514\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.4213 - acc: 0.4747\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3816 - acc: 0.4894\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3505 - acc: 0.5043\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3172 - acc: 0.5158\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 1.2882 - acc: 0.5266\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2598 - acc: 0.5383\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2333 - acc: 0.5496\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2066 - acc: 0.5604\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1869 - acc: 0.5674\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1650 - acc: 0.5749\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1416 - acc: 0.5846\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1227 - acc: 0.5915\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0993 - acc: 0.6020\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0821 - acc: 0.6105\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0647 - acc: 0.6191\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0441 - acc: 0.6238\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0360 - acc: 0.6267\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0182 - acc: 0.6339\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.9963 - acc: 0.6385\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.9826 - acc: 0.6460\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9718 - acc: 0.6491\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.9569 - acc: 0.6566\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9422 - acc: 0.6593\n",
      "10000/10000 [==============================] - 5s 460us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.7, score=0.640, total= 2.8min\n",
      "[CV] lr=0.0001, dropout_rate=0.7 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 15s 385us/step - loss: 2.3030 - acc: 0.1979\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.9521 - acc: 0.2889\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.7886 - acc: 0.3383\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.6688 - acc: 0.3777\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.5887 - acc: 0.4084\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5249 - acc: 0.4327\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4672 - acc: 0.4548\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.4255 - acc: 0.4718\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3863 - acc: 0.4858\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3550 - acc: 0.5022\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3155 - acc: 0.5156\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2847 - acc: 0.5272\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2569 - acc: 0.5386\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2286 - acc: 0.5539\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2039 - acc: 0.5640\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1825 - acc: 0.5725\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1633 - acc: 0.5766\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1356 - acc: 0.5921\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1197 - acc: 0.5954\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0975 - acc: 0.6055\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0804 - acc: 0.6063\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0639 - acc: 0.6160\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0415 - acc: 0.6256\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0300 - acc: 0.6282\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0067 - acc: 0.6373\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9919 - acc: 0.6420\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 0.9785 - acc: 0.6499\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.9612 - acc: 0.6539\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9481 - acc: 0.6631\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.9310 - acc: 0.6661\n",
      "10000/10000 [==============================] - 5s 473us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.7, score=0.653, total= 2.8min\n",
      "[CV] lr=0.0001, dropout_rate=0.7 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 15s 385us/step - loss: 2.2575 - acc: 0.2137\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.9197 - acc: 0.2947\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.7607 - acc: 0.3416\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.6661 - acc: 0.3795\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5833 - acc: 0.4098\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.5224 - acc: 0.4342\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 1.4711 - acc: 0.4538\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.4198 - acc: 0.4767\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3708 - acc: 0.4957\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3430 - acc: 0.5070\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3074 - acc: 0.5210\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2698 - acc: 0.5337\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2449 - acc: 0.5453\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2182 - acc: 0.5561\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1891 - acc: 0.5663\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1726 - acc: 0.5755\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1419 - acc: 0.5855\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1197 - acc: 0.5921\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1044 - acc: 0.5994\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0886 - acc: 0.6074\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0659 - acc: 0.6147\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0515 - acc: 0.6219\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0296 - acc: 0.6268\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0163 - acc: 0.6329\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0003 - acc: 0.6392\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9828 - acc: 0.6461\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9622 - acc: 0.6550\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9519 - acc: 0.6565\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9348 - acc: 0.6636\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9224 - acc: 0.6701\n",
      "10000/10000 [==============================] - 5s 471us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.7, score=0.650, total= 2.8min\n",
      "[CV] lr=0.0001, dropout_rate=0.7 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 16s 394us/step - loss: 2.2643 - acc: 0.2039\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.9117 - acc: 0.2969\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.7665 - acc: 0.3386\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6651 - acc: 0.3781\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5945 - acc: 0.4018\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5335 - acc: 0.4280\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4756 - acc: 0.4564\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4369 - acc: 0.4673\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3918 - acc: 0.4862\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3555 - acc: 0.4979\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3173 - acc: 0.5136\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2864 - acc: 0.5275\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2575 - acc: 0.5393\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2326 - acc: 0.5496\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2053 - acc: 0.5619\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 1.1861 - acc: 0.5690\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1579 - acc: 0.5760\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1344 - acc: 0.5855\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1143 - acc: 0.5957\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0937 - acc: 0.6022\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0774 - acc: 0.6110\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0575 - acc: 0.6182\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0429 - acc: 0.6220\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0272 - acc: 0.6295\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0058 - acc: 0.6382\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9957 - acc: 0.6395\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9773 - acc: 0.6468\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9612 - acc: 0.6531\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9471 - acc: 0.6599\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9320 - acc: 0.6667\n",
      "10000/10000 [==============================] - 5s 477us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.7, score=0.632, total= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 119.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 1.7286 - acc: 0.3736\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2662 - acc: 0.5363\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.0727 - acc: 0.6125\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.9541 - acc: 0.6598\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.8493 - acc: 0.6977\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.7654 - acc: 0.7287\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.6981 - acc: 0.7531\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.6308 - acc: 0.7777\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.5768 - acc: 0.7979\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.5289 - acc: 0.8111\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.4785 - acc: 0.8315\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.4385 - acc: 0.8460\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.3985 - acc: 0.8585\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.3672 - acc: 0.8685\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.3304 - acc: 0.8828\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.2956 - acc: 0.8952\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.2790 - acc: 0.9018\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.2551 - acc: 0.9092\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.2334 - acc: 0.9179\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2046 - acc: 0.9266\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2006 - acc: 0.9280\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1732 - acc: 0.9376\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1691 - acc: 0.9416\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1481 - acc: 0.9474\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1435 - acc: 0.9509\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1379 - acc: 0.9519\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1283 - acc: 0.9561\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1203 - acc: 0.9578\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1091 - acc: 0.9626\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1091 - acc: 0.9625\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(x_train, y_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-ZDrKXQBwcLP",
    "outputId": "c1faebdf-1630-47c5-a838-bf7b09aafe93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'dropout_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8L_-0ACwnWk"
   },
   "outputs": [],
   "source": [
    "best_model = grid_result.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nD1M7ov7qiXv"
   },
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2d8NUOFqiXz"
   },
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zb4EImJOqiX2"
   },
   "outputs": [],
   "source": [
    "best_model = grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "G4ZIAtr_qiX8",
    "outputId": "d39be832-cf6a-4001-ca07-11c82e8296f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 40000 samples\n",
      "Epoch 1/60\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 1.7001 - acc: 0.3859 - val_loss: 2.3283 - val_acc: 0.2944\n",
      "Epoch 2/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.2371 - acc: 0.5483 - val_loss: 1.5486 - val_acc: 0.4531\n",
      "Epoch 3/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.0466 - acc: 0.6235 - val_loss: 1.2596 - val_acc: 0.5465\n",
      "Epoch 4/60\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.9113 - acc: 0.6722 - val_loss: 1.1328 - val_acc: 0.6129\n",
      "Epoch 5/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.8172 - acc: 0.7088 - val_loss: 1.4909 - val_acc: 0.5450\n",
      "Epoch 6/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.7470 - acc: 0.7353 - val_loss: 0.8006 - val_acc: 0.7046\n",
      "Epoch 7/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.6786 - acc: 0.7593 - val_loss: 1.0747 - val_acc: 0.6205\n",
      "Epoch 8/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.6146 - acc: 0.7816 - val_loss: 1.6339 - val_acc: 0.5414\n",
      "Epoch 9/60\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.5658 - acc: 0.7999 - val_loss: 0.4985 - val_acc: 0.8292\n",
      "Epoch 10/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.5095 - acc: 0.8191 - val_loss: 0.7874 - val_acc: 0.7384\n",
      "Epoch 11/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.4709 - acc: 0.8330 - val_loss: 0.9080 - val_acc: 0.6994\n",
      "Epoch 12/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.4246 - acc: 0.8484 - val_loss: 0.5183 - val_acc: 0.8195\n",
      "Epoch 13/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.3818 - acc: 0.8632 - val_loss: 0.4040 - val_acc: 0.8478\n",
      "Epoch 14/60\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.3450 - acc: 0.8773 - val_loss: 0.6988 - val_acc: 0.7845\n",
      "Epoch 15/60\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.3215 - acc: 0.8846 - val_loss: 0.8624 - val_acc: 0.7444\n",
      "Epoch 16/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.2889 - acc: 0.8979 - val_loss: 0.4412 - val_acc: 0.8475\n",
      "Epoch 17/60\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.2630 - acc: 0.9060 - val_loss: 0.2706 - val_acc: 0.8977\n",
      "Epoch 18/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2350 - acc: 0.9159 - val_loss: 0.5250 - val_acc: 0.8226\n",
      "Epoch 19/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.2216 - acc: 0.9207 - val_loss: 0.3142 - val_acc: 0.8867\n",
      "Epoch 20/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.1984 - acc: 0.9307 - val_loss: 0.3095 - val_acc: 0.8928\n",
      "Epoch 21/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.1921 - acc: 0.9334 - val_loss: 0.2340 - val_acc: 0.9192\n",
      "Epoch 22/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.1697 - acc: 0.9402 - val_loss: 0.1107 - val_acc: 0.9601\n",
      "Epoch 23/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.1652 - acc: 0.9428 - val_loss: 0.3808 - val_acc: 0.8768\n",
      "Epoch 24/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.1419 - acc: 0.9494 - val_loss: 0.2910 - val_acc: 0.9123\n",
      "Epoch 25/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.1467 - acc: 0.9486 - val_loss: 0.3988 - val_acc: 0.8728\n",
      "Epoch 26/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.1264 - acc: 0.9565 - val_loss: 0.8570 - val_acc: 0.8117\n",
      "Epoch 27/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.1205 - acc: 0.9587 - val_loss: 0.4430 - val_acc: 0.8683\n",
      "Epoch 28/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.1176 - acc: 0.9599 - val_loss: 0.5331 - val_acc: 0.8636\n",
      "Epoch 29/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.1086 - acc: 0.9621 - val_loss: 0.1208 - val_acc: 0.9572\n",
      "Epoch 30/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.1083 - acc: 0.9620 - val_loss: 0.1222 - val_acc: 0.9585\n",
      "Epoch 31/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0987 - acc: 0.9670 - val_loss: 0.5135 - val_acc: 0.8558\n",
      "Epoch 32/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0970 - acc: 0.9662 - val_loss: 0.2683 - val_acc: 0.9093\n",
      "Epoch 33/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0915 - acc: 0.9689 - val_loss: 0.1018 - val_acc: 0.9635\n",
      "Epoch 34/60\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.0814 - acc: 0.9726 - val_loss: 0.2045 - val_acc: 0.9358\n",
      "Epoch 35/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0865 - acc: 0.9716 - val_loss: 0.1517 - val_acc: 0.9467\n",
      "Epoch 36/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0749 - acc: 0.9749 - val_loss: 0.7856 - val_acc: 0.8269\n",
      "Epoch 37/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0826 - acc: 0.9716 - val_loss: 0.9639 - val_acc: 0.8007\n",
      "Epoch 38/60\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.0768 - acc: 0.9750 - val_loss: 0.2860 - val_acc: 0.9149\n",
      "Epoch 39/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0715 - acc: 0.9763 - val_loss: 0.1863 - val_acc: 0.9355\n",
      "Epoch 40/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0685 - acc: 0.9768 - val_loss: 0.4001 - val_acc: 0.8875\n",
      "Epoch 41/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0685 - acc: 0.9769 - val_loss: 0.5094 - val_acc: 0.8603\n",
      "Epoch 42/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0658 - acc: 0.9774 - val_loss: 0.4344 - val_acc: 0.8851\n",
      "Epoch 43/60\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.0657 - acc: 0.9785 - val_loss: 0.3457 - val_acc: 0.8992\n",
      "Epoch 44/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0628 - acc: 0.9790 - val_loss: 0.2157 - val_acc: 0.9311\n",
      "Epoch 45/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0589 - acc: 0.9799 - val_loss: 0.0996 - val_acc: 0.9667\n",
      "Epoch 46/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0627 - acc: 0.9792 - val_loss: 0.1200 - val_acc: 0.9582\n",
      "Epoch 47/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0546 - acc: 0.9814 - val_loss: 0.3334 - val_acc: 0.9108\n",
      "Epoch 48/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0506 - acc: 0.9830 - val_loss: 0.2327 - val_acc: 0.9382\n",
      "Epoch 49/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0537 - acc: 0.9823 - val_loss: 0.3593 - val_acc: 0.9121\n",
      "Epoch 50/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0528 - acc: 0.9821 - val_loss: 0.3185 - val_acc: 0.9173\n",
      "Epoch 51/60\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.0531 - acc: 0.9828 - val_loss: 0.4605 - val_acc: 0.8968\n",
      "Epoch 52/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0470 - acc: 0.9841 - val_loss: 0.1712 - val_acc: 0.9509\n",
      "Epoch 53/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0511 - acc: 0.9833 - val_loss: 0.0887 - val_acc: 0.9688\n",
      "Epoch 54/60\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.0555 - acc: 0.9830 - val_loss: 0.1928 - val_acc: 0.9354\n",
      "Epoch 55/60\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.0437 - acc: 0.9852 - val_loss: 0.3146 - val_acc: 0.9211\n",
      "Epoch 56/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0486 - acc: 0.9839 - val_loss: 0.0572 - val_acc: 0.9805\n",
      "Epoch 57/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0454 - acc: 0.9849 - val_loss: 0.8695 - val_acc: 0.8317\n",
      "Epoch 58/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0450 - acc: 0.9853 - val_loss: 0.0830 - val_acc: 0.9711\n",
      "Epoch 59/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0428 - acc: 0.9862 - val_loss: 0.2118 - val_acc: 0.9404\n",
      "Epoch 60/60\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0404 - acc: 0.9863 - val_loss: 0.1170 - val_acc: 0.9619\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = best_model.fit(x_train, y_train_vec,  \n",
    "           epochs=60, \n",
    "           verbose = 1,\n",
    "           validation_data = (x_tr, y_tr)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "wQJPuhUcymlE",
    "outputId": "7e60e332-c73d-4b53-af0a-40a87800c760",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx3GKHBcCx3GcIseFwHEcp8j5/4GRSsxMupmCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_val_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BqpyXBdQqiYH"
   },
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "usP1sKYzkaez",
    "outputId": "70819aff-2983-4a74-9e80-9ddc921e878c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = best_model.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xl1nyMOJqiYP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HM4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
