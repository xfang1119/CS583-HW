{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CpLYkhvwqiWU"
   },
   "source": [
    "# Home 4: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Xing Fang\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSjwn_ZyqiWY"
   },
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbHH0uUEqiWa"
   },
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5dpUgZGlqiWd"
   },
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "_Q-FXyc-qiWg",
    "outputId": "3dcef9f7-fef2-4d8d-9760-61c8cb0ba94c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 6s 0us/step\n",
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lcFme21AqiWq"
   },
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "hVkAYnWxqiWt",
    "outputId": "14f61400-86c7-4e19-be38-c48bce5f90ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def to_one_hot(y, num_class=10):\n",
    "    results = np.zeros([(len(y)), num_class])\n",
    "    for i, label in enumerate(y):\n",
    "        results[i, label] = 1\n",
    "    return results\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ImANKJ4qiW8"
   },
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaunHMUKqiXB"
   },
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "D8BfvIwFqiXE",
    "outputId": "f3379e09-397e-490a-cd79-513688644cde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "se1byVdAqiXM"
   },
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I3u_WFijqiXO"
   },
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OlqeudRXfPzg"
   },
   "source": [
    "### Baseline model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7OYdPv7hqiXQ",
    "outputId": "4ac8ca4d-1681-4b90-88a7-2ecaf5d5c49e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 461,514\n",
      "Trainable params: 460,554\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "ZFds7ct6YQBJ",
    "outputId": "518e67dc-1b0c-4c95-951a-cf1435b2b826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-5 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "92DiBqRvYK6e",
    "outputId": "fcafa846-c2d8-45d9-979f-b4e837f896f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "40000/40000 [==============================] - 31s 773us/step - loss: 2.1598 - acc: 0.2171 - val_loss: 1.7682 - val_acc: 0.3875\n",
      "Epoch 2/60\n",
      "40000/40000 [==============================] - 24s 601us/step - loss: 1.8700 - acc: 0.3166 - val_loss: 1.6091 - val_acc: 0.4365\n",
      "Epoch 3/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 1.7257 - acc: 0.3640 - val_loss: 1.5039 - val_acc: 0.4657\n",
      "Epoch 4/60\n",
      "40000/40000 [==============================] - 24s 606us/step - loss: 1.6373 - acc: 0.3999 - val_loss: 1.4294 - val_acc: 0.4960\n",
      "Epoch 5/60\n",
      "40000/40000 [==============================] - 24s 604us/step - loss: 1.5682 - acc: 0.4241 - val_loss: 1.3787 - val_acc: 0.5113\n",
      "Epoch 6/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 1.5111 - acc: 0.4471 - val_loss: 1.3377 - val_acc: 0.5218\n",
      "Epoch 7/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.4661 - acc: 0.4637 - val_loss: 1.3016 - val_acc: 0.5333\n",
      "Epoch 8/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.4249 - acc: 0.4832 - val_loss: 1.2717 - val_acc: 0.5424\n",
      "Epoch 9/60\n",
      "40000/40000 [==============================] - 24s 601us/step - loss: 1.3867 - acc: 0.4947 - val_loss: 1.2360 - val_acc: 0.5560\n",
      "Epoch 10/60\n",
      "40000/40000 [==============================] - 24s 604us/step - loss: 1.3552 - acc: 0.5072 - val_loss: 1.2134 - val_acc: 0.5666\n",
      "Epoch 11/60\n",
      "40000/40000 [==============================] - 24s 600us/step - loss: 1.3257 - acc: 0.5197 - val_loss: 1.1956 - val_acc: 0.5729\n",
      "Epoch 12/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.2965 - acc: 0.5323 - val_loss: 1.1725 - val_acc: 0.5802\n",
      "Epoch 13/60\n",
      "40000/40000 [==============================] - 24s 601us/step - loss: 1.2731 - acc: 0.5415 - val_loss: 1.1534 - val_acc: 0.5880\n",
      "Epoch 14/60\n",
      "40000/40000 [==============================] - 24s 601us/step - loss: 1.2542 - acc: 0.5483 - val_loss: 1.1328 - val_acc: 0.5966\n",
      "Epoch 15/60\n",
      "40000/40000 [==============================] - 24s 605us/step - loss: 1.2252 - acc: 0.5619 - val_loss: 1.1189 - val_acc: 0.6028\n",
      "Epoch 16/60\n",
      "40000/40000 [==============================] - 24s 611us/step - loss: 1.1992 - acc: 0.5677 - val_loss: 1.1042 - val_acc: 0.6073\n",
      "Epoch 17/60\n",
      "40000/40000 [==============================] - 24s 608us/step - loss: 1.1824 - acc: 0.5767 - val_loss: 1.0893 - val_acc: 0.6144\n",
      "Epoch 18/60\n",
      "40000/40000 [==============================] - 24s 607us/step - loss: 1.1628 - acc: 0.5841 - val_loss: 1.0750 - val_acc: 0.6175\n",
      "Epoch 19/60\n",
      "40000/40000 [==============================] - 24s 605us/step - loss: 1.1440 - acc: 0.5901 - val_loss: 1.0651 - val_acc: 0.6215\n",
      "Epoch 20/60\n",
      "40000/40000 [==============================] - 24s 604us/step - loss: 1.1286 - acc: 0.5951 - val_loss: 1.0528 - val_acc: 0.6274\n",
      "Epoch 21/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.1093 - acc: 0.6043 - val_loss: 1.0428 - val_acc: 0.6321\n",
      "Epoch 22/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.0936 - acc: 0.6087 - val_loss: 1.0372 - val_acc: 0.6329\n",
      "Epoch 23/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 1.0787 - acc: 0.6145 - val_loss: 1.0238 - val_acc: 0.6387\n",
      "Epoch 24/60\n",
      "40000/40000 [==============================] - 24s 604us/step - loss: 1.0628 - acc: 0.6201 - val_loss: 1.0248 - val_acc: 0.6353\n",
      "Epoch 25/60\n",
      "40000/40000 [==============================] - 24s 604us/step - loss: 1.0461 - acc: 0.6246 - val_loss: 1.0092 - val_acc: 0.6400\n",
      "Epoch 26/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.0258 - acc: 0.6351 - val_loss: 1.0037 - val_acc: 0.6434\n",
      "Epoch 27/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 1.0137 - acc: 0.6370 - val_loss: 0.9956 - val_acc: 0.6488\n",
      "Epoch 28/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 0.9980 - acc: 0.6454 - val_loss: 0.9887 - val_acc: 0.6507\n",
      "Epoch 29/60\n",
      "40000/40000 [==============================] - 24s 605us/step - loss: 0.9878 - acc: 0.6473 - val_loss: 0.9879 - val_acc: 0.6514\n",
      "Epoch 30/60\n",
      "40000/40000 [==============================] - 24s 599us/step - loss: 0.9745 - acc: 0.6504 - val_loss: 0.9866 - val_acc: 0.6514\n",
      "Epoch 31/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 0.9681 - acc: 0.6555 - val_loss: 0.9719 - val_acc: 0.6586\n",
      "Epoch 32/60\n",
      "40000/40000 [==============================] - 24s 598us/step - loss: 0.9508 - acc: 0.6628 - val_loss: 0.9698 - val_acc: 0.6590\n",
      "Epoch 33/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 0.9338 - acc: 0.6686 - val_loss: 0.9609 - val_acc: 0.6629\n",
      "Epoch 34/60\n",
      "40000/40000 [==============================] - 24s 600us/step - loss: 0.9264 - acc: 0.6688 - val_loss: 0.9599 - val_acc: 0.6623\n",
      "Epoch 35/60\n",
      "40000/40000 [==============================] - 24s 598us/step - loss: 0.9144 - acc: 0.6735 - val_loss: 0.9566 - val_acc: 0.6654\n",
      "Epoch 36/60\n",
      "40000/40000 [==============================] - 24s 598us/step - loss: 0.9011 - acc: 0.6803 - val_loss: 0.9551 - val_acc: 0.6672\n",
      "Epoch 37/60\n",
      "40000/40000 [==============================] - 24s 596us/step - loss: 0.8938 - acc: 0.6819 - val_loss: 0.9496 - val_acc: 0.6688\n",
      "Epoch 38/60\n",
      "40000/40000 [==============================] - 24s 597us/step - loss: 0.8795 - acc: 0.6898 - val_loss: 0.9434 - val_acc: 0.6699\n",
      "Epoch 39/60\n",
      "40000/40000 [==============================] - 24s 594us/step - loss: 0.8757 - acc: 0.6887 - val_loss: 0.9381 - val_acc: 0.6729\n",
      "Epoch 40/60\n",
      "40000/40000 [==============================] - 24s 596us/step - loss: 0.8592 - acc: 0.6949 - val_loss: 0.9435 - val_acc: 0.6712\n",
      "Epoch 41/60\n",
      "40000/40000 [==============================] - 24s 597us/step - loss: 0.8531 - acc: 0.6971 - val_loss: 0.9446 - val_acc: 0.6708\n",
      "Epoch 42/60\n",
      "40000/40000 [==============================] - 24s 600us/step - loss: 0.8427 - acc: 0.7020 - val_loss: 0.9319 - val_acc: 0.6777\n",
      "Epoch 43/60\n",
      "40000/40000 [==============================] - 24s 598us/step - loss: 0.8377 - acc: 0.7023 - val_loss: 0.9241 - val_acc: 0.6813\n",
      "Epoch 44/60\n",
      "40000/40000 [==============================] - 24s 596us/step - loss: 0.8247 - acc: 0.7062 - val_loss: 0.9273 - val_acc: 0.6783\n",
      "Epoch 45/60\n",
      "40000/40000 [==============================] - 24s 596us/step - loss: 0.8162 - acc: 0.7098 - val_loss: 0.9293 - val_acc: 0.6778\n",
      "Epoch 46/60\n",
      "40000/40000 [==============================] - 24s 595us/step - loss: 0.8004 - acc: 0.7176 - val_loss: 0.9291 - val_acc: 0.6802\n",
      "Epoch 47/60\n",
      "40000/40000 [==============================] - 24s 595us/step - loss: 0.7940 - acc: 0.7187 - val_loss: 0.9280 - val_acc: 0.6812\n",
      "Epoch 48/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 0.7864 - acc: 0.7212 - val_loss: 0.9333 - val_acc: 0.6757\n",
      "Epoch 49/60\n",
      "40000/40000 [==============================] - 24s 605us/step - loss: 0.7809 - acc: 0.7242 - val_loss: 0.9142 - val_acc: 0.6863\n",
      "Epoch 50/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 0.7659 - acc: 0.7273 - val_loss: 0.9341 - val_acc: 0.6805\n",
      "Epoch 51/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 0.7595 - acc: 0.7320 - val_loss: 0.9162 - val_acc: 0.6879\n",
      "Epoch 52/60\n",
      "40000/40000 [==============================] - 24s 606us/step - loss: 0.7548 - acc: 0.7325 - val_loss: 0.9238 - val_acc: 0.6849\n",
      "Epoch 53/60\n",
      "40000/40000 [==============================] - 24s 605us/step - loss: 0.7427 - acc: 0.7362 - val_loss: 0.9224 - val_acc: 0.6865\n",
      "Epoch 54/60\n",
      "40000/40000 [==============================] - 24s 603us/step - loss: 0.7320 - acc: 0.7416 - val_loss: 0.9139 - val_acc: 0.6907\n",
      "Epoch 55/60\n",
      "40000/40000 [==============================] - 24s 610us/step - loss: 0.7276 - acc: 0.7405 - val_loss: 0.9120 - val_acc: 0.6903\n",
      "Epoch 56/60\n",
      "40000/40000 [==============================] - 24s 606us/step - loss: 0.7216 - acc: 0.7441 - val_loss: 0.9185 - val_acc: 0.6881\n",
      "Epoch 57/60\n",
      "40000/40000 [==============================] - 24s 604us/step - loss: 0.7146 - acc: 0.7458 - val_loss: 0.9216 - val_acc: 0.6903\n",
      "Epoch 58/60\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 0.6991 - acc: 0.7531 - val_loss: 0.9191 - val_acc: 0.6916\n",
      "Epoch 59/60\n",
      "40000/40000 [==============================] - 24s 605us/step - loss: 0.6874 - acc: 0.7567 - val_loss: 0.9119 - val_acc: 0.6956\n",
      "Epoch 60/60\n",
      "40000/40000 [==============================] - 24s 601us/step - loss: 0.6861 - acc: 0.7563 - val_loss: 0.9221 - val_acc: 0.6895\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_tr, y_tr,  \n",
    "           epochs=60, \n",
    "           verbose = 1,\n",
    "           validation_data = (x_val, y_val)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ZiQwOcXYfmu"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_train_val_acc(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "luPsGGYJYouF",
    "outputId": "db9fe012-c9bc-42b4-ac6f-873423be7aef"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU5fX48c8hhH01oCAgQaRCWIUI\nKGgRQXCDqqggft1FcSl1qRu0UOtSf1q3Fq24tC5R6lIVFFzR4i6hLBWUpRAwrIGwhyWB8/vjuRMm\nk5lkksxkMjPn/XrNK3Pv3Lnz3Elyz73Pch5RVYwxxiSvWrEugDHGmNiyQGCMMUnOAoExxiQ5CwTG\nGJPkLBAYY0ySs0BgjDFJzgKBKUVEUkRkt4gcE8ltY0lEjhORiPeVFpEhIpLjt7xMRE4JZ9tKfNZz\nInJPZd9vTCi1Y10AU3UisttvsQGwHzjoLV+nqlkV2Z+qHgQaRXrbZKCqx0diPyJyDXCpqg7y2/c1\nkdi3MYEsECQAVS0+EXtXnNeo6iehtheR2qpaVB1lM6Y89vcYe1Y1lARE5D4R+aeIvCYiu4BLReQk\nEflWRLaLyAYReVJEUr3ta4uIiki6t/yK9/psEdklIt+ISIeKbuu9fqaILBeRHSLyFxH5SkSuCFHu\ncMp4nYisFJFtIvKk33tTROQxEdkqIquA4WV8PxNFZHrAuqki8qj3/BoR+dE7nv95V+uh9pUrIoO8\n5w1E5GWvbEuAPgHbThKRVd5+l4jICG99d+CvwCletdsWv+92it/7r/eOfauIvCMircP5biryPfvK\nIyKfiEi+iGwUkTv8Pud33neyU0SyReToYNVwIvKl7/fsfZ9zvc/JByaJSCcR+cz7jC3e99bU7/3t\nvWPM815/QkTqeWXu4rddaxEpEJG0UMdrglBVeyTQA8gBhgSsuw84AJyLC/71gROBfri7wmOB5cBN\n3va1AQXSveVXgC1AJpAK/BN4pRLbHgnsAkZ6r90KFAJXhDiWcMr4LtAUSAfyfccO3AQsAdoCacBc\n9+ce9HOOBXYDDf32vRnI9JbP9bYRYDCwF+jhvTYEyPHbVy4wyHv+CPA50BxoDywN2PYioLX3O7nE\nK8NR3mvXAJ8HlPMVYIr3/AyvjL2AesBTwJxwvpsKfs9NgU3ABKAu0ATo6712N7AI6OQdQy/gCOC4\nwO8a+NL3e/aOrQgYD6Tg/h5/AZwO1PH+Tr4CHvE7nh+877Oht/0A77VpwP1+n3Mb8Has/w/j7RHz\nAtgjwr/Q0IFgTjnvux14w3se7OT+N79tRwA/VGLbq4Av/F4TYAMhAkGYZezv9/q/gNu953NxVWS+\n184KPDkF7Ptb4BLv+ZnAsjK2fQ+40XteViBY6/+7AG7w3zbIfn8AzvaelxcIXgQe8HutCa5dqG15\n300Fv+f/A+aF2O5/vvIGrA8nEKwqpwyjfJ8LnAJsBFKCbDcAWA2It7wQOD/S/1eJ/rCqoeTxs/+C\niHQWkfe9W/2dwL1AizLev9HveQFlNxCH2vZo/3Ko+8/NDbWTMMsY1mcBa8ooL8CrwBjv+SXesq8c\n54jId161xXbc1XhZ35VP67LKICJXiMgir3pjO9A5zP2CO77i/anqTmAb0MZvm7B+Z+V8z+1wJ/xg\nynqtPIF/j61E5HURWeeV4R8BZchR1zGhBFX9Cnd3MVBEugHHAO9XskxJywJB8gjsOvkM7gr0OFVt\nAvwed4UeTRtwV6wAiIhQ8sQVqCpl3IA7gfiU1731dWCIiLTBVV296pWxPvAm8CCu2qYZ8FGY5dgY\nqgwicizwNK56JM3b709++y2vq+t6XHWTb3+NcVVQ68IoV6CyvuefgY4h3hfqtT1emRr4rWsVsE3g\n8T2E6+3W3SvDFQFlaC8iKSHK8RJwKe7u5XVV3R9iOxOCBYLk1RjYAezxGtuuq4bPfA/oLSLnikht\nXL1zyyiV8XXgNyLSxms4vLOsjVV1I6764h+4aqEV3kt1cfXWecBBETkHV5cdbhnuEZFm4sZZ3OT3\nWiPcyTAPFxOvxd0R+GwC2vo32gZ4DbhaRHqISF1coPpCVUPeYZWhrO95BnCMiNwkInVFpImI9PVe\new64T0Q6itNLRI7ABcCNuE4JKSIyDr+gVUYZ9gA7RKQdrnrK5xtgK/CAuAb4+iIywO/1l3FVSZfg\ngoKpIAsEyes24HJc4+0zuEbdqFLVTcDFwKO4f+yOwALclWCky/g08CnwX2Ae7qq+PK/i6vyLq4VU\ndTtwC/A2rsF1FC6ghWMy7s4kB5iN30lKVRcDfwG+97Y5HvjO770fAyuATSLiX8Xje/8HuCqct733\nHwOMDbNcgUJ+z6q6AxgKXIALTsuBX3ovPwy8g/ued+Iabut5VX7XAvfgOg4cF3BswUwG+uIC0gzg\nLb8yFAHnAF1wdwdrcb8H3+s5uN/zflX9uoLHbjjcwGJMtfNu9dcDo1T1i1iXx8QvEXkJ1wA9JdZl\niUc2oMxUKxEZjuuhsxfX/bAQd1VsTKV47S0jge6xLku8sqohU90GAqtwdePDgPOscc9Ulog8iBvL\n8ICqro11eeKVVQ0ZY0ySszsCY4xJcnHXRtCiRQtNT0+PdTGMMSauzJ8/f4uqBu2uHXeBID09nezs\n7FgXwxhj4oqIhBxdb1VDxhiT5CwQGGNMkrNAYIwxSS7u2giCKSwsJDc3l3379sW6KKYM9erVo23b\ntqSmhkqfY4yJhYQIBLm5uTRu3Jj09HRcQktT06gqW7duJTc3lw4dOpT/BmNMtUmIqqF9+/aRlpZm\nQaAGExHS0tLsrs2YMmRlQXo61KrlfmZllb0+UhLijgCwIBAH7HdkTGhZWTBuHBQUuOU1a9zyV1/B\niy+WXg8wtrL5ZgMkxB2BMcbEm8Cr/AkTDp/sfQoKYNq04OsnToxcWSwQRMDWrVvp1asXvXr1olWr\nVrRp06Z4+cCBA2Ht48orr2TZsmVlbjN16lSyIn1PaIypdr6r/zVrQNX93Lo1+LYHS03Q6ayNYIq9\nhKkaqoisLBdN166FY46B+++v2i1WWloaCxcuBGDKlCk0atSI22+/vcQ2xZNE1woee//+97+X+zk3\n3nhj5QtpjImZwHPO7t2lr/JDSUkJHgyOKW/y1QpIujuCYJF43LjIN74ArFy5koyMDMaOHUvXrl3Z\nsGED48aNIzMzk65du3LvvfcWbztw4EAWLlxIUVERzZo146677qJnz56cdNJJbN68GYBJkybx+OOP\nF29/11130bdvX44//ni+/tpNzLRnzx4uuOACMjIyGDVqFJmZmcVByt/kyZM58cQT6datG9dffz2+\nLLTLly9n8ODB9OzZk969e5OTkwPAAw88QPfu3enZsycTI3lPakyCCazyueGG8K/+AzVo4N7boEHp\n9fffH8FC+65U4+XRp08fDbR06dJS60Jp317V/TpKPtq3D3sXZZo8ebI+/PDDqqq6YsUKFRGdN29e\n8etbt25VVdXCwkIdOHCgLlmyRFVVBwwYoAsWLNDCwkIFdNasWaqqesstt+iDDz6oqqoTJ07Uxx57\nrHj7O+64Q1VV3333XR02bJiqqj744IN6ww03qKrqwoULtVatWrpgwYJS5fSV49ChQzp69Ojiz+vd\nu7fOmDFDVVX37t2re/bs0RkzZujAgQO1oKCgxHsroyK/K2NqkldececJEffzlVdKrxs/XrVBg5Ln\nFpHg55xgj7S00p8R6rMrCsjWEOfVpKsaClWvFsn6Nn8dO3YkMzOzePm1117j+eefp6ioiPXr17N0\n6VIyMjJKvKd+/fqceeaZAPTp04cvvgg+i+P5559fvI3vyv3LL7/kzjvdPO09e/aka9euQd/76aef\n8vDDD7Nv3z62bNlCnz596N+/P1u2bOHcc88F3AAwgE8++YSrrrqK+vXrA3DEEUdU5qswJm4F69Fz\n5ZUgAr5mwDVr4G9/c6d0f+FO+dKgATzxRPBq6rFjI9dDKJikqxoKVa8Wyfo2fw0bNix+vmLFCp54\n4gnmzJnD4sWLGT58eNB+9XXq1Cl+npKSQlFRUdB9161bt9xtgikoKOCmm27i7bffZvHixVx11VXW\nv98YP+H06CksPBwEfCoyz1daGrRv74JJ+/aud1A0T/ZlSbpAcP/91VDfFsLOnTtp3LgxTZo0YcOG\nDXz44YcR/4wBAwbw+uuvA/Df//6XpUuXltpm79691KpVixYtWrBr1y7eeustAJo3b07Lli2ZOXMm\n4AbqFRQUMHToUF544QX27t0LQH5+fsTLbUy0BRuUFWpdZev0QwkcQuO7+s/JgUOH3M9YBQFIwl5D\nvi87kr2GwtW7d28yMjLo3Lkz7du3Z8CAARH/jJtvvpnLLruMjIyM4kfTpk1LbJOWlsbll19ORkYG\nrVu3pl+/fsWvZWVlcd111zFx4kTq1KnDW2+9xTnnnMOiRYvIzMwkNTWVc889lz/+8Y8RL7sx0RJu\n1c64cVC/fvg9eoIRKXln0KABXH45zJpV/eeccMXdnMWZmZkaODHNjz/+SJcuXWJUopqlqKiIoqIi\n6tWrx4oVKzjjjDNYsWIFtWvXjJhvvytTHYJ116zqVX2g1NSSgQRq9klfROaramaw12rG2cFEzO7d\nuzn99NMpKipCVXnmmWdqTBAwJhoCT/pnnVU6JUMkpKVBo0YlT/AQm9qFSLMzRIJp1qwZ8+fPj3Ux\njImKcE76wXruVERaGuzdW7J6qLwePfEu6RqLjTHxIZyBWX/7W+n6/HCDQGoq+HXQAw6f8KdNqzk9\neqqD3REYY2IqWMoXKN24W5U++lDxqp1EPvEHskBgjImZUKmXg/XcqchJP1jPnUSu2qkqqxoyxlSb\ncFMvV6SHT7A++tdfn1xVO1VlgSACTjvttFKDwx5//HHGjx9f5vsaNWoEwPr16xk1alTQbQYNGkRg\nd9lAjz/+OAV+/01nnXUW27dvD6foxlSbSAzUCvek/9RTNWewVjywQBABY8aMYfr06SXWTZ8+nTFj\nxoT1/qOPPpo333yz0p8fGAhmzZpFs2bNKr0/YyIhnKv/UNLSgmcAsJN+dFggiIBRo0bx/vvvF09C\nk5OTw/r16znllFOK+/X37t2b7t278+6775Z6f05ODt26dQNc+ofRo0fTpUsXzjvvvOK0DgDjx48v\nTmE9efJkAJ588knWr1/PaaedxmmnnQZAeno6W7ZsAeDRRx+lW7dudOvWrTiFdU5ODl26dOHaa6+l\na9eunHHGGSU+x2fmzJn069ePE044gSFDhrBp0ybAjVW48sor6d69Oz169ChOUfHBBx/Qu3dvevbs\nyemnnx6R79bUPOGkaqhq6uVQPXfspB8lodKSRuIBDAeWASuBu4K8/hiw0HssB7aXt89y01BPmKD6\ny19G9jFhQrkpXs8++2x95513VNWlgr7ttttU1aWb3rFjh6qq5uXlaceOHfXQoUOqqtqwYUNVVV29\nerV27dpVVVX//Oc/65VXXqmqqosWLdKUlJTiNNa+9M9FRUX6y1/+UhctWqSqqu3bt9e8vLzisviW\ns7OztVu3brp7927dtWuXZmRk6H/+8x9dvXq1pqSkFKenvvDCC/Xll18udUz5+fnFZX322Wf11ltv\nVVXVO+64Qyf4fSf5+fm6efNmbdu2ra5atapEWQNZGur49sorpdMsp6aq1qkT+dTLJrKIRRpqEUkB\npgJDgVxgnojMUNXiLGiqeovf9jcDJ0SrPNHmqx4aOXIk06dP5/nnnwdcoL3nnnuYO3cutWrVYt26\ndWzatIlWrVoF3c/cuXP59a9/DUCPHj3o0aNH8Wuvv/4606ZNo6ioiA0bNrB06dISrwf68ssvOe+8\n84ozoJ5//vl88cUXjBgxgg4dOtCrVy+gZBprf7m5uVx88cVs2LCBAwcO0KFDB8ClpfavCmvevDkz\nZ87k1FNPLd7GUlUnhnBm1iosLP2+SKReNtUnmt1H+wIrVXUVgIhMB0YCpdNhOmOAyVX+VK/6o7qN\nHDmSW265hf/85z8UFBTQp08fwCVxy8vLY/78+aSmppKenl6plM+rV6/mkUceYd68eTRv3pwrrrii\nSqmjfSmswaWxDlY1dPPNN3PrrbcyYsQIPv/8c6ZMmVLpzzM1W7h9+asqWF9+CwKxF802gjbAz37L\nud66UkSkPdABmBPi9XEiki0i2Xl5eREvaCQ0atSI0047jauuuqpEI/GOHTs48sgjSU1N5bPPPmNN\nOf9Np556Kq+++ioAP/zwA4sXLwZcCuuGDRvStGlTNm3axOzZs4vf07hxY3bt2lVqX6eccgrvvPMO\nBQUF7Nmzh7fffptTTjkl7GPasWMHbdq4X9mLL75YvH7o0KFMnTq1eHnbtm3079+fuXPnsnr1asBS\nVceTUNO3VqRxN5iannq5xlKFau71V1Mai0cDb6pqkCmaQVWnqWqmqma2bNmymosWvjFjxrBo0aIS\ngWDs2LFkZ2fTvXt3XnrpJTp37lzmPsaPH8/u3bvp0qULv//974vvLHr27MkJJ5xA586dueSSS0qk\nsB43bhzDhw8vbiz26d27N1dccQV9+/alX79+XHPNNZxwQvi1b1OmTOHCCy+kT58+tGjRonj9pEmT\n2LZtG926daNnz5589tlntGzZkmnTpnH++efTs2dPLr744rA/x0RPOA27Ve3LHypVg/Xlr4Ddu2HG\nDBg/Ho49Fpo3h1NOgTffhApMOlVZUUtDLSInAVNUdZi3fDeAqj4YZNsFwI2q+nV5+7U01PHNflfV\nJ3DULgRPnVxRiZyFs0wFBfDlly4jXd26UK/e4Z+tW8NRR5W+DfJRhbw8WL0aNm50j02b3M+ffnL7\nLSx0X+zpp0PXrvDqq+626Zhj4MYb4ZproAptb2WloY5mIKiN6wl0OrAOmAdcoqpLArbrDHwAdNAw\nCmOBIL7Z76r6pKdXrV4/VBbOuL6y37oVli6FHj0gYMKmoH7+Gd57zz3mzIGy2uWaNoXOnQ8/RGDZ\nMnei/+kn2Lat9HvS0tyJfsgQGD4cBg48fHt18CDMnOnq0z7/3H35Tz3lJjyohJjMR6CqRSJyE/Ah\nkAK8oKpLROReXDemGd6mo4Hp4QQBY4wTqnHXf11VgoCvPj9wnzXySn/vXnjwQXdFfe21rmol0K5d\n8Nhj8Mgj7rmIO1n37Qv9+kGXLrB5szvxr13rfi5fDku869Zjj4XrrnN5r1u0gP373WPfPvf4+efD\nJ/yPP3a5scHdKXTuDKNHu58dO0KrVu7RsmXpOjV/KSnwq1+5x6JF8Je/QPfukf/+SKAZyjp37oyE\nui0zNYKq8tNPP9kdQRWFW+UTmHitLHHbm2f5crjoIneiTElxrdDDhrkRbWed5YLD00/DAw/Ali1w\n/vlw6aXuBP/dd+4R2AGlUSNo1841bAweDOecc/gKP1w7d7ovP5y7jmqS8DOU1atXj61bt5KWlmbB\noIZSVbZu3Uq9evViXZS4N3Fi+H35A4NBqOkVK92Xf9cuV7/92Weu+kLEXWX7rrSPO861SodSWHj4\nynvZMld1k5/vHlu3wp49MHQoXH01ZGSUfO8//+nqzevWdXND9ugBzz7rHiNGuIh26BDk5sIZZ8B9\n98GJJ7r3nnfe4S9pzRpYscJdpbdr507eVT2PNGlStfdXs4S4IygsLCQ3N7dK/epN9NWrV4+2bduS\nmpoa66LElcBqoIpW+bRvH+GG3fx8d5X9/vswb57r1ZKaCv37u5N+drY7gQM0a+auphs0cLml69d3\njasHDri6+mXLSkaxJk1cg2hamvsp4oJMYSGcfLI78Y8YAZMmuQkKTj4Zpk93J3CfwkLXA+eZZ1w9\n++9+B4MGVexLS0AxaSyOlmCBwJhEUd5UjFCxKp/27V3Hk4jIy4NHH4W//tV1d+zXz1WdDB7sTsi+\nLHEHD7qT/Pffu6qX1atdPb7/IyXF1ct363b4cfzxLkgE2rwZXn4ZnnvO1cH7voDf/tZFMbuwCIsF\nAmNqmHBG8kLok364VT4levjs3QsLFriT8/ffuwjRpo0rQPv27tGunXujf/fIPXvgySfdXcDevXDx\nxa7wXqLEaqMKX38N//qX62Vz5pnV+/lxzgKBMTVIsMZeX81JRfLz+1f5PDh5Hw3yc5n+8M/Ipo10\nar6FCwZtoUfrLa6RdOVKWLz48OCkdu1c/f2GDa6uKUiKkRJq1YJLLnEBoJxBkaZmSvjGYmNqsnAS\ntxUUlJ3OoQF7OJZVpJNDB1bTs/Fqrj4hB45Y47ouXuXSjo/0vWEb8I64evYWLdyJ/7e/ddU5ffu6\nbo0+qi5YrF3rGlb37nVdIn1dJA8ehHPPdYHDJCQLBMZEUbA5eX1qcZBjWMt+6rKHhuyhIQepjXCI\n41lGf77lJL6hP9/SjR+oxeG796IDDWBFBxdZTjzRneh9j9atXR/15s1dXXx5RNz2LVuCl9LEJBcL\nBMZEUHlX/0ezjmF8yDA+ZAifkEbJ5Hz7qcMhalEf1wNuG81Y364ff9l5Ht/syGBfq3Qu/V0HRo1v\nWfUujsZ4LBAYEyFZWTD+2iLO25tFP76j7pr91GU/9dhHXfaTTg7d+QGA9bRmJufyFQOoxSGap+5h\nzIg91N6/h2/+fYCvd3VnzdH9uepPxzP2/2rRFZgQ28MzCcwCgTGV5H/1n97uIMPyX2P+3j/QiZVs\noxl7aMh+6rKPeuynLus5mpe4jA8ZxvojutOosZToNdTT693TFbgmpkdmko0FAmPCEKp//96CQ4zi\nTaasnUIGP7KQnozgXWZyLhC86qZBA5j2ZJykcDBJwQKBMYWF7gy/ahX8738sfW8Vqz7LIbVgBy3q\n7qJVw10M2LabebqbFA7CGuBpuA+oTRFN2MUSMhjFG/yL89GAaT7iNo+PSRoWCExyKiqCDz6A5593\nqRL80hx0pA61aU8+R5C/vzFr9x/FLhqzm0YUBfmX+ZqTeYMLOUTpHjo2J6+JBxYITHJZtgz+/ndX\nr7NxIxx5pJsVqmdP6NiRk8Yey3fr2pS6qg+XXf2beGSBwCS2tWth7lz3+OILl6smJQXOPpt/d7yK\nq986i1V/SS0+aX+3HsIdax+Y5sGu/k28skBg4oeqS5PQpImbfitYP/qiIpcO+Y034MMPi0dwHWjQ\nlLl6CrO5lrmtL+HENq148ZmSA73GjXMDcYOleQh20r/8cpf92K7+TbyzQGBqvt27Xbedp55ygQCg\nbVs3ufepp7qfGzfC66+7hGRbtkDDhm6Ckttu4/1dpzL6vm7s3uvV4efC/L+VTuZWUODy/TRoUDoP\nkJ30TSKzQGBqFlWX52bHDpf35h//gJdechOg9OrlMmAeOuSqej7/HF577fB7GzZ0OXEuusjN/1q/\nPgA3psPuvaU/Jpj8fJfxuMZPz2hMBFn2URM7Bw+6evs33nDzvObnuwDgy5AJLg3yRRe5Bt3+/UtW\nB6nC//7nZshq2rTEyd9frVoxyt9vTA1i2UdNzeG7mn/jDXjrLdi0yZ28hw511T1Nm7o2gKZNXdK0\nIUNc9sxgRFxGzICsmIGDvypS7++bF8CYZGKBwFSP/HzXbfOpp9zArfr14eyz4cIL3c+GDSu12/Jm\n9Fqzxk3aUqdO6UlbrN7fGMcCgYmuBQtg6lR3xt63DwYOhD/+EUaOrPTJ3ydYiue/BWkELiy0/v3G\nlMUCgYms/fvhq69g9mz3WLLEXX7/3//BjTe6gVuVFM4EL2U1Am/ZUumPNiahWSAwVXPgACxaBN98\nA59+6h579rj6mFNPdZfsl10GzZpV6WPKmuAlHMccU6WPNyahWSAwFaMKH33kevl8+y3Mn++qfMAN\n8rrsMtd7Z/BgVxdTSeFc/YdijcDGVIwFAhMeVZecbcoUd/KvU8dNa3jDDa5bZ//+bprECKjK1b81\nAhtTcRYITNlUXV3/lCkwbx506AAvvACXXOL6+FdR4JX//fe75XCv/q0R2Jiqi2ogEJHhwBNACvCc\nqv4pyDYXAVNwub4Wqeol0SyTCVNODrz9Nrz6KmRnu5FWzz3nqn5SUyPyEcGu/P2Xy2NJ3oyJjKgF\nAhFJAaYCQ4FcYJ6IzFDVpX7bdALuBgao6jYROTJa5TFh+PFHN8jrX/9y3T4BevSAZ56BK65w1UER\nFOzKv6DAJQc9eLD09nb1b0x0RPOOoC+wUlVXAYjIdGAksNRvm2uBqaq6DUBVN0exPCaYgwdh5kx4\n7DE34hfgpJPg4YfhvPOgY8eIfVRgNVCouv+DB4MnfrOrf2Oio3Kzb4SnDfCz33Kut87fL4BfiMhX\nIvKtV5VkqsOuXe7M+otfuBP+mjXu5L9uHXz9Ndx+e8SDwLhx7mNU3c9gWaTB1UJNm+Z+ihxetiBg\nTHTEurG4NtAJGAS0BeaKSHdV3e6/kYiMA8YBHGMdwqvmwAF39f/AA7BzJwwYAA89BL/6FdSO3J9D\nuIO/QnX1HDvWTvzGVJdo3hGsA/z7E7b11vnLBWaoaqGqrgaW4wJDCao6TVUzVTWzZcuWUStwwvv8\nc5fK+a67YNAg+O47l7lz1KiIB4HAq/9gSd/AvW5X/sbEVjTvCOYBnUSkAy4AjAYCewS9A4wB/i4i\nLXBVRauiWKbktGmTq+p55RXX/fO991yitwipyuAvS/tsTOxFLRCoapGI3AR8iOs++oKqLhGRe4Fs\nVZ3hvXaGiCwFDgK/VdUQ146mwg4ccBO5TJ7szsyTJsHdd7v6lwip6uAvG/FrTOzZxDSJSNV1Ab3r\nLli50uX0/+tf4fjjI/5R6enhn/yt+6cxsVPWxDTRbCMwsfDtty7V86hRbuTvrFkuN1CEgkBWljv5\n16pVsSDg6/6Zk+PmpsnJsSBgTE1hgSBRLF3qTv4nneQmfnn2WVi4EM48M3Q/zQqqSBfQtDRrBDYm\nXsS6+6ipqlWrXB6grCx32T15smsYrkLmz1CCjQQO1QXUBn8ZEz/sjiBe5ebCdde5Kp833oBbb4XV\nq11QiFAQCLcayLqAGhPf7I4g3ixcCI8+Cq+95s68113nLtVbt47oxwTrDRR45e9jXUCNiW8WCOLB\noUMuFfSjj8KcOW6u3xtugFtucZfqUVCRaiDrAmpMfLOqoZpu8WI3Gvicc2DZMpcOIjfXVcJHMAhY\nNZAxycvuCGoqVTcBzE03uXTOuxYAABS8SURBVPl+X34ZLroo4qmgwaqBjEl2Fghqoj17YPx4d/I/\n/XR3pj7qqKh9nFUDGZPcrGqoplmyBE480eUF+sMf4MMPoxoEwI30DcaqgYxJDnZHUJN88AFccAE0\nbgyffAKDB1fLx4aaJMaqgYxJDnZHUFO8+y6MHOkmilmwIGpBILBROCvLVfcE5qGzaiBjkocFgprg\njTdceogTTnDdQyM8JsAnWIqIcePcazYjmDHJy6qGYu3ll93E8CefDO+/D02aRGzX4cwTUFDgtrEk\ncMYkLwsEsfTss25k8ODBrmqoYcOI7boi8wSEaiw2xiQHqxqKhd274Te/cWfqM8+EmTMjGgQgeJfQ\nUGwaaGOSW7mBQERuFpHm1VGYpPDRR9C9uxsZfOONbgKZ+vWrvNuqzBNgjcLGJLdw7giOAuaJyOsi\nMlwkQsntk01+vmsLGDbMTRjzxRdu1rC6dau8a5snwBhTFeUGAlWdBHQCngeuAFaIyAMi0jHKZUsc\ns2ZBly6HW28XLnSziEVIWSOD/dksYcaYYMJqI1A3sfFG71EENAfeFJH/F8WyxT9V+NOfXMK4Vq1g\n3jy47z6oVy+iH2Mjg40xVVFuryERmQBcBmwBngN+q6qFIlILWAHcEd0ixqmCArjmGjdvwMUXuwRy\ngaO2IsRGBhtjqiKcO4IjgPNVdZiqvqGqhQCqegg4J6qli1e5uXDqqTB9OjzwgAsGEQwCgQ3DZ51l\nI4ONMZUXTiCYDeT7FkSkiYj0A1DVH6NVsLj11VeQmQnLl7uxAXffHbHJ4yF4w/CLL8Lll1s1kDGm\ncsIZUPY00NtveXeQdebQIXjkEbjnHneZPmcOZGRE/GOCNQwXFLj2aKsGMsZURjiBQLzGYsBVCYmI\njUj2l5fnLslnz3Y5g557Dpo2jcpHhWoYttHBxpjKCqdqaJWI/FpEUr3HBGBVtAsWN774wk0lOWcO\nPPUUvP561IIAhB4FbKODjTGVFU4guB44GVgH5AL9gHHRLFTc+POfYdAglx7i22/drGIRHm9nDcPG\nmGgrt4pHVTcDo6uhLPHlySfh9ttdVdALL7jJZCIsWOI4X8PwrFmHs4ref781DBtjKi+ccQT1gKuB\nrkDxSChVvSqM9w4HngBSgOdU9U8Br18BPIy72wD4q6o+F27hYyYrCyZMgF/9ynUNrR2dJhNrGDbG\nVIdwqoZeBloBw4B/A22BXeW9SURSgKnAmUAGMEZEgnWj+aeq9vIeNT8IzJ7tcgYNGhTVIADWMGyM\nqR7hBILjVPV3wB5VfRE4G9dOUJ6+wEpVXaWqB4DpwMjKF7UG+PprN6dwjx5ujECEU0UEtgcccUTw\n7axh2BgTSeEEgkLv53YR6QY0BY4M431tgJ/9lnO9dYEuEJHFIvKmiLQLtiMRGSci2SKSnZeXF8ZH\nR8F//wtnnw3t2rm7ggjOJAbBB4rt3Al16pTczhqGjTGRFk4gmObNRzAJmAEsBR6K0OfPBNJVtQfw\nMfBisI1UdZqqZqpqZsuWLSP00RWwd6/rrtOwoZtP4Mhw4mDFBGsPKCx0bdA2YtgYE01lVnB7ieV2\nquo2YC5wbAX2vQ7wv8Jvy+FGYQBUdavf4nNAzcxm+o9/uPxBc+a4s3EUhKr3z8+HLVui8pHGGAOU\nc0fgJZarbHbReUAnEekgInVwXVBn+G8gIq39FkcANS93UVGRSx3Rr59rII6AwLaArCwbKGaMiZ1w\nqoY+EZHbRaSdiBzhe5T3JlUtAm4CPsSd4F9X1SUicq+IjPA2+7WILBGRRcCvcRPf1CxvvQWrVsGd\nd0ZksFiwtoBx42ygmDEmdsQvjVDwDURWB1mtqlqRaqKIyczM1Ozs7Or5MFXo08dV3i9d6i7hqyjU\nfMLt27uT/sSJNlDMGBN5IjJfVTODvRbOyOIOkS9SnPjkE1iwwCWRi0AQgLLHBowdayd+Y0z1C2dk\n8WXB1qvqS5EvTg3z0ENw9NFw6aUR22Wo2cSsLcAYEyvhXOae6Pc4BZiCa9hNbPPnw6efwm9+A3Xr\nRmy3999vbQHGmJolnKqhm/2XRaQZbpRwYnvoIZdO+rrrIrpbX9WPtQUYY2qKyiTK2QMkdrvBypWu\nt9Add0R8BDFYW4AxpmYpt2pIRGaKyAzv8R6wDHg7+kWLoUcegdRUl2G0ioKNGTDGmJoknDuCR/ye\nFwFrVDU3SuWJvY0b3Ujiyy+HVq2qtKtg8wmM86b0sTsCY0xNEU5j8VrgO1X9t6p+BWwVkfSoliqW\nHn3UJfm5/fYq7yrUfAITJ1Z518YYEzHhBII3gEN+ywe9dYln61Y37/Do0dCpU5V3Z/MJGGPiQTiB\noLY3nwAA3vM6ZWwfv558EvbsgbvvjsjuLH+QMSYehBMI8vxyAyEiI4HEy4e5c6cLBOedB926RWSX\nNmbAGBMPwgkE1wP3iMhaEVkL3AlEtnN9TfDUU7B9e5Uq8AN7CIGbP8DmEzDG1GThDCj7H9BfRBp5\ny7ujXqrqVlDgGomHDXNJ5iohVA+hadNsonljTM0WzjiCB0SkmaruVtXdItJcRO6rjsJVm2efhbw8\nmDSp0ruwHkLGmHgVTtXQmaq63bfgzVZ2VvSKVM3274eHH4ZTT4WBAyu9G+shZIyJV+EEghQRKc66\nJiL1gchlYYu1F1+EdeuqdDcA1kPIGBO/wgkEWcCnInK1iFxDGZPMx52iIvjTn+DEE2HIkCrtynoI\nGWPiVTiNxQ95U0kOARQ39WR0ZnCvbu+9B6tXu4biKk5DaVlFjTHxKtzso5twQeBCYDXwVtRKVJ3e\nf99lFz377IjszrKKGmPiUciqIRH5hYhMFpGfgL/gcg6Jqp6mqn+tthJGiyrMmgVDh7pMoxVkWUWN\nMYmirDuCn4AvgHNUdSWAiNxSLaWqDosXw/r1cFbFO0BZVlFjTCIpq7H4fGAD8JmIPCsipwNVq0iv\nSWbPdj+HD6/wW23MgDEmkYQMBKr6jqqOBjoDnwG/AY4UkadF5IzqKmDUzJoFvXq5yekryMYMGGMS\nSbndR1V1j6q+qqrnAm2BBbh8Q/Fr+3b4+utKVQuBjRkwxiSWcMYRFFPVbao6TVVPj1aBqsXHH8PB\ng3DmmZV6u40ZMMYkkgoFgoQxezY0awb9+1fq7WPHWlZRY0ziCHccQeI4dMgFgjPOgNqVP3wbM2CM\nSRTJd0ewcKGboL6S7QPGGJNoohoIRGS4iCwTkZUiclcZ210gIioimdEsD1CpbqM2eMwYk8iiVjUk\nIinAVGAokAvME5EZqro0YLvGwATgu2iVpYRZs9zkM0cdFdbmNnjMGJPoonlH0BdYqaqrvAnvpwMj\ng2z3R+AhYF8Uy+Lk58O331aoWsgGjxljEl00A0Eb4Ge/5VxvXTER6Q20U9X3y9qRiIwTkWwRyc7L\ny6t8iT76yDUWV6DbqA0eM8Ykupg1FotILeBR4LbytvXGLmSqambLli0r/6GzZsERR0DfvmG/xQaP\nGWMSXTQDwTqgnd9yW2+dT2OgG/C5iOQA/YEZUWswPnQIPvjATVCfkhL222zwmDEm0UUzEMwDOolI\nBxGpA4wGZvheVNUdqtpCVdNVNR34FhihqtlRKc38+W6C+gp2G7XBY8aYRBe1XkOqWiQiN+FmNEsB\nXlDVJSJyL5CtqjPK3kOEzZ7tzuTDhlX4rTZ4zBiTyERVY12GCsnMzNTs7ErcNGzfDt9/70YUG2NM\nkhGR+aoatOo9eUYWN2tmQcAYY4JInkBgjDEmKAsExhiT5CwQGGNMkrNAEMASzBljkk3yzUdQBksw\nZ4xJRnZH4McSzBljkpEFAj+WYM4Yk4wsEPixBHPGmGRkgcCPJZgzxiQjCwR+LMGcMSYZWa+hAJZg\nzhiTbOyOwBhjkpwFAmOMSXIWCIwxJslZIDDGmCRngcAYY5KcBQJjjElyFgiMMSbJWSAwxpgkZ4HA\nGGOSXNIGApuAxhhjnKRMMWET0BhjzGFJeUdgE9AYY8xhSRkIbAIaY4w5LCkDgU1AY4wxhyVlILAJ\naIwx5rCoBgIRGS4iy0RkpYjcFeT160XkvyKyUES+FJGMaJbHxyagMcaYw0RVo7NjkRRgOTAUyAXm\nAWNUdanfNk1Udaf3fARwg6oOL2u/mZmZmp2dHZUyG2NMohKR+aqaGey1aN4R9AVWquoqVT0ATAdG\n+m/gCwKehkB0opIxxpiQojmOoA3ws99yLtAvcCMRuRG4FagDDI5ieYwxxgQR88ZiVZ2qqh2BO4FJ\nwbYRkXEiki0i2Xl5edVbQGOMSXDRDATrgHZ+y229daFMB34V7AVVnaaqmaqa2bJlywgW0RhjTDQD\nwTygk4h0EJE6wGhghv8GItLJb/FsYEUUy2OMMSaIqLURqGqRiNwEfAikAC+o6hIRuRfIVtUZwE0i\nMgQoBLYBl0erPMYYY4KLatI5VZ0FzApY93u/5xOi+fnGGGPKF/PGYmOMMbFlgcAYY5KcBQJjjEly\nFgiMMSbJWSAwxpgkZ4HAGGOSnAUCY4xJchYIjDEmyVkgMMaYJGeBwBhjkpwFAmOMSXIWCIwxJslZ\nIDDGmCRngcAYY5KcBQJjjElyFgiMMSbJWSAwxpgkZ4HAGGOSnAUCY4xJchYIjDEmyVkgMMaYJGeB\nwBhjklxSBIKsLEhPh1q13M+srFiXyBhjao7asS5AtGVlwbhxUFDgltesccsAY8fGrlzGGFNTJPwd\nwcSJh4OAT0GBW2+MMSYJAsHatRVbb4wxySbhA8Exx1RsvTHGJJuEDwT33w8NGpRc16CBW2+MMSbK\ngUBEhovIMhFZKSJ3BXn9VhFZKiKLReRTEWkf6TKMHQvTpkH79iDifk6bZg3FxhjjI6oanR2LpADL\ngaFALjAPGKOqS/22OQ34TlULRGQ8MEhVLy5rv5mZmZqdnR2VMhtjTKISkfmqmhnstWjeEfQFVqrq\nKlU9AEwHRvpvoKqfqaqvT8+3QNsolscYY0wQ0QwEbYCf/ZZzvXWhXA3MDvaCiIwTkWwRyc7Ly4tg\nEY0xxtSIxmIRuRTIBB4O9rqqTlPVTFXNbNmyZfUWzhhjElw0RxavA9r5Lbf11pUgIkOAicAvVXV/\nFMtjjDEmiGjeEcwDOolIBxGpA4wGZvhvICInAM8AI1R1cxTLYowxJoSo9RoCEJGzgMeBFOAFVb1f\nRO4FslV1hoh8AnQHNnhvWauqI8rZZx6wppJFagFsqeR7a6JEOp5EOhaw46nJEulYIPzjaa+qQevW\noxoIahoRyQ7VfSoeJdLxJNKxgB1PTZZIxwKROZ4a0VhsjDEmdiwQGGNMkku2QDAt1gWIsEQ6nkQ6\nFrDjqckS6VggAseTVG0ExhhjSku2OwJjjDEBLBAYY0ySS5pAUF5K7JpORF4Qkc0i8oPfuiNE5GMR\nWeH9bB7LMoZLRNqJyGdeCvIlIjLBWx+vx1NPRL4XkUXe8fzBW99BRL7z/ub+6Q2sjAsikiIiC0Tk\nPW85no8lR0T+KyILRSTbWxevf2vNRORNEflJRH4UkZMicSxJEQi8lNhTgTOBDGCMiGTEtlQV9g9g\neMC6u4BPVbUT8Km3HA+KgNtUNQPoD9zo/T7i9Xj2A4NVtSfQCxguIv2Bh4DHVPU4YBsusWK8mAD8\n6Lccz8cCcJqq9vLrbx+vf2tPAB+oamegJ+53VPVjUdWEfwAnAR/6Ld8N3B3rclXiONKBH/yWlwGt\nveetgWWxLmMlj+td3LwVcX88QAPgP0A/3GjP2t76En+DNfmBywv2KTAYeA+QeD0Wr7w5QIuAdXH3\ntwY0BVbjdfKJ5LEkxR0BFU+JHS+OUlVfeo6NwFGxLExliEg6cALwHXF8PF5VykJgM/Ax8D9gu6oW\neZvE09/c48AdwCFvOY34PRYABT4SkfkiMs5bF49/ax2APODvXrXdcyLSkAgcS7IEgoSn7nIgrvoC\ni0gj4C3gN6q60/+1eDseVT2oqr1wV9N9gc4xLlKliMg5wGZVnR/rskTQQFXtjasavlFETvV/MY7+\n1moDvYGnVfUEYA8B1UCVPZZkCQRhpcSOQ5tEpDWA9zNuMriKSCouCGSp6r+81XF7PD6quh34DFd9\n0kxEfKne4+VvbgAwQkRycLMKDsbVS8fjsQCgquu8n5uBt3GBOh7/1nKBXFX9zlt+ExcYqnwsyRII\nyk2JHadmAJd7zy/H1bXXeCIiwPPAj6r6qN9L8Xo8LUWkmfe8Pq6940dcQBjlbRYXx6Oqd6tqW1VN\nx/2fzFHVscThsQCISEMRaex7DpwB/EAc/q2p6kbgZxE53lt1OrCUSBxLrBtAqrGh5SxgOa7udmKs\ny1OJ8r+GS9ddiLsyuBpXd/spsAL4BDgi1uUM81gG4m5fFwMLvcdZcXw8PYAF3vH8APzeW38s8D2w\nEngDqBvrslbwuAYB78XzsXjlXuQ9lvj+9+P4b60XkO39rb0DNI/EsViKCWOMSXLJUjVkjDEmBAsE\nxhiT5CwQGGNMkrNAYIwxSc4CgTHGJDkLBMZ4ROSgl6HS94hYIjIRSffPHGtMTVK7/E2MSRp71aWJ\nMCap2B2BMeXw8tn/Py+n/fcicpy3Pl1E5ojIYhH5VESO8dYfJSJve/MTLBKRk71dpYjIs96cBR95\no5ARkV97czMsFpHpMTpMk8QsEBhzWP2AqqGL/V7boardgb/isnMC/AV4UVV7AFnAk976J4F/q5uf\noDduRCtAJ2CqqnYFtgMXeOvvAk7w9nN9tA7OmFBsZLExHhHZraqNgqzPwU08s8pLlrdRVdNEZAsu\nD3yht36DqrYQkTygraru99tHOvCxuslDEJE7gVRVvU9EPgB241IGvKOqu6N8qMaUYHcExoRHQzyv\niP1+zw9yuI3ubNwMer2BeX5ZPo2pFhYIjAnPxX4/v/Gef43L0AkwFvjCe/4pMB6KJ6xpGmqnIlIL\naKeqnwF34mahKnVXYkw02ZWHMYfV92YZ8/lAVX1dSJuLyGLcVf0Yb93NuNmifoubOepKb/0EYJqI\nXI278h+PyxwbTArwihcsBHhS3ZwGxlQbayMwphxeG0Gmqm6JdVmMiQarGjLGmCRndwTGGJPk7I7A\nGGOSnAUCY4xJchYIjDEmyVkgMMaYJGeBwBhjktz/ByNYNK04ovS6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h+nBLlcCkpaxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_val_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahljEKwtfGW1"
   },
   "source": [
    "### 1.Tune structure of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kEC1wyqvHxMe"
   },
   "outputs": [],
   "source": [
    "def create_model(dropout_rate = 0.5,lr = 1e-2 ):\n",
    "    \n",
    "    #build model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optimizers.RMSprop(lr = lr),\n",
    "                metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0a8-JMIeJ3Tk"
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "model = KerasClassifier(build_fn = create_model, batch_size = 1000, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9FNP4AdKV8-"
   },
   "outputs": [],
   "source": [
    "lr = [1e-2, 1e-3, 1e-4]\n",
    "dropout_rate = [0.3, 0.5, 0.7]\n",
    "param_grid = dict(lr = lr, dropout_rate = dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WQYHh1eCUHj"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "grid = RandomizedSearchCV(estimator = model, cv = KFold(5), \n",
    "              param_distributions = param_grid,\n",
    "              verbose = 20, \n",
    "              n_iter = 10, n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YNZc942RCX3e",
    "outputId": "a170b374-efb1-48c5-d3be-1f30df34b93c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] lr=0.01, dropout_rate=0.3 .......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 7s 172us/step - loss: 3.7218 - acc: 0.1365\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.9680 - acc: 0.2621\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.7191 - acc: 0.3516\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.5314 - acc: 0.4310\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3763 - acc: 0.4901\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2357 - acc: 0.5499\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.1306 - acc: 0.5874\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0282 - acc: 0.6301\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9386 - acc: 0.6652\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8577 - acc: 0.6938\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7823 - acc: 0.7220\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7194 - acc: 0.7449\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6489 - acc: 0.7711\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6064 - acc: 0.7854\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5372 - acc: 0.8107\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4970 - acc: 0.8248\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4460 - acc: 0.8441\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4067 - acc: 0.8587\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3701 - acc: 0.8702\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3267 - acc: 0.8860\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2953 - acc: 0.8961\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2729 - acc: 0.9051\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2456 - acc: 0.9147\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2203 - acc: 0.9233\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2060 - acc: 0.9284\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1966 - acc: 0.9329\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1756 - acc: 0.9398\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1647 - acc: 0.9449\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1560 - acc: 0.9465\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1418 - acc: 0.9523\n",
      "10000/10000 [==============================] - 1s 66us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.3, score=0.717, total= 2.5min\n",
      "[CV] lr=0.01, dropout_rate=0.3 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 3.9443 - acc: 0.1132\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 2.0649 - acc: 0.2288\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.7534 - acc: 0.3351\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.5478 - acc: 0.4187\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.3766 - acc: 0.4897\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.2451 - acc: 0.5418\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.1397 - acc: 0.5880\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0400 - acc: 0.6236\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9427 - acc: 0.6612\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8605 - acc: 0.6952\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7815 - acc: 0.7242\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7110 - acc: 0.7496\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6548 - acc: 0.7688\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5890 - acc: 0.7923\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5423 - acc: 0.8082\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4779 - acc: 0.8322\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4377 - acc: 0.8472\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4025 - acc: 0.8597\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3582 - acc: 0.8752\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3296 - acc: 0.8841\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2904 - acc: 0.9002\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2677 - acc: 0.9069\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2390 - acc: 0.9174\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2234 - acc: 0.9236\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2038 - acc: 0.9323\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1894 - acc: 0.9351\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1757 - acc: 0.9395\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1587 - acc: 0.9471\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1563 - acc: 0.9467\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1375 - acc: 0.9535\n",
      "10000/10000 [==============================] - 1s 73us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.3, score=0.674, total= 2.5min\n",
      "[CV] lr=0.01, dropout_rate=0.3 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 3.4553 - acc: 0.1232\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 2.0526 - acc: 0.2014\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.8214 - acc: 0.3031\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.6079 - acc: 0.3902\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.4438 - acc: 0.4636\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2950 - acc: 0.5240\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1650 - acc: 0.5759\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0588 - acc: 0.6190\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9609 - acc: 0.6562\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8777 - acc: 0.6885\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8060 - acc: 0.7167\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7386 - acc: 0.7393\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6699 - acc: 0.7666\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6140 - acc: 0.7861\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5618 - acc: 0.8048\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5135 - acc: 0.8216\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4657 - acc: 0.8355\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4167 - acc: 0.8541\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3711 - acc: 0.8696\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3428 - acc: 0.8795\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3104 - acc: 0.8914\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2837 - acc: 0.9000\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2537 - acc: 0.9121\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2233 - acc: 0.9222\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2169 - acc: 0.9260\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1976 - acc: 0.9316\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1708 - acc: 0.9417\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1723 - acc: 0.9405\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1614 - acc: 0.9462\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1378 - acc: 0.9540\n",
      "10000/10000 [==============================] - 1s 80us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.3, score=0.587, total= 2.5min\n",
      "[CV] lr=0.01, dropout_rate=0.3 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 3.8744 - acc: 0.1217\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 2.0676 - acc: 0.2274\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.7553 - acc: 0.3373\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.5420 - acc: 0.4272\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3728 - acc: 0.4937\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.2364 - acc: 0.5464\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.1182 - acc: 0.5974\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0120 - acc: 0.6369\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9194 - acc: 0.6726\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8378 - acc: 0.7031\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7610 - acc: 0.7327\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6933 - acc: 0.7566\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6309 - acc: 0.7797\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5707 - acc: 0.7983\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5162 - acc: 0.8182\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4613 - acc: 0.8400\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4165 - acc: 0.8528\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3800 - acc: 0.8660\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3282 - acc: 0.8833\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3052 - acc: 0.8943\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2677 - acc: 0.9065\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2470 - acc: 0.9137\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2283 - acc: 0.9215\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2110 - acc: 0.9280\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1933 - acc: 0.9322\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1764 - acc: 0.9405\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1596 - acc: 0.9459\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1537 - acc: 0.9481\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1450 - acc: 0.9510\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1382 - acc: 0.9537\n",
      "10000/10000 [==============================] - 1s 89us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.3, score=0.651, total= 2.5min\n",
      "[CV] lr=0.01, dropout_rate=0.3 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 10.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 7s 168us/step - loss: 3.4886 - acc: 0.1313\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 2.0062 - acc: 0.2288\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.7778 - acc: 0.3262\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.5477 - acc: 0.4200\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3902 - acc: 0.4852\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2614 - acc: 0.5388\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1428 - acc: 0.5823\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0414 - acc: 0.6221\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9457 - acc: 0.6627\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8648 - acc: 0.6905\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7827 - acc: 0.7237\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7189 - acc: 0.7449\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6439 - acc: 0.7743\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5928 - acc: 0.7909\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5377 - acc: 0.8109\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4949 - acc: 0.8262\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4410 - acc: 0.8446\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3970 - acc: 0.8601\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3624 - acc: 0.8743\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3290 - acc: 0.8852\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2887 - acc: 0.8976\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2653 - acc: 0.9078\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2372 - acc: 0.9173\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2230 - acc: 0.9227\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1949 - acc: 0.9326\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1828 - acc: 0.9370\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1753 - acc: 0.9395\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1595 - acc: 0.9453\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1537 - acc: 0.9478\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1419 - acc: 0.9521\n",
      "10000/10000 [==============================] - 1s 95us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.3, score=0.722, total= 2.5min\n",
      "[CV] lr=0.001, dropout_rate=0.3 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 7s 170us/step - loss: 1.7617 - acc: 0.3667\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3208 - acc: 0.5113\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1434 - acc: 0.5839\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0047 - acc: 0.6383\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8993 - acc: 0.6797\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8159 - acc: 0.7096\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7538 - acc: 0.7297\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6799 - acc: 0.7586\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6154 - acc: 0.7843\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5692 - acc: 0.7992\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5111 - acc: 0.8196\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4703 - acc: 0.8352\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4337 - acc: 0.8453\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3936 - acc: 0.8601\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3583 - acc: 0.8734\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3242 - acc: 0.8846\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2917 - acc: 0.8966\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2665 - acc: 0.9056\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2512 - acc: 0.9101\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2212 - acc: 0.9211\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.2105 - acc: 0.9274\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1964 - acc: 0.9310\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1730 - acc: 0.9399\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1641 - acc: 0.9430\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1515 - acc: 0.9479\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1400 - acc: 0.9513\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1294 - acc: 0.9542\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1400 - acc: 0.9522\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1105 - acc: 0.9616\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1138 - acc: 0.9619\n",
      "10000/10000 [==============================] - 1s 102us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.3, score=0.730, total= 2.5min\n",
      "[CV] lr=0.001, dropout_rate=0.3 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 15.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 7s 175us/step - loss: 1.7776 - acc: 0.3620\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3387 - acc: 0.5083\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1658 - acc: 0.5749\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0347 - acc: 0.6260\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9343 - acc: 0.6655\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8383 - acc: 0.7011\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7660 - acc: 0.7284\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6966 - acc: 0.7524\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6434 - acc: 0.7743\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5844 - acc: 0.7943\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5400 - acc: 0.8098\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4882 - acc: 0.8260\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4562 - acc: 0.8370\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.4078 - acc: 0.8544\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3728 - acc: 0.8696\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3449 - acc: 0.8787\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3101 - acc: 0.8903\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2923 - acc: 0.8934\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2618 - acc: 0.9062\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2365 - acc: 0.9160\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2147 - acc: 0.9243\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1951 - acc: 0.9318\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1926 - acc: 0.9345\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1675 - acc: 0.9420\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1698 - acc: 0.9407\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1513 - acc: 0.9481\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1399 - acc: 0.9516\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1311 - acc: 0.9548\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1252 - acc: 0.9562\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1254 - acc: 0.9567\n",
      "10000/10000 [==============================] - 1s 112us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.3, score=0.742, total= 2.5min\n",
      "[CV] lr=0.001, dropout_rate=0.3 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 17.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 1.7747 - acc: 0.3655\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3295 - acc: 0.5087\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1461 - acc: 0.5835\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0218 - acc: 0.6319\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9187 - acc: 0.6707\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8336 - acc: 0.7041\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7651 - acc: 0.7280\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6879 - acc: 0.7553\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6356 - acc: 0.7730\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5871 - acc: 0.7913\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5249 - acc: 0.8137\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5007 - acc: 0.8232\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4464 - acc: 0.8405\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4023 - acc: 0.8547\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3642 - acc: 0.8699\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3435 - acc: 0.8774\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3139 - acc: 0.8887\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2756 - acc: 0.9007\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2555 - acc: 0.9090\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2349 - acc: 0.9162\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2145 - acc: 0.9241\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1950 - acc: 0.9303\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1838 - acc: 0.9335\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1704 - acc: 0.9406\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1604 - acc: 0.9439\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1466 - acc: 0.9504\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1382 - acc: 0.9518\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1393 - acc: 0.9529\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1130 - acc: 0.9624\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1188 - acc: 0.9595\n",
      "10000/10000 [==============================] - 1s 130us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.3, score=0.675, total= 2.6min\n",
      "[CV] lr=0.001, dropout_rate=0.3 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 20.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 1.7716 - acc: 0.3596\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3365 - acc: 0.5076\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1488 - acc: 0.5830\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0286 - acc: 0.6276\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9252 - acc: 0.6685\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8329 - acc: 0.7040\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7625 - acc: 0.7276\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7002 - acc: 0.7482\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6393 - acc: 0.7721\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5948 - acc: 0.7885\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5341 - acc: 0.8095\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4977 - acc: 0.8236\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4515 - acc: 0.8381\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4128 - acc: 0.8525\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3752 - acc: 0.8660\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3355 - acc: 0.8787\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3107 - acc: 0.8890\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2751 - acc: 0.9020\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2621 - acc: 0.9073\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2258 - acc: 0.9213\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2305 - acc: 0.9181\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1974 - acc: 0.9314\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1794 - acc: 0.9363\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1793 - acc: 0.9375\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1619 - acc: 0.9435\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1419 - acc: 0.9510\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1445 - acc: 0.9511\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1295 - acc: 0.9547\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1271 - acc: 0.9580\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1183 - acc: 0.9604\n",
      "10000/10000 [==============================] - 1s 133us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.3, score=0.651, total= 2.5min\n",
      "[CV] lr=0.001, dropout_rate=0.3 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 22.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.7495 - acc: 0.3740\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3097 - acc: 0.5202\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1284 - acc: 0.5919\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0001 - acc: 0.6375\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8896 - acc: 0.6836\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8161 - acc: 0.7091\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7439 - acc: 0.7333\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6772 - acc: 0.7579\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6254 - acc: 0.7776\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5710 - acc: 0.7985\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5134 - acc: 0.8172\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4779 - acc: 0.8293\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4229 - acc: 0.8497\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3936 - acc: 0.8584\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3614 - acc: 0.8731\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3283 - acc: 0.8822\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2906 - acc: 0.8978\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2655 - acc: 0.9066\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2532 - acc: 0.9109\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2233 - acc: 0.9213\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2090 - acc: 0.9260\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1935 - acc: 0.9331\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1755 - acc: 0.9398\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1747 - acc: 0.9405\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1609 - acc: 0.9437\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.1399 - acc: 0.9503\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1318 - acc: 0.9539\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1255 - acc: 0.9568\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1245 - acc: 0.9589\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1187 - acc: 0.9598\n",
      "10000/10000 [==============================] - 1s 135us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.3, score=0.704, total= 2.6min\n",
      "[CV] lr=0.0001, dropout_rate=0.3 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 25.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.9265 - acc: 0.3120\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5916 - acc: 0.4207\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.4338 - acc: 0.4764\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3342 - acc: 0.5133\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2666 - acc: 0.5413\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2051 - acc: 0.5643\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1544 - acc: 0.5846\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1084 - acc: 0.6020\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0682 - acc: 0.6184\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0302 - acc: 0.6324\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9965 - acc: 0.6451\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9660 - acc: 0.6564\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9331 - acc: 0.6697\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9052 - acc: 0.6787\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8758 - acc: 0.6875\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8477 - acc: 0.6998\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8262 - acc: 0.7069\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8019 - acc: 0.7177\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7748 - acc: 0.7276\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7529 - acc: 0.7345\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7271 - acc: 0.7417\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7123 - acc: 0.7474\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6881 - acc: 0.7576\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6666 - acc: 0.7651\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6499 - acc: 0.7705\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6280 - acc: 0.7790\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6072 - acc: 0.7864\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5928 - acc: 0.7895\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5731 - acc: 0.7987\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5574 - acc: 0.8027\n",
      "10000/10000 [==============================] - 1s 145us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.3, score=0.664, total= 2.6min\n",
      "[CV] lr=0.0001, dropout_rate=0.3 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed: 27.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 1.8947 - acc: 0.3117\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5688 - acc: 0.4282\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.4233 - acc: 0.4829\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3270 - acc: 0.5207\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2549 - acc: 0.5442\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1956 - acc: 0.5708\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1428 - acc: 0.5897\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0975 - acc: 0.6059\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0556 - acc: 0.6205\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0219 - acc: 0.6325\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9849 - acc: 0.6493\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9568 - acc: 0.6599\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9229 - acc: 0.6702\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8965 - acc: 0.6795\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8659 - acc: 0.6928\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8407 - acc: 0.7031\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8169 - acc: 0.7119\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7922 - acc: 0.7165\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7721 - acc: 0.7256\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7525 - acc: 0.7333\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7255 - acc: 0.7408\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7059 - acc: 0.7498\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6829 - acc: 0.7562\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6695 - acc: 0.7605\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6457 - acc: 0.7724\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6310 - acc: 0.7760\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6118 - acc: 0.7833\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5952 - acc: 0.7884\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5705 - acc: 0.7965\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5620 - acc: 0.8003\n",
      "10000/10000 [==============================] - 2s 157us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.3, score=0.658, total= 2.6min\n",
      "[CV] lr=0.0001, dropout_rate=0.3 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 30.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 1.9208 - acc: 0.3064\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.5603 - acc: 0.4353\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.4048 - acc: 0.4903\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.2984 - acc: 0.5314\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.2136 - acc: 0.5646\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1558 - acc: 0.5847\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0972 - acc: 0.6068\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0519 - acc: 0.6218\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0122 - acc: 0.6393\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9677 - acc: 0.6548\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9326 - acc: 0.6688\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8997 - acc: 0.6825\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8683 - acc: 0.6918\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8358 - acc: 0.7064\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8139 - acc: 0.7123\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7869 - acc: 0.7204\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7600 - acc: 0.7321\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7363 - acc: 0.7394\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7158 - acc: 0.7469\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6897 - acc: 0.7579\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6680 - acc: 0.7635\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6458 - acc: 0.7740\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6240 - acc: 0.7802\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6047 - acc: 0.7872\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5874 - acc: 0.7945\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5668 - acc: 0.8008\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5468 - acc: 0.8076\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5265 - acc: 0.8152\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5051 - acc: 0.8224\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4926 - acc: 0.8258\n",
      "10000/10000 [==============================] - 2s 168us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.3, score=0.690, total= 2.6min\n",
      "[CV] lr=0.0001, dropout_rate=0.3 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed: 33.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 9s 214us/step - loss: 1.9349 - acc: 0.2958\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5599 - acc: 0.4264\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.4125 - acc: 0.4859\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3073 - acc: 0.5263\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2381 - acc: 0.5514\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1775 - acc: 0.5770\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1210 - acc: 0.5969\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0750 - acc: 0.6139\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0366 - acc: 0.6286\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9922 - acc: 0.6499\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9592 - acc: 0.6570\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9204 - acc: 0.6719\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8910 - acc: 0.6817\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8609 - acc: 0.6956\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8372 - acc: 0.7014\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8114 - acc: 0.7118\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7812 - acc: 0.7241\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7570 - acc: 0.7322\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7346 - acc: 0.7409\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7111 - acc: 0.7494\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6916 - acc: 0.7544\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6659 - acc: 0.7650\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6457 - acc: 0.7712\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6239 - acc: 0.7777\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6035 - acc: 0.7872\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5867 - acc: 0.7909\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5693 - acc: 0.7993\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5513 - acc: 0.8057\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5324 - acc: 0.8149\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5157 - acc: 0.8180\n",
      "10000/10000 [==============================] - 2s 176us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.3, score=0.662, total= 2.6min\n",
      "[CV] lr=0.0001, dropout_rate=0.3 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 35.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.8908 - acc: 0.3174\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.5592 - acc: 0.4358\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.4059 - acc: 0.4905\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3067 - acc: 0.5284\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2274 - acc: 0.5600\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.1659 - acc: 0.5802\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.1169 - acc: 0.6005\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0689 - acc: 0.6173\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0329 - acc: 0.6323\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9938 - acc: 0.6453\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9547 - acc: 0.6612\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9278 - acc: 0.6710\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8981 - acc: 0.6826\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8691 - acc: 0.6923\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8390 - acc: 0.7023\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8133 - acc: 0.7093\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7882 - acc: 0.7213\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7660 - acc: 0.7308\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7417 - acc: 0.7354\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7169 - acc: 0.7469\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.7005 - acc: 0.7535\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6744 - acc: 0.7607\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6597 - acc: 0.7672\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6408 - acc: 0.7729\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6205 - acc: 0.7821\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5958 - acc: 0.7891\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5791 - acc: 0.7957\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.5631 - acc: 0.8033\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5490 - acc: 0.8052\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5266 - acc: 0.8143\n",
      "10000/10000 [==============================] - 2s 188us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.3, score=0.678, total= 2.6min\n",
      "[CV] lr=0.01, dropout_rate=0.5 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 38.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 3.8905 - acc: 0.1102\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 2.1150 - acc: 0.1993\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.8111 - acc: 0.3097\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.6289 - acc: 0.3880\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.4664 - acc: 0.4573\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3406 - acc: 0.5054\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.2455 - acc: 0.5415\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.1440 - acc: 0.5847\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0528 - acc: 0.6182\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9678 - acc: 0.6512\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9018 - acc: 0.6755\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8370 - acc: 0.7040\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7723 - acc: 0.7269\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7206 - acc: 0.7493\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.6610 - acc: 0.7688\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6026 - acc: 0.7906\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5619 - acc: 0.8017\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5177 - acc: 0.8211\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4760 - acc: 0.8346\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4426 - acc: 0.8461\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3956 - acc: 0.8613\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3647 - acc: 0.8743\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3388 - acc: 0.8794\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3086 - acc: 0.8928\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2874 - acc: 0.9016\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2672 - acc: 0.9094\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2548 - acc: 0.9114\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2172 - acc: 0.9229\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2185 - acc: 0.9260\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1953 - acc: 0.9347\n",
      "10000/10000 [==============================] - 2s 190us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.5, score=0.676, total= 2.6min\n",
      "[CV] lr=0.01, dropout_rate=0.5 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 40.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 3.7977 - acc: 0.1143\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 2.0919 - acc: 0.2079\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.7938 - acc: 0.3208\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5855 - acc: 0.4021\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.4305 - acc: 0.4626\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3086 - acc: 0.5203\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2075 - acc: 0.5567\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0927 - acc: 0.6030\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0029 - acc: 0.6440\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9286 - acc: 0.6677\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8487 - acc: 0.7017\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7828 - acc: 0.7249\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7223 - acc: 0.7455\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6611 - acc: 0.7672\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6154 - acc: 0.7841\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5616 - acc: 0.8025\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5138 - acc: 0.8213\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4764 - acc: 0.8330\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4306 - acc: 0.8497\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3991 - acc: 0.8615\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3627 - acc: 0.8739\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3410 - acc: 0.8802\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.3072 - acc: 0.8926\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2878 - acc: 0.9012\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2663 - acc: 0.9075\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2482 - acc: 0.9147\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2215 - acc: 0.9234\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2060 - acc: 0.9296\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2040 - acc: 0.9300\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1856 - acc: 0.9364\n",
      "10000/10000 [==============================] - 2s 203us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.5, score=0.704, total= 2.6min\n",
      "[CV] lr=0.01, dropout_rate=0.5 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed: 43.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 3.9346 - acc: 0.1242\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 2.0642 - acc: 0.2033\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.8353 - acc: 0.2908\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.6306 - acc: 0.3723\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.4690 - acc: 0.4505\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3212 - acc: 0.5102\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2030 - acc: 0.5663\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0888 - acc: 0.6081\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 1.0077 - acc: 0.6393\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9231 - acc: 0.6747\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8491 - acc: 0.7010\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7839 - acc: 0.7263\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7283 - acc: 0.7455\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6580 - acc: 0.7710\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.6143 - acc: 0.7858\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5663 - acc: 0.8020\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5151 - acc: 0.8199\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4760 - acc: 0.8347\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4293 - acc: 0.8525\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3892 - acc: 0.8646\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3641 - acc: 0.8735\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3295 - acc: 0.8860\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3046 - acc: 0.8938\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2753 - acc: 0.9048\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2605 - acc: 0.9123\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2319 - acc: 0.9192\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2253 - acc: 0.9245\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2093 - acc: 0.9298\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1897 - acc: 0.9351\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1915 - acc: 0.9367\n",
      "10000/10000 [==============================] - 2s 210us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.5, score=0.694, total= 2.6min\n",
      "[CV] lr=0.01, dropout_rate=0.5 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 45.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 4.1138 - acc: 0.1106\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 2.1995 - acc: 0.1627\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.8898 - acc: 0.2704\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.6599 - acc: 0.3632\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.4697 - acc: 0.4409\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3363 - acc: 0.5034\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2082 - acc: 0.5546\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0965 - acc: 0.6023\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0181 - acc: 0.6352\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9156 - acc: 0.6770\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8407 - acc: 0.7018\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7694 - acc: 0.7318\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7004 - acc: 0.7539\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6490 - acc: 0.7742\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.5974 - acc: 0.7923\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5363 - acc: 0.8123\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4919 - acc: 0.8283\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4474 - acc: 0.8445\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4073 - acc: 0.8576\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3712 - acc: 0.8705\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3434 - acc: 0.8813\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3087 - acc: 0.8936\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2809 - acc: 0.9003\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2557 - acc: 0.9138\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2411 - acc: 0.9197\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2157 - acc: 0.9256\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2085 - acc: 0.9301\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1969 - acc: 0.9329\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1772 - acc: 0.9396\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1690 - acc: 0.9442\n",
      "10000/10000 [==============================] - 2s 223us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.5, score=0.629, total= 2.6min\n",
      "[CV] lr=0.01, dropout_rate=0.5 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed: 48.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 10s 250us/step - loss: 3.3105 - acc: 0.1338\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 2.0213 - acc: 0.2255\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.7727 - acc: 0.3200\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5827 - acc: 0.4002\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.4304 - acc: 0.4676\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3045 - acc: 0.5236\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1933 - acc: 0.5664\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0941 - acc: 0.6047\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0162 - acc: 0.6335\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9423 - acc: 0.6656\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8705 - acc: 0.6916\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8058 - acc: 0.7153\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7412 - acc: 0.7395\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6819 - acc: 0.7622\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6318 - acc: 0.7788\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5888 - acc: 0.7964\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5348 - acc: 0.8129\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4896 - acc: 0.8302\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4577 - acc: 0.8398\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4137 - acc: 0.8556\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3820 - acc: 0.8667\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3443 - acc: 0.8820\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3245 - acc: 0.8885\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2899 - acc: 0.8986\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2752 - acc: 0.9059\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2536 - acc: 0.9121\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2350 - acc: 0.9193\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2219 - acc: 0.9256\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2015 - acc: 0.9309\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1836 - acc: 0.9379\n",
      "10000/10000 [==============================] - 2s 236us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.5, score=0.646, total= 2.6min\n",
      "[CV] lr=0.001, dropout_rate=0.5 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 10s 257us/step - loss: 1.8415 - acc: 0.3351\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.3931 - acc: 0.4868\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2038 - acc: 0.5590\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0845 - acc: 0.6086\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9858 - acc: 0.6480\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8980 - acc: 0.6788\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8298 - acc: 0.7059\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7729 - acc: 0.7250\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7137 - acc: 0.7460\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6563 - acc: 0.7701\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6228 - acc: 0.7809\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5674 - acc: 0.7985\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5299 - acc: 0.8120\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4943 - acc: 0.8259\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4676 - acc: 0.8355\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4249 - acc: 0.8486\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4008 - acc: 0.8589\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3658 - acc: 0.8696\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3457 - acc: 0.8782\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3080 - acc: 0.8919\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2960 - acc: 0.8953\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2742 - acc: 0.9009\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2523 - acc: 0.9106\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2350 - acc: 0.9167\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2230 - acc: 0.9189\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2012 - acc: 0.9298\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.1920 - acc: 0.9347\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.1826 - acc: 0.9366\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1668 - acc: 0.9417\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1649 - acc: 0.9439\n",
      "10000/10000 [==============================] - 2s 248us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.5, score=0.723, total= 2.6min\n",
      "[CV] lr=0.001, dropout_rate=0.5 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 10s 262us/step - loss: 1.8530 - acc: 0.3343\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.4374 - acc: 0.4698\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2563 - acc: 0.5387\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1172 - acc: 0.5950\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0274 - acc: 0.6319\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9296 - acc: 0.6678\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8622 - acc: 0.6926\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7885 - acc: 0.7199\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7275 - acc: 0.7414\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6740 - acc: 0.7613\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6326 - acc: 0.7753\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5897 - acc: 0.7923\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5450 - acc: 0.8078\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5022 - acc: 0.8231\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4635 - acc: 0.8355\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4352 - acc: 0.8482\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4004 - acc: 0.8589\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3707 - acc: 0.8707\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3402 - acc: 0.8804\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3271 - acc: 0.8865\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3009 - acc: 0.8941\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2693 - acc: 0.9039\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2617 - acc: 0.9080\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2356 - acc: 0.9179\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2152 - acc: 0.9236\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2072 - acc: 0.9258\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1983 - acc: 0.9311\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1819 - acc: 0.9359\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1772 - acc: 0.9379\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1555 - acc: 0.9451\n",
      "10000/10000 [==============================] - 3s 253us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.5, score=0.708, total= 2.7min\n",
      "[CV] lr=0.001, dropout_rate=0.5 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 11s 268us/step - loss: 1.8353 - acc: 0.3420\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.3804 - acc: 0.4925\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1977 - acc: 0.5653\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0796 - acc: 0.6122\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9854 - acc: 0.6469\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8959 - acc: 0.6802\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8336 - acc: 0.7029\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7646 - acc: 0.7322\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7124 - acc: 0.7484\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6660 - acc: 0.7641\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6167 - acc: 0.7830\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5662 - acc: 0.8009\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5306 - acc: 0.8123\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.4879 - acc: 0.8270\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4548 - acc: 0.8382\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4177 - acc: 0.8540\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3888 - acc: 0.8611\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3678 - acc: 0.8690\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3282 - acc: 0.8840\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3090 - acc: 0.8898\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2793 - acc: 0.9007\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2627 - acc: 0.9070\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2469 - acc: 0.9135\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2258 - acc: 0.9194\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2109 - acc: 0.9238\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2014 - acc: 0.9298\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1967 - acc: 0.9322\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1690 - acc: 0.9401\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1659 - acc: 0.9422\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1606 - acc: 0.9448\n",
      "10000/10000 [==============================] - 3s 253us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.5, score=0.673, total= 2.6min\n",
      "[CV] lr=0.001, dropout_rate=0.5 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 11s 267us/step - loss: 1.8179 - acc: 0.3469\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3934 - acc: 0.4854\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2159 - acc: 0.5585\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0841 - acc: 0.6052\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9848 - acc: 0.6460\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9073 - acc: 0.6748\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8330 - acc: 0.7030\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7706 - acc: 0.7284\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7163 - acc: 0.7463\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6699 - acc: 0.7619\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6100 - acc: 0.7827\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5723 - acc: 0.7979\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5289 - acc: 0.8124\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4936 - acc: 0.8247\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4573 - acc: 0.8386\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4252 - acc: 0.8520\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3867 - acc: 0.8626\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3724 - acc: 0.8670\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.3353 - acc: 0.8811\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3190 - acc: 0.8878\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2848 - acc: 0.9010\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2764 - acc: 0.9035\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2471 - acc: 0.9151\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2299 - acc: 0.9191\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.2205 - acc: 0.9213\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2017 - acc: 0.9291\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1974 - acc: 0.9319\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1755 - acc: 0.9395\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1681 - acc: 0.9423\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1576 - acc: 0.9439\n",
      "10000/10000 [==============================] - 3s 265us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.5, score=0.704, total= 2.6min\n",
      "[CV] lr=0.001, dropout_rate=0.5 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 11s 276us/step - loss: 1.8217 - acc: 0.3428\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3795 - acc: 0.4892\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.2043 - acc: 0.5589\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0714 - acc: 0.6129\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9723 - acc: 0.6510\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8857 - acc: 0.6844\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8160 - acc: 0.7137\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7571 - acc: 0.7310\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6996 - acc: 0.7514\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6472 - acc: 0.7687\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6005 - acc: 0.7895\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5642 - acc: 0.8017\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.5192 - acc: 0.8182\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4846 - acc: 0.8276\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.4500 - acc: 0.8423\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4108 - acc: 0.8517\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3886 - acc: 0.8639\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3571 - acc: 0.8740\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3351 - acc: 0.8811\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.3032 - acc: 0.8936\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2884 - acc: 0.8984\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2621 - acc: 0.9059\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2473 - acc: 0.9121\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2305 - acc: 0.9193\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.2236 - acc: 0.9214\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1926 - acc: 0.9317\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1853 - acc: 0.9346\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.1791 - acc: 0.9379\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1697 - acc: 0.9406\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1517 - acc: 0.9464\n",
      "10000/10000 [==============================] - 3s 270us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.5, score=0.650, total= 2.7min\n",
      "[CV] lr=0.0001, dropout_rate=0.5 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 11s 283us/step - loss: 2.0723 - acc: 0.2519\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.7031 - acc: 0.3747\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5383 - acc: 0.4340\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.4336 - acc: 0.4724\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.3489 - acc: 0.5062\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2898 - acc: 0.5299\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2406 - acc: 0.5504\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1989 - acc: 0.5658\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1544 - acc: 0.5830\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1163 - acc: 0.5998\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0865 - acc: 0.6113\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0552 - acc: 0.6229\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0250 - acc: 0.6332\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0031 - acc: 0.6387\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9740 - acc: 0.6484\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9519 - acc: 0.6601\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9259 - acc: 0.6705\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9054 - acc: 0.6764\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8813 - acc: 0.6870\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8673 - acc: 0.6891\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8461 - acc: 0.7015\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8254 - acc: 0.7064\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8044 - acc: 0.7160\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7860 - acc: 0.7199\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7698 - acc: 0.7258\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7509 - acc: 0.7326\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7362 - acc: 0.7376\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7241 - acc: 0.7443\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7021 - acc: 0.7512\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.6930 - acc: 0.7553\n",
      "10000/10000 [==============================] - 3s 289us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.5, score=0.665, total= 2.7min\n",
      "[CV] lr=0.0001, dropout_rate=0.5 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 11s 286us/step - loss: 2.0269 - acc: 0.2670\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.7310 - acc: 0.3665\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.5810 - acc: 0.4167\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.4747 - acc: 0.4593\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.4019 - acc: 0.4857\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.3351 - acc: 0.5112\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2855 - acc: 0.5344\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2388 - acc: 0.5501\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1970 - acc: 0.5661\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1617 - acc: 0.5793\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.1283 - acc: 0.5936\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0971 - acc: 0.6036\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0667 - acc: 0.6154\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0428 - acc: 0.6240\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.0087 - acc: 0.6372\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9919 - acc: 0.6445\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9576 - acc: 0.6572\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9405 - acc: 0.6602\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9213 - acc: 0.6704\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8987 - acc: 0.6767\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8753 - acc: 0.6853\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8596 - acc: 0.6929\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8409 - acc: 0.6977\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8243 - acc: 0.7046\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8032 - acc: 0.7101\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7837 - acc: 0.7190\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7733 - acc: 0.7224\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7516 - acc: 0.7302\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7384 - acc: 0.7355\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7190 - acc: 0.7457\n",
      "10000/10000 [==============================] - 3s 299us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.5, score=0.671, total= 2.7min\n",
      "[CV] lr=0.0001, dropout_rate=0.5 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 12s 291us/step - loss: 2.0401 - acc: 0.2597\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.7149 - acc: 0.3678\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.5610 - acc: 0.4255\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.4710 - acc: 0.4598\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.4022 - acc: 0.4870\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.3449 - acc: 0.5076\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2930 - acc: 0.5323\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2510 - acc: 0.5463\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2032 - acc: 0.5642\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1727 - acc: 0.5744\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.1381 - acc: 0.5883\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1033 - acc: 0.6012\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0823 - acc: 0.6120\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0522 - acc: 0.6229\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0300 - acc: 0.6293\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0057 - acc: 0.6418\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9817 - acc: 0.6480\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9562 - acc: 0.6574\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9366 - acc: 0.6645\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9183 - acc: 0.6711\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8934 - acc: 0.6793\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8791 - acc: 0.6851\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8576 - acc: 0.6958\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8409 - acc: 0.6993\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8221 - acc: 0.7082\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8036 - acc: 0.7148\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7903 - acc: 0.7169\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7736 - acc: 0.7233\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7560 - acc: 0.7323\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7401 - acc: 0.7372\n",
      "10000/10000 [==============================] - 3s 315us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.5, score=0.667, total= 2.7min\n",
      "[CV] lr=0.0001, dropout_rate=0.5 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 12s 300us/step - loss: 2.0377 - acc: 0.2601\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.7204 - acc: 0.3618\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.5623 - acc: 0.4201\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4747 - acc: 0.4561\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3949 - acc: 0.4864\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3302 - acc: 0.5137\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2810 - acc: 0.5344\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2350 - acc: 0.5520\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1966 - acc: 0.5667\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1576 - acc: 0.5830\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1207 - acc: 0.5933\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0883 - acc: 0.6080\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0557 - acc: 0.6176\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0258 - acc: 0.6310\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0025 - acc: 0.6391\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9747 - acc: 0.6489\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9519 - acc: 0.6591\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9305 - acc: 0.6684\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9022 - acc: 0.6755\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8804 - acc: 0.6848\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8636 - acc: 0.6901\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8411 - acc: 0.7010\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8233 - acc: 0.7048\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7994 - acc: 0.7121\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7816 - acc: 0.7207\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7689 - acc: 0.7279\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7522 - acc: 0.7310\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7299 - acc: 0.7406\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7169 - acc: 0.7433\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6964 - acc: 0.7519\n",
      "10000/10000 [==============================] - 3s 327us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.5, score=0.652, total= 2.7min\n",
      "[CV] lr=0.0001, dropout_rate=0.5 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 12s 303us/step - loss: 2.1023 - acc: 0.2480\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.7201 - acc: 0.3680\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5530 - acc: 0.4282\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4470 - acc: 0.4693\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3645 - acc: 0.5010\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3037 - acc: 0.5252\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2527 - acc: 0.5472\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2073 - acc: 0.5677\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1682 - acc: 0.5799\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1357 - acc: 0.5911\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1031 - acc: 0.6033\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0742 - acc: 0.6139\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0423 - acc: 0.6249\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 1.0194 - acc: 0.6348\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9952 - acc: 0.6440\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9649 - acc: 0.6560\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.9459 - acc: 0.6612\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.9249 - acc: 0.6728\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.9041 - acc: 0.6760\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8842 - acc: 0.6863\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8665 - acc: 0.6915\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.8445 - acc: 0.7008\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.8286 - acc: 0.7053\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.8059 - acc: 0.7141\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7916 - acc: 0.7188\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7781 - acc: 0.7226\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.7558 - acc: 0.7318\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7404 - acc: 0.7393\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7259 - acc: 0.7444\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.7074 - acc: 0.7496\n",
      "10000/10000 [==============================] - 3s 342us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.5, score=0.681, total= 2.7min\n",
      "[CV] lr=0.01, dropout_rate=0.7 .......................................\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 12s 310us/step - loss: 3.7977 - acc: 0.1098\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 2.1920 - acc: 0.1718\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.8756 - acc: 0.2691\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6592 - acc: 0.3650\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5132 - acc: 0.4311\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3798 - acc: 0.4923\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.2799 - acc: 0.5312\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1789 - acc: 0.5722\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0862 - acc: 0.6119\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0192 - acc: 0.6361\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9464 - acc: 0.6657\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8879 - acc: 0.6881\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8249 - acc: 0.7100\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7708 - acc: 0.7312\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7126 - acc: 0.7534\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6762 - acc: 0.7652\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6151 - acc: 0.7869\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5729 - acc: 0.8043\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5441 - acc: 0.8128\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4956 - acc: 0.8292\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4655 - acc: 0.8409\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4307 - acc: 0.8521\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3981 - acc: 0.8660\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3737 - acc: 0.8744\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3489 - acc: 0.8806\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3229 - acc: 0.8897\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3088 - acc: 0.8988\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2935 - acc: 0.9023\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2646 - acc: 0.9105\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2550 - acc: 0.9144\n",
      "10000/10000 [==============================] - 3s 348us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.7, score=0.560, total= 2.7min\n",
      "[CV] lr=0.01, dropout_rate=0.7 .......................................\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 13s 319us/step - loss: 3.3480 - acc: 0.1421\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.9972 - acc: 0.2164\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.8079 - acc: 0.3030\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6238 - acc: 0.3766\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4656 - acc: 0.4497\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.3570 - acc: 0.4988\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2530 - acc: 0.5402\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1727 - acc: 0.5770\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0836 - acc: 0.6123\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0064 - acc: 0.6418\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9419 - acc: 0.6631\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8856 - acc: 0.6875\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8150 - acc: 0.7170\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7683 - acc: 0.7288\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7055 - acc: 0.7560\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6606 - acc: 0.7714\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6232 - acc: 0.7848\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5812 - acc: 0.8025\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5370 - acc: 0.8178\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4953 - acc: 0.8299\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4592 - acc: 0.8421\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4201 - acc: 0.8575\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3972 - acc: 0.8658\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.3624 - acc: 0.8770\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3439 - acc: 0.8821\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3193 - acc: 0.8902\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3093 - acc: 0.8958\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2763 - acc: 0.9068\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2577 - acc: 0.9127\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2502 - acc: 0.9155\n",
      "10000/10000 [==============================] - 4s 364us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.7, score=0.629, total= 2.7min\n",
      "[CV] lr=0.01, dropout_rate=0.7 .......................................\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 13s 327us/step - loss: 3.5317 - acc: 0.1199\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 2.0606 - acc: 0.2127\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.8431 - acc: 0.2914\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6621 - acc: 0.3620\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5072 - acc: 0.4283\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3945 - acc: 0.4797\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2849 - acc: 0.5281\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1960 - acc: 0.5667\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1029 - acc: 0.6055\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0351 - acc: 0.6278\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9625 - acc: 0.6584\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.8966 - acc: 0.6861\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.8483 - acc: 0.7011\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7948 - acc: 0.7215\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7387 - acc: 0.7424\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6890 - acc: 0.7609\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6576 - acc: 0.7733\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6039 - acc: 0.7906\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5641 - acc: 0.8057\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5305 - acc: 0.8203\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4921 - acc: 0.8315\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4549 - acc: 0.8447\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4158 - acc: 0.8586\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3933 - acc: 0.8673\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3705 - acc: 0.8751\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3348 - acc: 0.8869\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3255 - acc: 0.8919\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2987 - acc: 0.9015\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2798 - acc: 0.9073\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.2690 - acc: 0.9100\n",
      "10000/10000 [==============================] - 4s 372us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.7, score=0.621, total= 2.7min\n",
      "[CV] lr=0.01, dropout_rate=0.7 .......................................\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 13s 329us/step - loss: 3.3795 - acc: 0.1518\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 2.0202 - acc: 0.2339\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.7877 - acc: 0.3139\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.6248 - acc: 0.3821\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4891 - acc: 0.4409\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3697 - acc: 0.4932\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2739 - acc: 0.5335\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1730 - acc: 0.5746\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0889 - acc: 0.6089\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0074 - acc: 0.6403\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9473 - acc: 0.6647\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8787 - acc: 0.6895\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8225 - acc: 0.7128\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7787 - acc: 0.7288\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7275 - acc: 0.7454\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6778 - acc: 0.7627\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6339 - acc: 0.7764\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5886 - acc: 0.7955\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5610 - acc: 0.8045\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5183 - acc: 0.8203\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4845 - acc: 0.8325\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4548 - acc: 0.8448\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4191 - acc: 0.8552\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4003 - acc: 0.8632\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3657 - acc: 0.8733\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3530 - acc: 0.8791\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3253 - acc: 0.8874\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3071 - acc: 0.8952\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2870 - acc: 0.9009\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.2766 - acc: 0.9061\n",
      "10000/10000 [==============================] - 4s 386us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.7, score=0.524, total= 2.7min\n",
      "[CV] lr=0.01, dropout_rate=0.7 .......................................\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 13s 337us/step - loss: 3.4229 - acc: 0.1152\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 2.1104 - acc: 0.1992\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.8660 - acc: 0.2842\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6838 - acc: 0.3612\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.5259 - acc: 0.4282\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4118 - acc: 0.4758\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2989 - acc: 0.5230\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2125 - acc: 0.5626\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1269 - acc: 0.5934\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0475 - acc: 0.6253\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9800 - acc: 0.6527\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9158 - acc: 0.6775\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8592 - acc: 0.6981\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8057 - acc: 0.7186\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7592 - acc: 0.7372\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7000 - acc: 0.7556\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6657 - acc: 0.7696\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6217 - acc: 0.7850\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5716 - acc: 0.8034\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5328 - acc: 0.8154\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.5027 - acc: 0.8257\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4616 - acc: 0.8423\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4405 - acc: 0.8494\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4013 - acc: 0.8628\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3833 - acc: 0.8702\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3590 - acc: 0.8770\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3342 - acc: 0.8851\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3141 - acc: 0.8930\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3122 - acc: 0.8940\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2721 - acc: 0.9074\n",
      "10000/10000 [==============================] - 4s 382us/step\n",
      "[CV] ........... lr=0.01, dropout_rate=0.7, score=0.673, total= 2.7min\n",
      "[CV] lr=0.001, dropout_rate=0.7 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 14s 338us/step - loss: 1.9566 - acc: 0.3002\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5149 - acc: 0.4329\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3313 - acc: 0.5119\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2067 - acc: 0.5625\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1008 - acc: 0.6045\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0271 - acc: 0.6346\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9592 - acc: 0.6591\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8998 - acc: 0.6820\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8358 - acc: 0.7035\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8032 - acc: 0.7170\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7498 - acc: 0.7365\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7192 - acc: 0.7479\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6779 - acc: 0.7603\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6385 - acc: 0.7788\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6013 - acc: 0.7891\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5632 - acc: 0.8012\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5425 - acc: 0.8102\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5061 - acc: 0.8220\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4785 - acc: 0.8302\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4538 - acc: 0.8396\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4374 - acc: 0.8469\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4032 - acc: 0.8588\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3883 - acc: 0.8662\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.3625 - acc: 0.8715\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.3386 - acc: 0.8804\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3275 - acc: 0.8830\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3084 - acc: 0.8924\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2917 - acc: 0.8973\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2785 - acc: 0.9013\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2544 - acc: 0.9098\n",
      "10000/10000 [==============================] - 4s 394us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.7, score=0.652, total= 2.8min\n",
      "[CV] lr=0.001, dropout_rate=0.7 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 14s 342us/step - loss: 2.0005 - acc: 0.2914\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.5683 - acc: 0.4145\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3870 - acc: 0.4901\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2565 - acc: 0.5427\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.1509 - acc: 0.5814\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0719 - acc: 0.6107\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9904 - acc: 0.6470\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9243 - acc: 0.6733\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8776 - acc: 0.6881\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.8233 - acc: 0.7109\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7732 - acc: 0.7287\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7348 - acc: 0.7417\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6878 - acc: 0.7585\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6504 - acc: 0.7708\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6193 - acc: 0.7836\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5874 - acc: 0.7935\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5599 - acc: 0.8027\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5305 - acc: 0.8120\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4957 - acc: 0.8253\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4739 - acc: 0.8318\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.4552 - acc: 0.8411\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4197 - acc: 0.8532\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4018 - acc: 0.8588\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3795 - acc: 0.8676\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3589 - acc: 0.8741\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3472 - acc: 0.8779\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.3144 - acc: 0.8899\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3094 - acc: 0.8909\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2865 - acc: 0.9010\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2822 - acc: 0.9026\n",
      "10000/10000 [==============================] - 4s 399us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.7, score=0.683, total= 2.8min\n",
      "[CV] lr=0.001, dropout_rate=0.7 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 14s 350us/step - loss: 1.9937 - acc: 0.2910\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.5656 - acc: 0.4152\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3731 - acc: 0.4901\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2386 - acc: 0.5478\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1375 - acc: 0.5869\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0416 - acc: 0.6272\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9756 - acc: 0.6536\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9129 - acc: 0.6775\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8653 - acc: 0.6948\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8104 - acc: 0.7138\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7619 - acc: 0.7354\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7201 - acc: 0.7504\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6849 - acc: 0.7598\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6404 - acc: 0.7765\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6062 - acc: 0.7881\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.5755 - acc: 0.7988\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5456 - acc: 0.8086\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5148 - acc: 0.8185\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4897 - acc: 0.8274\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.4566 - acc: 0.8393\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.4356 - acc: 0.8486\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4141 - acc: 0.8541\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3831 - acc: 0.8665\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3594 - acc: 0.8748\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3467 - acc: 0.8786\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.3250 - acc: 0.8862\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3250 - acc: 0.8859\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2935 - acc: 0.8978\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2773 - acc: 0.9029\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2744 - acc: 0.9042\n",
      "10000/10000 [==============================] - 4s 411us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.7, score=0.651, total= 2.8min\n",
      "[CV] lr=0.001, dropout_rate=0.7 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 14s 354us/step - loss: 1.9431 - acc: 0.2926\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5432 - acc: 0.4212\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3459 - acc: 0.5040\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2150 - acc: 0.5568\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1192 - acc: 0.5939\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0328 - acc: 0.6294\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9621 - acc: 0.6547\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8954 - acc: 0.6846\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.8378 - acc: 0.7002\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7827 - acc: 0.7229\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7445 - acc: 0.7381\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6969 - acc: 0.7571\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6573 - acc: 0.7698\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6289 - acc: 0.7791\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5921 - acc: 0.7902\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.5525 - acc: 0.8059\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5262 - acc: 0.8162\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4945 - acc: 0.8284\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4664 - acc: 0.8346\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4450 - acc: 0.8458\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4191 - acc: 0.8527\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3918 - acc: 0.8606\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3796 - acc: 0.8648\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3459 - acc: 0.8769\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3341 - acc: 0.8824\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3160 - acc: 0.8865\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3021 - acc: 0.8938\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2754 - acc: 0.9045\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.2658 - acc: 0.9073\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2546 - acc: 0.9098\n",
      "10000/10000 [==============================] - 4s 423us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.7, score=0.621, total= 2.8min\n",
      "[CV] lr=0.001, dropout_rate=0.7 ......................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 14s 362us/step - loss: 1.9672 - acc: 0.2963\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5363 - acc: 0.4269\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3433 - acc: 0.5091\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2116 - acc: 0.5583\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0991 - acc: 0.6045\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0270 - acc: 0.6322\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9594 - acc: 0.6598\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8903 - acc: 0.6860\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.8341 - acc: 0.7060\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.7918 - acc: 0.7195\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7397 - acc: 0.7414\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.7043 - acc: 0.7531\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.6517 - acc: 0.7718\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.6290 - acc: 0.7815\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5868 - acc: 0.7936\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.5590 - acc: 0.8036\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.5230 - acc: 0.8160\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4963 - acc: 0.8267\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4659 - acc: 0.8382\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4383 - acc: 0.8475\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.4220 - acc: 0.8518\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3965 - acc: 0.8621\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.3804 - acc: 0.8670\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.3516 - acc: 0.8755\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3324 - acc: 0.8831\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3145 - acc: 0.8904\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3038 - acc: 0.8945\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2803 - acc: 0.9006\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2702 - acc: 0.9048\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.2490 - acc: 0.9130\n",
      "10000/10000 [==============================] - 4s 428us/step\n",
      "[CV] .......... lr=0.001, dropout_rate=0.7, score=0.568, total= 2.8min\n",
      "[CV] lr=0.0001, dropout_rate=0.7 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 15s 363us/step - loss: 2.3600 - acc: 0.1985\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.9714 - acc: 0.2806\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.8086 - acc: 0.3260\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.7011 - acc: 0.3592\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6267 - acc: 0.3894\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5651 - acc: 0.4120\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5124 - acc: 0.4359\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4761 - acc: 0.4478\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.4316 - acc: 0.4686\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3928 - acc: 0.4811\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3567 - acc: 0.4971\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3290 - acc: 0.5079\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3017 - acc: 0.5176\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2733 - acc: 0.5318\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2477 - acc: 0.5404\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2239 - acc: 0.5486\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2048 - acc: 0.5605\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1837 - acc: 0.5669\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1532 - acc: 0.5756\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1340 - acc: 0.5869\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1198 - acc: 0.5908\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1011 - acc: 0.5991\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 1.0843 - acc: 0.6053\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0665 - acc: 0.6125\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0522 - acc: 0.6204\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0350 - acc: 0.6259\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0222 - acc: 0.6311\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0015 - acc: 0.6378\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9866 - acc: 0.6422\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9715 - acc: 0.6466\n",
      "10000/10000 [==============================] - 4s 437us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.7, score=0.633, total= 2.8min\n",
      "[CV] lr=0.0001, dropout_rate=0.7 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 15s 371us/step - loss: 2.2726 - acc: 0.2036\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.9333 - acc: 0.2935\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.7725 - acc: 0.3437\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6666 - acc: 0.3776\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5904 - acc: 0.4112\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.5236 - acc: 0.4319\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4694 - acc: 0.4514\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.4213 - acc: 0.4747\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3816 - acc: 0.4894\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3505 - acc: 0.5043\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3172 - acc: 0.5158\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 1.2882 - acc: 0.5266\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2598 - acc: 0.5383\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2333 - acc: 0.5496\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2066 - acc: 0.5604\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1869 - acc: 0.5674\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1650 - acc: 0.5749\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1416 - acc: 0.5846\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1227 - acc: 0.5915\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0993 - acc: 0.6020\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0821 - acc: 0.6105\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0647 - acc: 0.6191\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0441 - acc: 0.6238\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0360 - acc: 0.6267\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0182 - acc: 0.6339\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.9963 - acc: 0.6385\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.9826 - acc: 0.6460\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9718 - acc: 0.6491\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.9569 - acc: 0.6566\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9422 - acc: 0.6593\n",
      "10000/10000 [==============================] - 5s 460us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.7, score=0.640, total= 2.8min\n",
      "[CV] lr=0.0001, dropout_rate=0.7 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 15s 385us/step - loss: 2.3030 - acc: 0.1979\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.9521 - acc: 0.2889\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.7886 - acc: 0.3383\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.6688 - acc: 0.3777\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.5887 - acc: 0.4084\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5249 - acc: 0.4327\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4672 - acc: 0.4548\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.4255 - acc: 0.4718\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3863 - acc: 0.4858\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3550 - acc: 0.5022\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3155 - acc: 0.5156\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2847 - acc: 0.5272\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2569 - acc: 0.5386\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2286 - acc: 0.5539\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2039 - acc: 0.5640\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1825 - acc: 0.5725\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1633 - acc: 0.5766\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1356 - acc: 0.5921\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1197 - acc: 0.5954\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0975 - acc: 0.6055\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0804 - acc: 0.6063\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0639 - acc: 0.6160\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0415 - acc: 0.6256\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0300 - acc: 0.6282\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0067 - acc: 0.6373\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9919 - acc: 0.6420\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 0.9785 - acc: 0.6499\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.9612 - acc: 0.6539\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9481 - acc: 0.6631\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.9310 - acc: 0.6661\n",
      "10000/10000 [==============================] - 5s 473us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.7, score=0.653, total= 2.8min\n",
      "[CV] lr=0.0001, dropout_rate=0.7 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 15s 385us/step - loss: 2.2575 - acc: 0.2137\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.9197 - acc: 0.2947\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.7607 - acc: 0.3416\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.6661 - acc: 0.3795\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5833 - acc: 0.4098\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.5224 - acc: 0.4342\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 1.4711 - acc: 0.4538\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.4198 - acc: 0.4767\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3708 - acc: 0.4957\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3430 - acc: 0.5070\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3074 - acc: 0.5210\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2698 - acc: 0.5337\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2449 - acc: 0.5453\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2182 - acc: 0.5561\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1891 - acc: 0.5663\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1726 - acc: 0.5755\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1419 - acc: 0.5855\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1197 - acc: 0.5921\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1044 - acc: 0.5994\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0886 - acc: 0.6074\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0659 - acc: 0.6147\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0515 - acc: 0.6219\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0296 - acc: 0.6268\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0163 - acc: 0.6329\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0003 - acc: 0.6392\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9828 - acc: 0.6461\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9622 - acc: 0.6550\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9519 - acc: 0.6565\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9348 - acc: 0.6636\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9224 - acc: 0.6701\n",
      "10000/10000 [==============================] - 5s 471us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.7, score=0.650, total= 2.8min\n",
      "[CV] lr=0.0001, dropout_rate=0.7 .....................................\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 16s 394us/step - loss: 2.2643 - acc: 0.2039\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.9117 - acc: 0.2969\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.7665 - acc: 0.3386\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.6651 - acc: 0.3781\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5945 - acc: 0.4018\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.5335 - acc: 0.4280\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4756 - acc: 0.4564\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.4369 - acc: 0.4673\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.3918 - acc: 0.4862\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3555 - acc: 0.4979\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.3173 - acc: 0.5136\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2864 - acc: 0.5275\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.2575 - acc: 0.5393\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2326 - acc: 0.5496\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.2053 - acc: 0.5619\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 1.1861 - acc: 0.5690\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1579 - acc: 0.5760\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.1344 - acc: 0.5855\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1143 - acc: 0.5957\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0937 - acc: 0.6022\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0774 - acc: 0.6110\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0575 - acc: 0.6182\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0429 - acc: 0.6220\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.0272 - acc: 0.6295\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 1.0058 - acc: 0.6382\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9957 - acc: 0.6395\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.9773 - acc: 0.6468\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9612 - acc: 0.6531\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9471 - acc: 0.6599\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.9320 - acc: 0.6667\n",
      "10000/10000 [==============================] - 5s 477us/step\n",
      "[CV] ......... lr=0.0001, dropout_rate=0.7, score=0.632, total= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 119.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 1.7286 - acc: 0.3736\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2662 - acc: 0.5363\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.0727 - acc: 0.6125\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.9541 - acc: 0.6598\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.8493 - acc: 0.6977\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.7654 - acc: 0.7287\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.6981 - acc: 0.7531\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.6308 - acc: 0.7777\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.5768 - acc: 0.7979\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.5289 - acc: 0.8111\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.4785 - acc: 0.8315\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.4385 - acc: 0.8460\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.3985 - acc: 0.8585\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.3672 - acc: 0.8685\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.3304 - acc: 0.8828\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.2956 - acc: 0.8952\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.2790 - acc: 0.9018\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.2551 - acc: 0.9092\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.2334 - acc: 0.9179\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2046 - acc: 0.9266\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2006 - acc: 0.9280\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1732 - acc: 0.9376\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1691 - acc: 0.9416\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1481 - acc: 0.9474\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1435 - acc: 0.9509\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1379 - acc: 0.9519\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1283 - acc: 0.9561\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1203 - acc: 0.9578\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1091 - acc: 0.9626\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1091 - acc: 0.9625\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(x_train, y_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-ZDrKXQBwcLP",
    "outputId": "c1faebdf-1630-47c5-a838-bf7b09aafe93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'dropout_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8L_-0ACwnWk"
   },
   "outputs": [],
   "source": [
    "best_model = grid_result.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nD1M7ov7qiXv"
   },
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2d8NUOFqiXz"
   },
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zb4EImJOqiX2"
   },
   "outputs": [],
   "source": [
    "best_model = grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "G4ZIAtr_qiX8",
    "outputId": "f679bef8-3673-442d-bde6-d97f609d2862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "50000/50000 [==============================] - 20s 392us/step - loss: 1.7034 - acc: 0.3823 - val_loss: 1.4525 - val_acc: 0.4729\n",
      "Epoch 2/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.2682 - acc: 0.5334 - val_loss: 1.5230 - val_acc: 0.4514\n",
      "Epoch 3/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.0743 - acc: 0.6117 - val_loss: 1.1292 - val_acc: 0.5985\n",
      "Epoch 4/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.9468 - acc: 0.6606 - val_loss: 1.1783 - val_acc: 0.5718\n",
      "Epoch 5/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.8424 - acc: 0.6976 - val_loss: 1.0809 - val_acc: 0.6331\n",
      "Epoch 6/60\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.7621 - acc: 0.7308 - val_loss: 1.0796 - val_acc: 0.6198\n",
      "Epoch 7/60\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.6929 - acc: 0.7542 - val_loss: 0.9057 - val_acc: 0.6947\n",
      "Epoch 8/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.6300 - acc: 0.7763 - val_loss: 1.0476 - val_acc: 0.6627\n",
      "Epoch 9/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.5824 - acc: 0.7967 - val_loss: 0.9970 - val_acc: 0.6610\n",
      "Epoch 10/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.5240 - acc: 0.8168 - val_loss: 1.1328 - val_acc: 0.6512\n",
      "Epoch 11/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.4898 - acc: 0.8257 - val_loss: 1.2261 - val_acc: 0.6384\n",
      "Epoch 12/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.4447 - acc: 0.8424 - val_loss: 1.2383 - val_acc: 0.6309\n",
      "Epoch 13/60\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.4038 - acc: 0.8582 - val_loss: 0.8999 - val_acc: 0.7249\n",
      "Epoch 14/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3737 - acc: 0.8689 - val_loss: 0.9997 - val_acc: 0.7087\n",
      "Epoch 15/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3322 - acc: 0.8831 - val_loss: 1.8107 - val_acc: 0.6292\n",
      "Epoch 16/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3047 - acc: 0.8912 - val_loss: 1.1230 - val_acc: 0.6950\n",
      "Epoch 17/60\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2726 - acc: 0.9023 - val_loss: 1.1974 - val_acc: 0.6969\n",
      "Epoch 18/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.2557 - acc: 0.9075 - val_loss: 1.1933 - val_acc: 0.7072\n",
      "Epoch 19/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.2283 - acc: 0.9200 - val_loss: 1.3881 - val_acc: 0.6812\n",
      "Epoch 20/60\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.2234 - acc: 0.9227 - val_loss: 1.2793 - val_acc: 0.7057\n",
      "Epoch 21/60\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.1975 - acc: 0.9288 - val_loss: 1.1886 - val_acc: 0.7058\n",
      "Epoch 22/60\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.1827 - acc: 0.9354 - val_loss: 1.5789 - val_acc: 0.6818\n",
      "Epoch 23/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.1658 - acc: 0.9427 - val_loss: 1.3579 - val_acc: 0.7230\n",
      "Epoch 24/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.1576 - acc: 0.9449 - val_loss: 1.2416 - val_acc: 0.7333\n",
      "Epoch 25/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.1489 - acc: 0.9483 - val_loss: 1.7241 - val_acc: 0.6802\n",
      "Epoch 26/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.1438 - acc: 0.9498 - val_loss: 1.2483 - val_acc: 0.7550\n",
      "Epoch 27/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.1234 - acc: 0.9571 - val_loss: 1.4859 - val_acc: 0.7241\n",
      "Epoch 28/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.1309 - acc: 0.9565 - val_loss: 1.3857 - val_acc: 0.7414\n",
      "Epoch 29/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.1100 - acc: 0.9616 - val_loss: 1.3875 - val_acc: 0.7428\n",
      "Epoch 30/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.1071 - acc: 0.9635 - val_loss: 1.4890 - val_acc: 0.7206\n",
      "Epoch 31/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.1071 - acc: 0.9630 - val_loss: 1.5359 - val_acc: 0.7159\n",
      "Epoch 32/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.1015 - acc: 0.9648 - val_loss: 1.6454 - val_acc: 0.7238\n",
      "Epoch 33/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.1039 - acc: 0.9657 - val_loss: 1.1906 - val_acc: 0.7595\n",
      "Epoch 34/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0863 - acc: 0.9706 - val_loss: 1.3163 - val_acc: 0.7566\n",
      "Epoch 35/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0853 - acc: 0.9697 - val_loss: 1.5159 - val_acc: 0.7262\n",
      "Epoch 36/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0838 - acc: 0.9707 - val_loss: 1.8167 - val_acc: 0.7094\n",
      "Epoch 37/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0801 - acc: 0.9727 - val_loss: 1.3383 - val_acc: 0.7530\n",
      "Epoch 38/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0739 - acc: 0.9746 - val_loss: 2.4193 - val_acc: 0.6692\n",
      "Epoch 39/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0772 - acc: 0.9735 - val_loss: 1.7266 - val_acc: 0.7051\n",
      "Epoch 40/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0707 - acc: 0.9764 - val_loss: 1.6558 - val_acc: 0.6864\n",
      "Epoch 41/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0796 - acc: 0.9746 - val_loss: 1.6940 - val_acc: 0.7120\n",
      "Epoch 42/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0636 - acc: 0.9787 - val_loss: 1.6662 - val_acc: 0.7327\n",
      "Epoch 43/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0682 - acc: 0.9767 - val_loss: 1.6686 - val_acc: 0.7234\n",
      "Epoch 44/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0648 - acc: 0.9790 - val_loss: 1.7319 - val_acc: 0.7109\n",
      "Epoch 45/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0658 - acc: 0.9782 - val_loss: 1.6470 - val_acc: 0.7087\n",
      "Epoch 46/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0577 - acc: 0.9814 - val_loss: 2.3765 - val_acc: 0.6830\n",
      "Epoch 47/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0578 - acc: 0.9805 - val_loss: 1.7438 - val_acc: 0.7285\n",
      "Epoch 48/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0561 - acc: 0.9814 - val_loss: 1.5552 - val_acc: 0.7351\n",
      "Epoch 49/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0572 - acc: 0.9813 - val_loss: 1.4322 - val_acc: 0.7375\n",
      "Epoch 50/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0506 - acc: 0.9836 - val_loss: 1.4172 - val_acc: 0.7572\n",
      "Epoch 51/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0527 - acc: 0.9823 - val_loss: 2.9563 - val_acc: 0.6292\n",
      "Epoch 52/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0539 - acc: 0.9812 - val_loss: 1.5234 - val_acc: 0.7366\n",
      "Epoch 53/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0523 - acc: 0.9826 - val_loss: 2.5208 - val_acc: 0.6681\n",
      "Epoch 54/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0466 - acc: 0.9846 - val_loss: 1.5247 - val_acc: 0.7511\n",
      "Epoch 55/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0524 - acc: 0.9831 - val_loss: 1.6888 - val_acc: 0.7439\n",
      "Epoch 56/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0466 - acc: 0.9842 - val_loss: 1.5806 - val_acc: 0.7403\n",
      "Epoch 57/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0449 - acc: 0.9849 - val_loss: 1.6963 - val_acc: 0.7516\n",
      "Epoch 58/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0466 - acc: 0.9851 - val_loss: 2.1779 - val_acc: 0.6916\n",
      "Epoch 59/60\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0443 - acc: 0.9852 - val_loss: 1.6690 - val_acc: 0.7337\n",
      "Epoch 60/60\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0451 - acc: 0.9855 - val_loss: 1.5051 - val_acc: 0.7507\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = best_model.fit(x_train, y_train_vec,  \n",
    "           epochs=60, \n",
    "           verbose = 1,\n",
    "           validation_data = (x_test, y_test_vec)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "wQJPuhUcymlE",
    "outputId": "ca8adb67-544b-4c55-bfcf-bbd12fa6af70"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKwLHcZwcxxWB4zhOjuOKwHEcJ8f5f1hOVnkEL8LyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_val_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BqpyXBdQqiYH"
   },
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "sjRUaIX8XnFC",
    "outputId": "6973875a-a938-4c22-b433-3389f17bcf4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.5051226496696473\n",
      "accuracy = 0.7506999909877777\n"
     ]
    }
   ],
   "source": [
    "print('loss = ' + str(history.history['val_loss'][-1]))\n",
    "print('accuracy = ' + str(history.history['val_acc'][-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xl1nyMOJqiYP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HM4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
